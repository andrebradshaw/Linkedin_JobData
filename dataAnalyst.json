[{"jobtitle":"Data Analyst II CX / Text / NPS with ADP","companyname":"Not Just a Job Search","companyid":"18154965","address":"","geo":"El Paso, TX, US","postDate":"Nov 12 2018","views":"1","applicants":"0","employees":"2-10","jobDetails":[{"level":"Associate","industry":["Marketing & Advertising","Information Technology & Services","Computer Software"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nThe position listed below is not with Not Just a Job Search but with ADP\n\n Data Analyst II CX / Text / NPS Req Number:156666 Category:Technology Posted Date:July 6, 2018 Work Location(s):Florham Park,NJ,US Tempe,AZ Augusta,GA Florham Park,NJ El Paso,TX Norfolk,VA ADP is hiring a Data Analyst II. Responsible for key business metrics and reporting that drives decision making and process improvement for the Business Unit and NPS Center of Excellence. A champion for standardizing and automating internal client-facing reports provided to Business Units. Be a change agent within the Business Unit?s closed loop administration to ensure accurate and high quality data is collected and analyzed on a consistent basis. Leverage a variety of analytical tools to provide information that is flexible, responsive and nimble to changing business needs. The NPS Business Analyst is responsible for Analysis/ Consulting, Configuration/ Integration, Validation/ Support and Project Planning for all aspects of the NPS closed loop process with a focus on predictive Analytics, Reporting and Survey Administration. At ADP we are driven by your success. We engage your unique talents and perspectives. We welcome your ideas on how to do things differently and better. In your efforts to achieve, learn and grow, we support you all the way. If success motivates you, you belong at ADP. We strive for every interaction to be driven by our CORE values: Insightful Expertise, Integrity is Everything, Service Excellence, Inspiring Innovation, Each Person Counts, Results-Driven, & Social Responsibility. RESPONSIBILITIES: Analytics/ Consulting/Communicating : + Conducts NPS project initiation activities. + Uncover complex client experience opportunities. + Analyze existing client systems, interface requirements, business process and operational needs. + Assess client experience data including client feedback, predictive modeling, and client behaviors and profiling + Gather, assemble, analyze and deliver actionable insights and recommendations. + Provides professional consulting in the areas of tool customizations, business processes, analytics, complex custom reports and special projects. + Responsible for researching benchmarked and attainable validated systemic tools to evaluate HR performance, resulting in metrics that help senior leaders drive Service Excellence. + Develop meaningful analytic conclusions and recommends innovative solutions. + Work with Business Unit champions and Subject Matter Experts (SMEs) to define requirement related to reporting, analytics, trending and communications. + Create business requirements based on detailed analysis of Business Unit needs. + Coordinates and consults with Corporate IT for customization work. + Develops adhoc inquiries to assist in reporting, categorization and analysis. + Provides demos and training for champions and SMEs, including documentation as required for reporting, analysis, trending and communication. Configuration/ Integration: + Works and counsels with business units on system and service configuration tools, tool adaptation and business best practice solutions. + Determines best methodology and oversees the accurate and timely conversion of survey data, reporting and analytics. + Consults on interfaces to internal and external systems. Validation/Support: + Builds survey control information and oversees the pre- and post-implementation testing of tools, processes, reports and alerts. + Establish predictive analytics. + Oversees formal coordination of system and operational services to other ADP business units and departments. + Performs testing and support during UAT, works to resolve defects/ issues. + Support the COE (Center of Excellence) and Business Unit during the production release of new tools, reports, alerts and analytics. + Provide Tier I/II support for the tools, reports and system supporting the NPS initiative to the business units. Project Planning: + Participates in establishing and monitoring of Business Unit implementation schedule and report status to Project Team Members. + Ensures issues and risks are documented and work with team members to resolve. Knowledge Sharing of Best Practices: + Business Unit and Center of Excellence teams will work collaboratively to standardize all aspects of Closed Loop process, analytics, reporting and survey administration with consideration for the unique needs of the individual businesses. + Train appropriate uses on analytical tools to ensure widespread adoption of best practices in collecting and analyzing data for actionable recommendations to leaders. + Performs other related duties as assigned. QUALIFICATIONS REQUIRED: + Education Qualification: Bachelor?s Degree with major area of concentration BS in Finance, Accounting, Statistics. + Experience: 5-8 years of related experience in analytics, market intelligence and analytics, financial modeling or statistical analysis. \\ Preference will be given to candidates who have the following: + Excellent quantitative and analytical skills, and strong attention to detail. + Clarabridge Modeling, Tableau, SQL, SAS or other text analytics, CX Analytics, Python, R. + Excellent project management skills. + Strong verbal and interpersonal skills, with demonstrated ability to work with and communicate at all levels of staff and management. + Ability to interpret data into actionable recommendations. + Strong Excel skills required, including data modeling and ad hoc analysis. + Can easily build relationships across multiple functions and business Units. **Software in the Cloud. Experts on the Ground:** **ADP powers the working world with comprehensive solutions that drive business success.** Consistently named one of the ?Most Admired Companies? by _FORTUNE?_ Magazine, and recognized by _Forbes?_ as one of ?The World?s Most Innovative Companies,? ADP has over a half-million clients around the globe and 65 years of experience as one of the largest providers of human capital management solutions world-wide. At ADP, we believe that diversity fuels innovation. ADP is committed to equal employment opportunities regardless of race, color, genetic information, creed, religion, sex, sexual orientation, gender identity, lawful alien status, national origin, age, marital status, or protected veteran status. We support an inclusive workplace where associates excel based on personal merit, qualifications, experience, ability, and job performance.\n\n"},{"jobtitle":"Senior Associate Data Engineer","companyname":"Andiamo Partners","companyid":"32309","address":"","geo":"New York City, NY, US","postDate":"Nov 12 2018","views":"4","applicants":"1","employees":"51-200","jobDetails":[{"level":"","industry":["Computer Software","Financial Services","Information Technology & Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nJob Description\n\nThe largest writer of retail life insurance in the U.S. and a top player in annuities, long-term care and mutual funds, is seeking a Data Engineer in its Center for Data Science and Analytics.\n\n The Center for Data Science and Analytics is the innovative corporate Analytics group within the company. We are a rapidly growing entrepreneurial department, which aims to design, create and offer innovative data-driven solutions for many parts of the enterprise. We are aided by the company's existing business with a large market share in individual life insurance. We have the freedom to explore external data sources and new statistical techniques, and are excited about delivering a whole new generation of Analytical solutions.\n\n In fact, we are designing and will build one of the first multivariate model-based continuous risk differentiations in the industry. This model will incorporate current underwriting best practices (including medical rules) as features and add other data sources, patterns/ideas and variables to essentially create a rating plan to support the next generation underwriting process. This is just one of several projects with large business value. Geographic analytics on agents and customers, application fraud detection, agent success prediction and client prospecting analytics (off-line and on-line) are other exciting examples of enormous incremental value from analytics. Our products will be implemented into real-time core business processes and decisions that drive the company (e.g. underwriting, pricing, agent recruiting, prospecting, new product development).\n\n We work with data ranging from demographics, credit and geo data to detailed medical data (medical test results, diagnosis, prescriptions) and social media information . We have a modern computing environment with a solid suite of data science/modeling tools and packages, and a large (but manageable) group of well-trained professionals at various levels to support you. Life insurance is on the verge of huge change. This is a chance to be part of, actually to drive, the transformation of an industry.\n\n You will be part of Data & Platform sub-function team under Center for Data Science and Analytics . The Data & Platform team services internally to Data Scientists who focus on Statistical analysis.\n\n You will be part of a fast paced, high-impact team who will work with an entrepreneurial mindset using some of the best of breed tools as part of our Enterprise Data Lake (Hadoop) using R, Spark and Python.\n\n You will apply your data engineering skills to build pipelines, workflows to gather, cleanse, test and curate datasets from Oracle, MSSQL Server, 3rd party data and create datasets in Enterprise Data Lake (Hadoop) which will be used by several teams of predictive modelers.\n\n You will perform Proof of Concepts and test out new software tools under the umbrella of Data Science but geared more towards data engineering.\n\nResponsibilities\n\n\nIngests, merges, prepares, tests, documents curated datasets from various novel external and internal datasets for a variety of advanced analytics projects such as Multi-variate model for Risk, Marketing and Compliance\nUtilizes data wrangling/data matching/ETL techniques while to explore a variety of data sources, gain data expertise, perform summary analyses and curate datasets\nFunctions as data expert, contributes to analytics/solutions design and productizing decisions\nCan work independently with some supervision and be part of a collaborative team\nWork with Project Managers and Scrum Masters to provide milestones and stories\nProactively and effectively communicates in various verbal and written formats with senior level member of the team and partners\n\n\nRequired Qualifications\n\nGraduate-level degree in computer science, engineering, or relevant experience in the field of Business Intelligence, Data Mining, Database Engineering, Programming\n3-5 years of overall experience working in the field of data wrangling and programming with a minimum of 1 year experience with ingesting, cleaning, merging and applying necessary data wrangling logic in Hadoop\n1+ years in writing complex SQL queries in any of the following and/or similar databases - Oracle, SQL Server, DB2, MySQL\nProficiency using Python for all data related work such as Numpy, Pandas, PySpark\nExperience working with Linux Operating System\nExperience working with data visualization tools or packages\nExperience building Exploratory Data Analysis reports such as Histograms, Box plots, Pareto, Scatter Plot using R, Python or a Data Visualization tool such as Tableau, Spotfire\n\n\n\nPreferred\n\nUnderstanding of statistical modeling concepts, designs and analytics-based products\nAny experience in using ETL tools such as Ab Initio, Talend, Informatica, Pentaho\nAny experience working with Data Warehouses and/or Data Marts\nAny experience in Life Insurance business\n\n\n\nOther Notes\n\nOur technology stack is RStudio Pro, SAS, Enterprise Data Lake (using Hortonworks Hadoop Data Platform), Waterline, Trifacta, R, Python, Spark, PySpark, SparkR, Linux\n\n EOE M/F/D/V\n\nAndiamo Is An Equal Opportunity Employer\n\nAndiamo provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Andiamo complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.\n\n Recruiter Name: Bryan Spears"},{"jobtitle":"Data Scientist II with Orion Business Innovation","companyname":"South East Apply","companyid":"27150536","address":"","geo":"Jacksonville, FL, US","postDate":"Nov 11 2018","views":"3","applicants":"0","employees":"2-10","jobDetails":[{"level":"Entry level","industry":["Information Technology & Services","Computer Software","Computer Games"],"jobtype":"Full-time","function":["Engineering","Information Technology"]}],"description":"Job description\nThe position listed below is not with South East Apply but with Orion Business Innovation\n\n Candidate should have experience in some form of SQL (e.g. HIVE, PostgreSQL, MSSQL, etc.) and either Python or R for statistical application development. Experience in a Hadoop environment and / or statistical development tool (e.g. RapidMiner, Knime) a plus. Data Scientist Develop and communicate a deep understanding of client needs, perform analytical deep-dives to identify problems, opportunities and specific actions required Develop reproducible and deployable statistical applications on platform such as R/Python/Spark using techniques such as Regression, SVM, and Neural Networks Implementing processes that improve and lead to greater data quality Conducting statistical analyses to develop strategies Documenting all processes and research Building new algorithms and model training Executing projects involving analytics Identifying data patterns and trends Analyzing data to develop predictive models Creating, managing, and maintaining analytically rigorous data Possessing a solid machine learning foundation Proven record of successful statistical product delivery Ability to execute health insurance use cases via statistical applications such as R or Python Efficiently access data via multiple vectors (e.g. NFS, FTP, SSH, SQL, Sqoop, Flume, Spark) Significant experience with SQL and working with large datasets required Work with cross-functional teams (including Product Management, Engineering, and senior executives) to rapidly execute and iterate Noting anomaly detection and running diagnostics Performing graphical model analysis Strong verbal and written communication skills Strong in R or Python with good SQL knowledge and communication skills. About Us We are a global technology services provider enabling customers to capitalize on technology in their business for over 23 years. We have successfully delivered solutions across data, analytics, enterprise collaboration, risk & compliance, knowledge management and cloud enabling customers' journey from \" data to decision making \". We focus on engineering data-driven business processes using Digital technologies (data, analytics and the cloud) that allow our customers to enhance productivity into their business processes by making them run faster, better and cheaper. Our global collaborative workforce combines talent and passion for customer satisfaction that has resulted in transformative solutions for our customers. Website : www.orioninc.com Linked in : Specialties :Data Analytics & Business Intelligence, Cloud Computing, Data Management and Data Mining, DevOps, ERP, Telecom, Systems Integration, Enterprise Applications Development, and SharePoint. - provided by Dice Associated topics: data analyst, data analytic, data engineer, data management, data quality, data scientist, database administrator, mongo database administrator, sybase, teradata"},{"jobtitle":"Data Analyst II CX / Text / NPS with ADP","companyname":"ADP","companyid":"","address":"","geo":"El Paso, TX, US","postDate":"Nov 12 2018","views":"2","applicants":"0","employees":"","jobDetails":[{"level":"Associate","industry":["Marketing & Advertising","Information Technology & Services","Computer Software"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nThe position listed below is not with Not Just a Job Search but with ADP\n\n Data Analyst II CX / Text / NPS Req Number:156666 Category:Technology Posted Date:July 6, 2018 Work Location(s):Florham Park,NJ,US Tempe,AZ Augusta,GA Florham Park,NJ El Paso,TX Norfolk,VA ADP is hiring a Data Analyst II. Responsible for key business metrics and reporting that drives decision making and process improvement for the Business Unit and NPS Center of Excellence. A champion for standardizing and automating internal client-facing reports provided to Business Units. Be a change agent within the Business Unit?s closed loop administration to ensure accurate and high quality data is collected and analyzed on a consistent basis. Leverage a variety of analytical tools to provide information that is flexible, responsive and nimble to changing business needs. The NPS Business Analyst is responsible for Analysis/ Consulting, Configuration/ Integration, Validation/ Support and Project Planning for all aspects of the NPS closed loop process with a focus on predictive Analytics, Reporting and Survey Administration. At ADP we are driven by your success. We engage your unique talents and perspectives. We welcome your ideas on how to do things differently and better. In your efforts to achieve, learn and grow, we support you all the way. If success motivates you, you belong at ADP. We strive for every interaction to be driven by our CORE values: Insightful Expertise, Integrity is Everything, Service Excellence, Inspiring Innovation, Each Person Counts, Results-Driven, & Social Responsibility. RESPONSIBILITIES: Analytics/ Consulting/Communicating : + Conducts NPS project initiation activities. + Uncover complex client experience opportunities. + Analyze existing client systems, interface requirements, business process and operational needs. + Assess client experience data including client feedback, predictive modeling, and client behaviors and profiling + Gather, assemble, analyze and deliver actionable insights and recommendations. + Provides professional consulting in the areas of tool customizations, business processes, analytics, complex custom reports and special projects. + Responsible for researching benchmarked and attainable validated systemic tools to evaluate HR performance, resulting in metrics that help senior leaders drive Service Excellence. + Develop meaningful analytic conclusions and recommends innovative solutions. + Work with Business Unit champions and Subject Matter Experts (SMEs) to define requirement related to reporting, analytics, trending and communications. + Create business requirements based on detailed analysis of Business Unit needs. + Coordinates and consults with Corporate IT for customization work. + Develops adhoc inquiries to assist in reporting, categorization and analysis. + Provides demos and training for champions and SMEs, including documentation as required for reporting, analysis, trending and communication. Configuration/ Integration: + Works and counsels with business units on system and service configuration tools, tool adaptation and business best practice solutions. + Determines best methodology and oversees the accurate and timely conversion of survey data, reporting and analytics. + Consults on interfaces to internal and external systems. Validation/Support: + Builds survey control information and oversees the pre- and post-implementation testing of tools, processes, reports and alerts. + Establish predictive analytics. + Oversees formal coordination of system and operational services to other ADP business units and departments. + Performs testing and support during UAT, works to resolve defects/ issues. + Support the COE (Center of Excellence) and Business Unit during the production release of new tools, reports, alerts and analytics. + Provide Tier I/II support for the tools, reports and system supporting the NPS initiative to the business units. Project Planning: + Participates in establishing and monitoring of Business Unit implementation schedule and report status to Project Team Members. + Ensures issues and risks are documented and work with team members to resolve. Knowledge Sharing of Best Practices: + Business Unit and Center of Excellence teams will work collaboratively to standardize all aspects of Closed Loop process, analytics, reporting and survey administration with consideration for the unique needs of the individual businesses. + Train appropriate uses on analytical tools to ensure widespread adoption of best practices in collecting and analyzing data for actionable recommendations to leaders. + Performs other related duties as assigned. QUALIFICATIONS REQUIRED: + Education Qualification: Bachelor?s Degree with major area of concentration BS in Finance, Accounting, Statistics. + Experience: 5-8 years of related experience in analytics, market intelligence and analytics, financial modeling or statistical analysis. \\ Preference will be given to candidates who have the following: + Excellent quantitative and analytical skills, and strong attention to detail. + Clarabridge Modeling, Tableau, SQL, SAS or other text analytics, CX Analytics, Python, R. + Excellent project management skills. + Strong verbal and interpersonal skills, with demonstrated ability to work with and communicate at all levels of staff and management. + Ability to interpret data into actionable recommendations. + Strong Excel skills required, including data modeling and ad hoc analysis. + Can easily build relationships across multiple functions and business Units. **Software in the Cloud. Experts on the Ground:** **ADP powers the working world with comprehensive solutions that drive business success.** Consistently named one of the ?Most Admired Companies? by _FORTUNE?_ Magazine, and recognized by _Forbes?_ as one of ?The World?s Most Innovative Companies,? ADP has over a half-million clients around the globe and 65 years of experience as one of the largest providers of human capital management solutions world-wide. At ADP, we believe that diversity fuels innovation. ADP is committed to equal employment opportunities regardless of race, color, genetic information, creed, religion, sex, sexual orientation, gender identity, lawful alien status, national origin, age, marital status, or protected veteran status. We support an inclusive workplace where associates excel based on personal merit, qualifications, experience, ability, and job performance.\n\n"},{"jobtitle":"Big Data Analyst - Developer","companyname":"PowerAdvocate","companyid":"29420","address":"","geo":"Boston, MA, US","postDate":"Nov 12 2018","views":"14","applicants":"5","employees":"51-200","jobDetails":[{"level":"Entry level","industry":["Information Technology & Services","Business Supplies & Equipment","Education Management"],"jobtype":"Full-time","function":["Engineering","Information Technology"]}],"description":"Job description\nDo you want to join the world of Data Science in the fast-growing energy market?\n Do you love to turn large datasets into meaningful stories and actionable knowledge? Do you want to be involved in delivering the next generation of analytic solutions using Statistical/Machine Learning methods and a range of Big Data technologies? Join a team where you are encouraged to explore, learn, and push boundaries.\n We are currently developing several applied Machine Learning solutions with the goal of scaling and automating the classification of millions of records of our clients’ supply chain data. For ten years, we have been classifying our clients’ purchasing transactions into our industry-specific categorization schema. This gives us an inordinate amount of training data\n\nmillions of rows of classified transactions representing over $2+ Trillion of spend. That’s not a typo\ntwo trillion dollars! Our efforts are focused on deploying fully-integrated Machine Learning algorithms to assist our industry experts in leveraging their knowledge at greater scale and efficiency. We have a fertile ground of training data, a can-do entrepreneurial spirit and appreciation for robust and effective analytics approaches to delivering value. Come join our team!\n\nPowerAdvocate leads the energy data industry by providing energy companies with clarity into their complex data. Our Energy FactBase, currently at $2+ Trillion and growing, helps customers to create operational and financial excellence. We help our clients to understand how they can leverage our unique view of the marketplace to reduce costs and manage operation risk working with executives on the cutting edge in the power, oil and gas, and renewable energy sectors.\n\nJOB TITLE: Big Data Analyst\nDeveloper**\nDEPARTMENT**: Data Science\nLOCATION**: Boston\nSUMMARY**:As a member of PowerAdvocate’s Data Science team, the Big Data Analyst\nDeveloper actively participates in all aspects of the algorithm testing and development process—from data extraction and wrangling, through effective database integration solutions to model development and implementation. The Big Data Analyst\nDeveloper contributes as part of an Agile Scrum team, in a fast-paced environment with high visibility to the rest of the company. He or she also participates in broader aspects of each project including communicating ongoing results and outcomes via effective visualizations and other presentation tools, as well as gaining a deeper understanding of the results produced and their applicability to our internal customers.\n\nJob Responsibilities: In addition to the following, other duties may be assigned to meet business needs:\n\nExtract, clean, audit and prepare data for analysis, relying on well-structured procedures and maintaining reproducibility of results\nDesign experiments to answer targeted questions and conduct exploratory data analysis\nAnalyze and judge the quality of data produced and proactively develop and implement solutions to data quality issues\nPresent and visualize interim and final results of analyses\nImplement and test algorithms and techniques relevant to achieving project objectives\nMaintain and develop, as needed, databases relevant to analytic solutions being developed\nInterface with primary team members to construct, maintain, and automate client-related data to support other analyst teams in the Spend Intelligence Group\nTranslate business objectives into actionable analysis\nProvide insight into the development of new customer products and internal uses for PowerAdvocate’s vast database of information.\n\nJob Qualifications**:KEY COMPETENCIES**:\n\nCan guide the team through effective approaches to data extraction, data auditing, and exploratory data analyses\nDevelops clear workflow / implementation plans based on chosen modeling approaches\nHas a sharp eye for detail coupled with capacity for planning, organizing and analyzing large-scale complex data projects\nDemonstrates solid interpersonal skills to work cooperatively with a diverse team to deliver superior results in a self-managed Scrum environment\nCommunicates findings clearly to both technical and non-technical audiences\nDemonstrates the ability to shift between academically rigorous approaches and pragmatic quick-and-dirty-yet-useful tools for the real world\nIs open-minded about new approaches and tools for achieving the goals of our customer\nTECHNICAL SKILLS AND REQUIREMENTS**:\n0-1 year of relevant experience in Data Science, Statistics, Econometrics or Machine Learning projects\nHigh proficiency in a range of statistical / modeling tools\nProficient at data profiling, cleaning, and mining\nSolid programming skills in at least one object-oriented language (Python and/or R preferred)\nWorking knowledge of Javascript and SQL a plus\nExperience with R Shiny, Flask, or related frameworks a plus\nB.S./M.S. in a quantitative discipline: Econometrics, Statistics,"},{"jobtitle":"Senior Data Engineer - Finance Technology","companyname":"Amazoncom Services Inc","companyid":"","address":"","geo":"Seattle, WA, US","postDate":"Nov 12 2018","views":"4","applicants":"1","employees":"","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Computer Software","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nJob Description\n\nSenior Data Engineer - Finance Technology\n\n Location: US-WA-Seattle\n\n Job ID: ******\n\n Company: : ********** Services, Inc.\n\n Position Category: Business Intelligence\n\n Company/Location (search) : Country (Full Name): : United States\n\nJob Description\n\nFinance Technology team at Amazon is looking for a Data Engineer to play a key role in building the next generation Financial data warehouse. The ideal candidate will be passionate about building large, scalable and fast distributed systems on the AWS stack. Our new team member will want to be part of a team that has accepted the goal to democratize access to data and enabling data driven innovations for Finance users at Amazon. We are building one of the coolest brand new Big Data solutions at Amazon that will enable rapid self-service data reconciliations at Amazon.\n\n Amazon is seeking an engineer with a strong background in Big Data technologies (Redshift, EMR, EDX, S3 etc.) with interest in data mining and ability to sieve emerging patterns and trends from large amount of data. Data Engineers should have strong experience with standard data warehousing components (e.g. ETL, Reporting, and Data Modeling). The ideal candidate will have extensive experience in dimensional modeling, excellent problem solving ability dealing with huge volumes of data and a short learning curve. Excellent written and verbal communication skills are required as the candidate will work closely with Finance customers and our leadership.\n\n Along with Amazon scale problems to solve, we provide you with a chance to work the industry's most talented data engineering minds. Click Apply for an opportunity to create history while having fun.\n\nResponsibilities\n\nDesign, build and own a high volume financial data warehouse.\nBuild efficient data models using industry best practices and metadata for reporting.\nInterface with business customers, gathering requirements and delivering complete data & reporting solutions.\nOwning the design, development, and maintenance of ongoing metrics, reports, analyses, and dashboards to drive key business decisions\nContinually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers\nInterface with other technology teams to extract, transform, and load (ETL) data from a wide variety of data sources\nOwn the functional and technical scaling of software systems in your ownership area.\nProvides input and recommendations on technical issues to BI Engineers, Business and Data Analysts.\n\nBasic Qualifications\n\nBachelors in Computer Science, Engineering, Statistics, Mathematics or related field\n\nIntermediate to Expert experience in data engineering or Business Intelligence space\nStrong understanding of ETL concepts and experience building them with large-scale, complex datasets using traditional or map reduce batch mechanism.\nStrong data modelling skills with solid knowledge of various industry standards such as dimensional modelling, star schemas etc\nExtremely proficient in writing performant SQL working with large data volumes\nExperience designing and operating very large Data Warehouses\nExperience with scripting (e.g., Python, UNIX Shell scripting, Perl, or Ruby).\nExperience or willingness to learn working on the AWS stack.\nClear thinker with superb problem-solving skills to prioritize and stay focused on big needle movers\nCurious, self-motivated & a self-starter with a 'can do attitude'. Comfortable working in fast paced dynamic environment.\n\nPreferred Qualifications\n\nBe ready to learn and train on radical new tools on the AWS stack.\nWorking knowledge of PL/SQL working with large data sets.\nExperience working with Oracle Hyperion or Oracle Data Integrator (ODI)\nIdeally have experience with AWS technologies including Redshift, RDS, S3, EMR, DynamoDB, Hive, Spark etc.\nExperience with dimensional modelling skills.\n\nAmazon is an Equal Opportunity-Affirmative Action Employer - Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation"},{"jobtitle":"Data Engineer","companyname":"HUB International","companyid":"10001","address":"","geo":"Chicago, IL, US","postDate":"Nov 12 2018","views":"11","applicants":"0","employees":"10001","jobDetails":[{"level":"","industry":["Financial Services","Insurance"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nAbout Us\n\nHUB International Limited (“HUB”) is the 7th largest global insurance and employee benefits broker, providing a broad array of property, casualty, risk management, life and health, employee benefits, investment and wealth management products and services. With over 10,000 employees in 450 offices throughout North America, HUB has grown substantially, in part due to our industry leading success in Mergers and Acquisitions. The company is headquartered in Chicago and is currently owned by Hellman & Friedman.\n\nAbout The Position\n\nThe Big Data Engineer will lead the development of applications or system software and improve the efficiency of information processing systems. The candidate should have experience in designing, developing and testing a company's data management software, ensuring that it meets business requirements and industry practices. This position requires experience in training internal and external resources to integrate new products and software packages into the system in the organization.\n\nResponsibilities\n\nResponsible for designing, developing, testing, and deploying distributed machine learning systems and large-scale data mining solutions\nDesigns and implements data-oriented applications using a wide variety of technologies, including Microsoft’s Cloud technology stack (Azure).\nImplement data-intensive, horizontally-scalable systems (such as on Map-Reduce frameworks like Hadoop, Spark, etc.).\nDevelops distributed applications to solve large scale processing problems, utilizing various languages like Java, Scala , Shell etc.\nImplements, troubleshoots, and optimizes solutions based on modern big data technologies like Hadoop, Spark, Elastic Search, Storm, Kafka, etc. in both an on premise and cloud deployment model\nImplements data architecture, including data ingress in batch and real time from a broad variety of external systems; data transformations to prepare data for analytics processing, and data egress for availability of analytics results to visualization systems, applications, or external data stores\nSupports documentation, change control, and QA processes consistent with enterprise requirements\nEstablishes strong teamwork with client technical resources, and effectively communicates project status, technical issue options and resolution, and operational requirements to client stakeholders\nCommunicate via RESTful APIs with HTTP and JSON\nResearch and development of novel technologies and methodologies for extreme scale data analytics, big data processing, data mining, and machine learning on traditional and emerging computing architectures\n\n\n\nRequirements\n\nBachelor’s or Master’s degree in Computer Science, Engineering, Information Systems or related field preferred\n7 to 10 years of experience in a professional capacity as described above\nExperience with one or more of the cloud products: Azure, Amazon AWS, OpenStack, CloudFoundry, Mesos and Docker\nVery strong server-side Java or .NET experience, especially in an open source, data-intensive, distributed environments\nExpert in the Hadoop Framework & java programming (i.e. Spark, MapReduce, Pig, Hive, Kafka, Storm, etc.) including performance tuning\nGood understanding of algorithms, data structure, and performance optimization techniques\nExperience with agile development methodologies like Scrum\nSelf motivated, and has the ability to drive technical discussions\nOrganized, detail oriented, able to work both independently and in a team\nExcellent problem solver, analytical thinker and quick learner\nStrong verbal and written communication skills\nProficient in Data Architecture, Master Data Management and Governance\nExperience in NoSQL DB such as Cassandra and MongoDB\nCertifications a plus: Amazon, Cloudera, Spark\n\n\n\\\n\nLocation: United States, Illinois, Chicago\n\nRequired Education: Bachelor's degree (4-year degree)\n\nRequired Experience: 5-7 years\n\nRequired Travel: No travel required\n\nDate published: 8-Nov-2018\n\nDepartment: Information Technology\n\nRef#: P2061_20180825\n\n HUB International Limited is an equal opportunity and affirmative action employer that does not discriminate on the basis of race/ethnicity, national origin, religion, age, color, sex, sexual orientation, gender identity, disability or veteran's status, or any other characteristic protected by local, state or federal laws, rules or regulations. The EEO is the Law poster and its supplement is available here at http://www.dol.gov/ofccp/regs/compliance/posters/ofccpost.htm .\n\n We endeavor to make this website accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact the US Recruiting Team toll-free at (844) 300-9193 or USRecruiting@hubinternational.com . This contact information is for accommodation requests only; do not use this contact information to inquire about the status of applications.\n\n"},{"jobtitle":"Data Analyst-JDJP00018228","companyname":"Generis Tek Inc","companyid":"","address":"","geo":"Waterloo, IA, US","postDate":"Nov 12 2018","views":"2","applicants":"2","employees":"","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Computer Software","Staffing & Recruiting"],"jobtype":"Contract","function":["Information Technology"]}],"description":"Job description\nWe have a Contract role for a Data Analyst with our client in Waterloo, IA. Please let me know if you or any of your friends would be interested in this position.\n\nThe Details Of The Position Are\n\nData Analyst\n\nRole\n\nWorks closely with the business and other Information Technology (IT) teams focusing on the processes of gathering, analyzing and documenting information requirements using standard data management tools and techniques for the creating, support and administration of database objects.\nWork is of medium complexity and moderate in risk.\nHas broad contact with responsibility to multiple departments and functional operations, and ongoing interaction with business contacts on tactical issues.\nServes as an effective and key team member in various roles including serving as a team lead. Follows established processes for tasks with minimal review.\nUses discretion and judgment in planning own work/schedule and has some responsibility for planning work/schedules for others on project-related work.\nImpact of decision-making is medium risk and impact.\nActively works to share knowledge across workgroups.\nApplies information analyses to assist in the effective\nImplementation and integration of a business process.\nIntegrates medium to complex changes to existing processes with minimal review.\nPrimarily performs as an individual contributor, but may supervise a small work team (6 or fewer members).\n\n\nResponsibilities\n\nHelps define processes for tasks with minimal supervision to create and manage physical data models for applications, data warehouse, and data marts.\nCreates and manages logical data models for an enterprise and/or project level where projects are of medium complexity and moderate in risk.\nDocuments and maps interaction between business processes, information, and data to ensure that business has data integration for projects which are of medium complexity and moderate risk.\nPerforms gap analysis (including problem resolution and change management) and evaluation between information requirements and the quality of design of database and database administration environment of vendor purchased and/or outsource solutions, actively working to share knowledge.\nManages physical design and integration of databases to support information requirements where projects are of medium complexity and moderate in risk.\nServes as a key team member and may assume role of team lead to develop, implement, and support methodologies, standards, and tools for data management such as metadata management, data mining, data modeling, data cleansing, transformation and matching, data stewardship, data quality, data integration, data security, and data marts.\nProvides input to design of application systems and interfaces to ensure data access, integration, integrity, and security for projects which are of medium complexity and moderate risk.\nPerforms database/application performance tuning, data transformation and mapping, backup, and recovery of application databases including disaster recovery with minimal supervision.\nPrimarily responsible for data that drives an internal data aggregation tool used by enterprise supply management commodity teams.\nGather data from various internal sources and load into existing data bases.\nThis may include working with DB2 tables, SAP. Includes data mining (up to 80% initially), interpreting and converting data to common standards of the business, fixing/formatting for uploading.\nDevelop and run reports for the business, some analytics.\nAssist with documenting the tool and processes with potential for providing training. Works closely with users, tool developer, commodity suppliers.\nPotential to lead the data portion of projects to expand the tool for more commodities.\n\n\nRequirements\n\nSolid knowledge of the fundamentals of mathematics, statistical analysis, and probability theory Professional experience coupling data analysis and machine learning tools and techniques.\nAt least 3 years of professional experience with conducting statistical analysis, model building, and machine learning\nAt least 3 years of experience with writing scripts in SQL.\nAt least 3 years of experience with R or Python\nAt least 1 year of professional experience working on a diverse and collaborative team\nBachelor's Degree in Mathematics, Statistics, Computer Science, Computer Engineering, or Data & Analytics Ideal Candidate:\nAdvanced degree in mathematics or statistics\nDemonstrated experience with machine learning tools and techniques in the analytics industry Excellent communicator who is able to effectively communicate across a diverse team of functional areas and skillsets.\nAt least 1 year of experience with AWS (Amazon Web Services) Compute, Analytics, EMR, and/or Storage products.\nAt least 1 year of experience with the Hadoop Eco System of products Tools : You will utilize and gain experience in a wide range of tools and components as you develop cutting edge ways to better support our customers and dealers. Such as: Aginity, RStudio, R Shiny/R Connect, Python, Hadoop, Hive, Hbase, NiFi, Hue, AWS, Netezza, Tableau, Sqoop, Oozie, Spark, HDFS, Grafana, Databricks, Scala.\n\nIf you are interested in this opportunity, please email your resume at jobs@generistek.com. Also, you can call us at # (630) 299 5176.\n\nAbout Generis Tek\n\nGeneris Tek is a boutique IT/Professional staffing based in Chicagoland. We offer both Contingent Labor & Permanent placement services to several Fortune 500 clients Nationwide.\n Our philosophy is based on delivering long-term value and build lasting relationships with our clients, consultants and employees. Our fundamental success lies in understanding our clients’ specific needs and working very closely with our consultants to create a right fit for both sides. We aspire to be our client’s most trusted business partner.\n\n At Generís Tek we are constantly evolving to help talented professionals map their careers. We provide a competitive, fast-paced environment that promotes open communication to form a long term relationship built on mutual understanding, respect and trust. We at Generís Tek very highly value our relationship with our consultants. What sets us apart is the high level of service we provide to our clients after each employee is placed. Our dedicated professionals help you in reaching your career objective. Let’s connect and realize your goal."},{"jobtitle":"Data Engineer - AWSRedshift - ASAP!","companyname":"Techlink Systems","companyid":"","address":"","geo":"Redwood City, CA, US","postDate":"Nov 12 2018","views":"1","applicants":"0","employees":"","jobDetails":[{"level":"Entry level","industry":["Information Technology & Services","Computer Software","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nJob Description\n\nThe Data Engineer will play a key part in designing and building out the analytics stack to facilitate data democratization, business intelligence reporting and deep analytic capabilities for our company. This position will require a number of different skills from data design and architecture to conducting ad hoc analyses and building advanced statistical models. The right candidate will have technical experience with enterprise data environments as well as a keen analytic mind and ability to answer questions with data and insight using data mining techniques.\n\nJob Responsibilities\n\nWork with the Sr. Director to define, design and implement analytical data layer schema to support Machine Learning, Business Intelligence, and Analytical capabilities.\nWork with a number of data system types and craft an effective ecosystem accommodating elements such as MongoDB, REST API, AWS Redshift, R, Python, etc.\nPerform advanced data analysis and create various statistical models utilizing advanced data mining techniques and statistical software.\nDrive the build out and refinement of the BI visualization layer and help train staff in a self-service environment under the direction of the Sr. Director of Analytics.\nBe a data and information expert that consults with other areas of the business at both a strategic and tactical level.\nWork with the Sr. Director of Analytics to build out the Analytics Stack roadmap and proactively drive implementation including gather requirements, Project manages and execute, Present updates on infrastructure projects.\nEffectively communicate project status and analytic findings to all parts of the business.\n\n\nJob Qualifications\n\nDegree in statistics, data science, computer science, engineering or similar field.\n4+ years of experience working with enterprise data systems and/or analytic and BI data environments.\n3+ years of experience with BI Reporting platforms like Tableau, MicroStrategy, DOMO, etc. and creating data visualizations and dashboards.\nFamiliarity with data architecture and schema design.\nExcellent SQL, AWS Redshift, MongoDB, Python or R skills.\nFamiliarity with third party data collection platforms like MixPanel, Google Analytics, Apps Flyer, etc.\nExperience with SAS, SPSS, R or other statistical/analytical software.\nStrong analytical skills, problem-solver, and attention to detail.\nPassionate about Sports and Gaming.\nMotivated self-starter, revels in a dynamic, fast-changing environment and brings a can-do attitude\nExcellent communication skills.\n\n\nTechLink Systems is a privately held IT Consulting Firm that provides Consulting Services to organizations nationwide. TechLink Systems is a certified MWOBE and has been in business since 1998. Our network spans all major U.S. metropolitan areas touched by major sectors such as entertainment and leisure, finance, industry and government, health sciences, and information technology. Whether you are a client seeking IT services and support or a candidate searching for new opportunities, TechLink System's outstanding customer service and dedication will exceed your expectations in the marketplace! TechLink has 4 regional offices located in San Francisco, Los Angeles, New York City, Philadelphia and a Development Center in Bangalore, India.\n\n http://www.techlinksystems.com/\n\nAwards\n\n\nRanked Top 500 Asian-Owned & Asian Pacific American-Owned Businesses in the US -Ranked Top 100 Diversity-Owned & Privately-Owned Businesses in California -Ranked INC500 Fastest Growing Private Companies -Ranked Top 100 Largest Women Owned Business San Francisco Business Times -Ranked 50 Largest Minority-Owned Companies San Francisco Business Times - Ranked in Top 100 Woman Owned Business in the US, Diversity Business -Ranked in the Top 10 Minority-Owned Businesses in the Philadelphia Business Journal -Ranked in the Top 50 Woman-Owned Businesses in the 2014 Philadelphia Business Journal"},{"jobtitle":"Senior Analyst/Office of Strategic Insights","companyname":"Avamere Family of Companies","companyid":"62370","address":"","geo":"Wilsonville, OR, US","postDate":"Nov 12 2018","views":"4","applicants":"0","employees":"5001-10000","jobDetails":[{"level":"Associate","industry":["Non-profit Organization Management","Health, Wellness & Fitness","Hospital & Health Care"],"jobtype":"Full-time","function":["Research","Analyst","Information Technology"]}],"description":"Job description\nNow Hiring!\n\nSenior Analyst/Office of Strategic Insights: Avamere Health Services\n\nFull-Time Position Available\n\nPlease apply online at: https://careers-avamere.icims.com\n\nAvamere Health Services\n\n25117 SW Parkway Ste. B\n\n Wilsonville, Oregon 97070\n\nwww.avamere.com\n\nThe Senior Data Analyst is core to the success and growth of Business Intelligence at Avamere, driving adoption of BI reporting and helping get the most from our data. They will engage and consult with internal business stakeholders, providing support & guidance on maximizing the value from BI tools. They will create and maintain reporting systems for the executive team and business operators.\n\nWho We’re Looking For\n\nYou want to be part of a start-up team given the challenge of redefining the foundation for how the whole company will use business and market intelligence for making better decisions\nYou are a creative thinker who knows how to use quantitative/analytical models to communicate the language of numbers to people\nYou often find yourself imagining how to write a formula or a full-blown quantitative model to explain how the world works as you observe it during your daily commute or your afternoon stroll\nYou are confident in your analysis skills… AND yet still need to expand your “number crunching” toolkit\nYou are the type of person who gets excited when given a challenging problem to solve\nYou think creating two predictive models per month is a dream come true!\n\n\nNeed To Haves\n\nAbility to communicate complex results to executives and project sponsors\nExperience with unsupervised techniques such as cluster analysis and PCA\nPowerBI, Tableau, or RShiny for data visualization, reporting, and building data products\nApplied machine learning experience with a focus on interpreting results, model optimization, and cross validation\nAbility to perform complex data wrangling using Excel, Python, Altreyx, Power Query and/or SQL\nStrong foundation creating mathematical / financial / statistical formulas as part of quantitative modelling\n\n\nGood To Haves\n\nInterest in predictive modelling\nExperience building data tools and applications\nAbility to build data pipelines using SQL, Python, and/or other scripting languages\nExperience with Unix or windows command line\nAbility to perform given technical or compliance constraints\nExperience using popular python and R libraries for data science such as:\nPandas\nnumpy\nscikit-learn\nmatplotlib\ndply\ntable\nggplot2\nExperience writing reproducible code in R or Python with use of Jupyter notebooks and Git\n\n\nThe Responsibilities\n\nRepresent BI team, often as first point of contact, ensuring BI users/stakeholders have relevant access to BI tools/environments and understand how to use them\nWork with business leads to ensure we’re capturing the right data upfront to ensure consistency across sources to facilitate correlation and a holistic view in reporting\nExplore user needs, recommend BI solutions and arrange appropriate access\nExplore user needs and suggest/create quantitative models/analysis that support decision making and continuous improvement\nLiaise with other IT functions to coordinate master data changes\nDeliver training to end users centered around how to access, consume and utilize BI reporting\nEncourage BI best practice through drop-in sessions and troubleshooting\nMaintain business knowledge to be able to understand and explain context of BI reports\nPromote the use of BI solutions throughout the business, driving adoption and growth in user base\nConduct ad hoc deep-dives to diagnose and address performance defects\nDevelop predictive tools and responsive workflows to pro-actively identify defects within Amazon’s supply chain operations\nIdentify appropriate metrics and determine appropriate business requirements. Translates client's business requirements for development, anticipating client's needs.\nDetermines best methods in order to gather data and present complex information. Consults and gives guidance to other analysts.\nBuilds complex reporting solutions to meet business needs. Consults with other analysts, as well as other external/technology partners.\nCommunicates with project/team manager to share knowledge and findings. Communication of progress, milestones, challenges against plan, and escalation of issues.\nRespond in a timely manner to queries and faults, investigating and answering with clarity\nAct as mentor to other analysts\nAct as subject matter expert in the field of quantitative analysis\n\n\nQualifications\n\nBachelor’s degree in any actuarial/quantitative field (statistics, mathematics, economics, physics, financial planning, and other quantitative fields)\nMaster’s degree is highly preferred\n3-5 years’ experience working as a quantitative analyst\nTechnical aptitude and awareness of BI technologies (Excel, pivot tables, Power View, Power BI, Access, Tableau, etc.)\nDemonstrated expertise in extracting, manipulating, and understanding data to do draw conclusions\nExperience in developing new metrics and monitoring systems to increase understanding of business performance\nPassionate about data, statistics and reporting\nProven problem-solver when faced with unfamiliar situations\nRelentlessly high standards and capacity to pay extraordinary attention to detail\nCompetent at presenting (virtually and in-person) whilst thinking on the spot to provide answers\nAbility to think creatively, deal with ambiguity, and manage changing priorities\nStrong organizational skills\nThe ability to communicate clearly with both senior leadership and coworkers\nFast and efficient learner who is highly motivated and can work and thrive in a fast paced, deadline driven environment\nKnowledge of Microsoft Office - Word, Excel, Microsoft Outlook, Powerpoint\nConfident working in the detail to unpick complex problems and identify root cause"},{"jobtitle":"Data Analyst","companyname":"Brandfolder","companyid":"2807067","address":"","geo":"Denver, CO, US","postDate":"Nov 12 2018","views":"2","applicants":"1","employees":"11-50","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Business Supplies & Equipment","Events Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nBrandfolder is looking for a talented and motivated Data Analyst to grow our presence at the forefront of Digital Asset Management. You will inspire the most recognizable brands in the world, like TripAdvisor and Slack, by providing tools and strategic insights that increase their brand engagement. At our core, Brandfolder is data driven company. We strive to use data in all our decision and product development processes ranging from lead generation to product feature tuning to incorporating new machine learning based features in product.\n Who are we looking for? You have a solid grounding in statistics and are comfortable with hypothesis testing, design of experiments, regression and classification models, multivariate statistics and time series methods. You have experience with data munging and model building with R or Python using various statistical packages like tidyverse, forecast, lubridate, caret, statsmodels, scikit-learn, pandas to name a few. You have strong experience with query languages like SQL. You have experience building visualizations with packages like ggplot2, matplotlib, plotly etc. As a Data Analyst at Brandfolder, you will be part of the data science team that works across product, marketing, sales, customer experience and finance. Specifically, you would be involved in projects such as campaign response modeling and measurement, customer segmentation and persona modeling, customer lifetime value modeling, churn prediction, anomaly detection in product usage to proactively maintain reliability/uptime, lead scoring etc. We have an amazing list of clients that will rely on you to provide an enhanced data driven experience in all aspects of our interaction with them.\n Do you want a role where your contributions directly affect the success of the company? Will you make a name for yourself at Brandfolder? We have a team of curious, eager, and humble individuals who rally together both within and outside the confines of the office and aim to expand and evolve our culture as our team grows. We embrace that each interaction and opportunity for feedback can help us grow individually and collectively.\n\nWhat you'll do**:\nJoin a collaborative team of engineers, sales, marketing and customer experience folks in Denver\nContribute to best-in-class analytics patterns and practices as we grow\nDevelop and own analysis, dashboards and delivery platforms\nDevelop robust data and analysis pipelines for continuous analysis & reporting\nWrite good quality maintainable and reusable code\nConstantly optimize and improve data quality and models\nBecome an integral contributor to the direction of the data team\nWhat you'll need**:\nBachelor's Degree in Statistics, Computer Science or similar analytics discipline\n2+ years of data analysis and model building\nPositive attitude and the adaptability to thrive in a fast-paced environment\nStatistical programming experience with R or Python\nExperience building visualizations and dashboards\nSolid understanding of statistical inference, regression and classification\nData mining ability with query language like SQL\nGood ability of explaining results to broader audience\nStrong knack for picking up new tools and technologies, continuously learning\nThe drive to take initiative and own high-impact projects from day one\nBonus points for**:\nMaster's Degree in Statistics, Computer Science or similar analytics discipline\nExperience building shiny interactive dashboards or similar systems\nExperience with version control systems like git\nPrevious experience in marketing and/or sales analysis\nExperience with D3js to build visualizations\nPrevious work experience in a startup-like environment\nA growth mindset and passion for learning\nThe ability to elevate those around you\nBrandfolder Perks**:\nIconic office location in RiNo, bike and light rail friendly\nGenerous paid time off\nMedical and dental insurance, 100% paid by Brandfolder\nMonthly company events and happy hours\nDog-friendly office\nExposure to recognizable and powerful brands\nAbout Brandfolder**:\n\nHeadquartered in Denver's RiNo neighborhood, Brandfolder is an enterprise digital asset management (DAM) platform that enables businesses to organize, discover, distribute, and measure brand engagement. Loved by global brands including Under Armour, New Belgium, Slack, and jetBlue.\n Brandfolder is an equal opportunity employer; we are focused on creating an inclusive environment and believe that diversity of all types is essential to our success. We encourage all to apply, and will choose you on the basis of qualifications and merit."},{"jobtitle":"HR Business Analyst","companyname":"RYLEM Consulting","companyid":"","address":"","geo":"Seattle, WA, US","postDate":"Nov 12 2018","views":"","applicants":"0","employees":"","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Business Supplies & Equipment","Consumer Services"],"jobtype":"Contract","function":["Business Development","Sales"]}],"description":"Job description\nContractStrategic Recruiting is looking for an experienced Business Analyst. The Strategic Recruiting Team (SRT) focuses on building top specialized talent communities in Design and Applied Research, including Machine Learning (ML), Computer Vision, Speech Recognition/Natural Language Processing, Optimization, Economics, Sustainability, Hardware, Data Science and Robotics globally at Amazon. We build teams in emerging fields and recruit senior Design and Science leaders. As a core talent function, we also develop Amazon's presence at key gatherings, drive academic relations and facilitate internal community efforts. Our efforts support Amazon's development of new businesses, such as Alexa and Amazon Go while ensuring state-of-the-art research and design are at the forefront of Amazon's more mature organizations.\n As a Business Analyst you will support Strategic Recruiting to make data-driven recommendations. You will work with business owners to understand analytics requirements and develop solutions. You will be responsible for pulling, cleaning, analyzing, and dashboarding internal community data while looking for ways to streamline, standardize, and automate these reports. You will perform data-mining and analysis using tools such as Oracle HRBI, MS Excel, SQL, Tableau, and Amazon Redshift. You will manage data projects from beginning to end including, but not limited to: scoping requirements, collaboratively developing a methodology, executing data gathering and analysis, documenting your approach, and assessing what worked well and what did not. You will effectively prioritize your assignments to complete work in a timely manner and deliver results in a fast paced environment. You will independently follow-through on assignments with minimal direction.\n\nRequired Skills**:\n3+ years of prior work experience in a business analyst, data analyst, or business intelligence analyst role Bachelor's degree or equivalent work experience\nExperience developing data visualizations using tools such as Tableau, D3, QuickSight\nExperience developing requirements and formulating business metrics for reporting\nAdvanced Microsoft Office skills, particularly Excel and analytical platforms\nProficient SQL skills\nExperience in an analytical role with the ability to interpret data, analyse results using statistical techniques to identify trends or patterns in complex data sets, and provide ongoing reports\nAble to communicate complex messages and outputs from their analysis in a confident and simple way, and the ability to train others in technical/analysis skills. Strong analytical skills with the ability to collect, organize, analyse, and disseminate significant amounts of information with attention to detail and accuracy preferred skills\nBachelors degree in Mathematics, Statistics, or other quantitative fields Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, R, Python etc.)\nExperience in HR Operations, Recruitment, Staffing, Payroll, etc. Analytical mind set and ability to see the big picture and influence others.\nJob Type**: Contract\nExperience**:\nBusiness Analysis: 3 years (Required)\n\nWork Authorization\n\nUnited States (Preferred)\n"},{"jobtitle":"Senior Data Engineer (KH10951)","companyname":"Codeworks, Inc.","companyid":"456189","address":"","geo":"Wauwatosa, WI, US","postDate":"Nov 12 2018","views":"","applicants":"0","employees":"201-500","jobDetails":[{"level":"Associate","industry":["Information Technology & Services"],"jobtype":"Contract","function":["Information Technology"]}],"description":"Job description\nCodeworks is a locally owned and operated IT Services firms in SE Wisconsin, known for our strong commitment to quality and for our direct client relationships.\n\n Our DIRECT client is seeking two experienced Data Engineers .\n\n\nIn-Person interview required**\n\nAccountabilities\n\n REQUIRED:\n\nAssist with architecture and construction of BI solutions\nIntegration of data from enterprise assets like SalesForce, call center applications, click stream and development process management, production monitoring systems into an internal BI platform\nDeployment of highly automated end-to-end BI solutions from data acquisition to delivery of consumer insights\nAssist in the creation of data models for internal BI systems as well as consumer facing offering\nDevelop and deployment of data hygiene patterns\nAssist with definition of next generation product offerings including BI Analytics, data mining & AI/ML capabilities\nPromote data culture to and provide guidance to other project teams that supports access to data assets for future monetization\nEstimate the level of effort and duration for entire projects/engagements\nEnsure compliance of deliverable to architectural design patterns\nUsing client approved development tools and adhere to department coding standards\nAdherence to client secure development, coding an data rights management policies\nPerform other tasks on projects as needed/assigned\n\n\nRequired Skills\n\nB.S. in information systems technology or computer science with 5+ years relevant experience, or equivalent combination of education and expertise.\nExpertise developing complex SQL queries\nExperience with ETL/ELT concepts and SSIS\nExperience with database development and modeling tools like Erwin\nExperience with scripting and automation concepts\nExperience with Tableau or another visualization tool\nExperience working with structured and unstructured data sets including JSON\nExperience implementing ML algorithms from data sourcing and prep through experimentation, model selection, deployment and monitoring\nExposure to Java/C# and Object Oriented Programming concepts\nAbility to demonstrate solid development technical concepts\nAbility to work on self-directed tasks and complete work independently\nPossess excellent written and oral communication skills\nPossess a high level of organizational, creativity and problem solving skills\nFamiliar with Agile software development methodologies is preferred\nAbility to understand client products', customers' and partners' needs in the Financial industry\nA proactive style with the ability to follow through on commitments and understand the importance of deadlines\nA desire to promote a data driven culture throughout the technology and business teams\n\nLocal candidates to Milwaukee, WI area will be given priority. If you feel that you meet the qualifications listed above and are open to working in the Milwaukee area, please forward your resume in Word format to careers@codeworks-inc.com with a copy to kristy.harmann@codeworks-inc.com .\n\nAbout CODEWORKS\n\nHeadquartered in Milwaukee, WI with an additional office in Madison, WI—Codeworks has more than 19 years of experience successfully serving Fortune 1000 companies in Wisconsin, as well as, our client's national locations. Our Recruiting team consists of highly skilled Talent Specialists skilled at evaluating, advising, and connecting IT professionals with new career opportunities that facilitate career growth. Every year since 2007, Codeworks has been recognized by Inc. Magazine as one of the fastest growing private companies in the U.S.\n\n For more information, please visit our website at: www.codeworks-inc.com .\n\n For priority career/job posting updates, please follow us on Twitter: @CodeworksIT"},{"jobtitle":"Marketing Data Analyst","companyname":"Onward Search","companyid":"215561","address":"","geo":"Sunnyvale, California, United States","postDate":"Nov 12 2018","views":"119","applicants":"60","employees":"51-200","jobDetails":[{"level":"Entry level","industry":["Design"],"jobtype":"Contract","function":["Design","Product Management"]}],"description":"Job description\n\nThe Marketing Technology team is dedicated to initiatives, data solutions and platforms that harness technology to achieve brand-level KPIs and overall ecosystem growth.This enables omni-channel, personalized, relevant communication at scale.\n\n A Lot About You\n\n Oath Marketing technology team is looking for a motivated and experienced Marketing data product manager to assist cross channel database initiatives such as data for evergreen and custom cross channel projects, gathering business requirements, implementing life-cycle data strategies, marketing automation, user segmentation/scoring, surveys, and leveraging dynamic/triggered messaging to optimize campaign responsiveness.\n\n We're looking for someone with a proven track record of driving complex projects with multiple inputs to successful completion. Candidate should be able to thrive in a dynamic work environment.\n\n What you'll be doing:\n Manage data from a multitude of sources for usefulness in email marketing, and architect ways to wrangle and join this data together. Common tasks involve data mapping, identification and application of business rules to data sets and resolving varying data granularities.\n Manage data collection from clients, data review and quality checks of incoming data to ensure high quality data is used in CRM and cross channel data processing.\n Mine and profile large sets of data from data sources using different query and visualization tools (e.g. SQL, Perl, Python , Tableau , Excel).\n Document requirements and gain consensus across internal and external stakeholder teams.\n Communicate technical requirements to development teams. Work with internal developers to answer questions and resolve ambiguities.\n Improve data quality results by determining system improvements; identifying trends; evaluating, and re-designing work processes; implementing changes.\n Perform ad hoc analyses and data investigation/discovery to identify and/or explain business and marketing trends or anomalies.\n Identify areas to improve the efficiency and effectiveness of CRM tool and data sources.\n Build strategic partnership with CRM, Media, Campaign and product teams to optimize processes and data flows.\n Segment and leverage the marketing database for efficient and effective campaign targeting\n Develop testing strategies and execution plans to optimize and improve performance of customer marketing programs (cadence, format, multivariate, A/B, model, etc.)\n Work with operations team to manage all day-to-day aspects of CRM-email program including list selection, creative, reporting, optimization and vendor management in order to achieve weekly, monthly, and quarterly goals.\n Manages program data flow, reporting and analysis, which include response tracking, campaign reporting, transfer of data between vendors and ad hoc issue investigation.\n Proactively identifies operational gaps, issues and challenges – and propose remedies.\n\n Skills, Talents, Experience you have:\n 3+ years of experience in data collection, data analysis, quality assurance.\n Advanced proficiency with software tools such as SQL, Perl, Unix, Python, Excel, Access to gather and assess data\n Excellent diagnostic skills to analyze and identify discrepancies within data sets and identify solutions\n Hadoop experience is a plus\n Ideal if you have specific experience in the ad-tech industry, a marketing agency, consulting.\n Resilient work ethic with the capability to adapt to the situation, flexibility and nimbleness in terms of work planning, and the ability to think quickly on your feet.\n Client-facing or consulting experience is a plus as you will need to confidently communicate and partner with yahoo internal clients.\n BS or BA (Bachelor Degree preferably in computer science, statistics, mathematics, marketing, or economics)      \n\n\n "},{"jobtitle":"Principal Data Engineer, BI","companyname":"Rally Health","companyid":"5313796","address":"","geo":"San Francisco Bay Area","postDate":"Nov 12 2018","views":"335","applicants":"40","employees":"501-1000","jobDetails":[{"level":"Mid-Senior level","industry":["Health, Wellness & Fitness","Internet","Computer Software"],"jobtype":"Full-time","function":["Engineering","Analyst"]}],"description":"Job description\n\nRally Health is all about putting health in the hands of the individual. It’s our mission, and it drives everything we do, which is to empower people with easy-to-use online and mobile tools that help them take charge of their health and health care, from improving their diet and fitness to selecting health benefits, and choosing the right doctor at the right price for their needs.\n\n\n\n\nOur culture is built on a deep and sincere commitment to helping people live healthier lives. To do this, we are committed to innovating at every level. As our president and COO David Ko says, “We are a company that continuously innovates. It cannot end. It has to be in everything we do, which means that some of the things we’re going to do are not going to work – and that’s okay. We’re not trying to build something that is churn and burn. We’re building something that follows consumers over their lifetime.”\n\n\n\n\nDo you love data and supporting an organization that is dedicated to making it easier and more rewarding for people to handle their health and wellness? Rally's mission is to help people to become healthier every day by putting health and wellness tools and crucial information in their own hands. We are looking for expert Business Intelligence professionals to join our data team, which also includes engineers and scientists, to drive our analytics, reporting, and business intelligence.\n\n\n\n\nResponsibilities:\n\n\n\n\nAnalyze data from consumers interactions with their healthcare insurers and providers, monitor trends and develop strategies and opportunities to improve their health and lower their costs.\nPartner with employers and healthcare insurers, prova phenomenal great UI for covered members and their families to manage both their health and healthcare options\nDevelop actionable insights for population health management and positive recommendations for ways individuals can improve their health and manage their costs\nResponsible for the design, development, implementation and support of critical enterprise E2E Business Intelligence ETL solutions in Hadoop, sourcing data from HDFS, Amazon Redshift, MongoDB or Postgres environments and utilizing Python, Spark and Hive.\nHandle the product's or project’s conception, design initial product specifications and lead scheduling, estimating and securing of resources\nProvide technical guidance to other internal and external teams\nHelp to train new employees and stay ahead of industry trends and issues\nMaintaining business partner engagement and setting expectations\nAssessing current processes and recommending changes as needed\nDocumenting and communicating technical specifications to ensure that proper and optimized techniques, queries, data standards, and final outputs are understood and incorporated into data and analytics processes\nParticipate in business analysis activities to gather required reporting and dashboard requirements\nTranslate business requirements into specifications that will be used to implement the required user-friendly environments, reports and dashboards, built from potentially multiple data sources\n\n\n\n\nQualifications:\n\n\n\n\nAdvanced working knowledge and ability to write complex SQL and HQL queries in an HDFS environment\nExtensive hands-on experience working with Python and PySpark for the purposes of data transformations and ETL\nStrong familiarity with Kimball, OLAP, and EDW data design methodologies\n8+ years experience in ETL, Data Engineering, or BI fields with concentration on data transformations\nUnderstanding of various data extraction and transformation techniques with data sourced in HDFS, MongoDB, and Postgres\nWorking familiarity with Pentaho, Airflow, or Oozie\nKnowledge of Scala is a bonus\nFamiliar with Data Visualization standard methodologies\nAbility to succeed in a dynamic, Agile environment\nStrong prioritization and time-management skills\nDedication to team goals that include support of live 24/7 production systems\nA consummate collaborator, able to establish good relationships with technical, product, and business owners\nA champion of quality, able to QA and vouch for the integrity of the report output\n\n\n\n\nWhy join Rally? On top of an innovative work atmosphere and a chance to help people change their lives, we offer competitive pay, daily catered lunches, and an extensive benefits package for all full-time employees (including medical, dental, vision and 401(k)). In addition, offer the ability to grow, while truly making an impact in the healthcare system.\n\n\n\n\nRally Health is committed to ensuring that its workforce reflects America’s diverse population. Rally Health knows that such diversity will enrich us with the talent, energy, perspective and inspiration it needs to achieve its mission. Rally Health believes in a policy of equal employment and opportunity for all people based on merit and commitment to the principles of diversity. It is our policy to recruit, hire, train, and promote individuals in all job titles, and administer all programs, without regard to race, color, religion, national origin or ancestry, citizenship, sex, age, marital status, pregnancy, childbirth or related medical conditions, personal appearance, sexual orientation, gender identity or expression, family responsibilities, genetic information, disability, matriculation, political affiliation, veteran status, union affiliation, or any other category protected by applicable federal, state or local laws.\n\n\n\n\nIndividuals with disabilities and veterans are encouraged to apply. Applicants who require an accommodation related to the application and/or review process should notify Talent Acquisition (recruiting@rallyhealth.com).\n\n\n\n\nPursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records."},{"jobtitle":"Data Analyst","companyname":"Swoon Group","companyid":"","address":"","geo":"Chicago, IL, US","postDate":"Nov 12 2018","views":"14","applicants":"3","employees":"","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Computer Software","Computer & Network Security"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nThe Data Analyst will join a team that is on an upward trajectory to enhance our client's competitive advantage through analytics. This position will contribute to our strategic vision of developing advanced analytics capabilities in support of developing and executing business strategy.\n\n He/She will be a data “polyglot”, will fit into multiple roles and teams to help customers make data driven decisions. He/She will develop skills to take any data and organize it for building a model or also create descriptive/exploratory models.\n\n A candidate capable of driving projects to their successful outcomes with effective communication and interpersonal skills will do well.\n\n This position reports to the Manager, Analytics\n\n Collaborate with Project Managers and business stakeholders to execute Analytics projects. This includes outlining specific deliverables, provide input to project plans and milestones.\n\n\nAnalyze and model structured data using advanced statistical methods and implement algorithms and software needed to perform analyses\n\n\nPerform machine learning, natural language, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods\n\n\nLeverage data management processes and available infrastructure / Relation data soruces/API tools to develop POC capabilities/solutions\nWork alongside ETL engineers to establish an analytics platform to be used across the business\nUse good Data Engineering process – Preperation, Exploration, Blending, Validation and Quality Control\nDemonstrate a commitment to core values\nThe position responsibilities outlined above are in no way to be construed as all encompassing. Other duties, responsibilities, and qualifications may be required and/or assigned as necessary\n\n\nQualifications\n\nAt least 3 years of professional experience as a Data Analyst\nExperience with Data Manipulation/wrangling techniques—Preparation, Exploration and Blending.\nExperience in supporting analytics projects in the following areas-- Consumer Insights, Brand Management, Customer Segmentation, Campaign Development, Web Analytics and Media/Message Mix Modeling\nKnowledge in a professional or academic setting on a range of analytical techniques (e.g. Supervised and Un-supervised machine learning techniques, graph data based analytics, statistical analysis, time series, geospatial, nlp, sentiment analysis, pattern detection to name a few)\nGood understanding of data manipulation/wrangling techniques\nExperience with command-line scripting, data structures and algorithms and ability to work in a Linux/Windows environment, processing large amounts of data in an on-premise and/or cloud environment\nStrong work ethic and personal integrity; self-directed and self-motivated with a highly developed curiosity and willingness to learn.\nExcellent verbal and written communication skills as well as interpersonal and influencing skills; ability to define and capture business needs along with articulating strategic implications of analytic results with clarity and persuasiveness in an audience appropriate manner.\nMasters in a quantitative field: computer science, econometrics, mathematics, statistics, analytics, or other related field\nOne or more years programming in SQL, R and/or Python.\nExperience with R and/or Python is strongly desired\nExperience with Spark is desired\nExperience with Alteryx is preferred\nExperience with Tableau or other data visualization tools is desired\nExpert in Microsoft Office suite, especially Word, Excel and Powerpoint\nFamiliarity with data warehousing concept\nExpert in Microsoft Office suite, especially Word, Excel and Powerpoint\nFamiliarity with IBM DB2 and SQL Server (SSRS, SSIS, SSAS) databases.\nFamiliarity with IBM SPSS and SAS tools for data exploration and mining is a plus\n\n\n#JB\n\n #dcejobs\n Id: 30862 - provided by Dice Algorithms, Analysis, Analyst, API, DB2, Development, Excel, IBM, Linux, Manager, Management, Modeling, PowerPoint, Programming, Project, Python, SAS, SQL, SQL Server, Statistical Analysis, Validation, Windows"},{"jobtitle":"Manager Modeling Data Analysis (Marketing Analytics) - Omaha, NE","companyname":"Mutual of Omaha","companyid":"","address":"","geo":"Omaha, NE, US","postDate":"Nov 12 2018","views":"2","applicants":"0","employees":"","jobDetails":[{"level":"Entry level","industry":["Information Technology & Services","Insurance","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nManager Modeling & Data Analysis (Marketing Analytics) - Omaha, NE\n\n Job no: ******\n\n Work type: Full Time Regular\n\n Location: Nebraska\n\n Categories: Analytics/Data Science, Leadership, Marketing/Communications\n\n The Manager Modeling and Data Analysis is responsible for driving top line growth by leading development of targeting and segmentation solutions to improve effectiveness of acquisition and early months on book marketing campaigns while interacting with business stakeholders across the organization to promote usage of advanced analytical solutions.\n\nEssential Job Functions\n\nDrive top line growth by leading development of targeting and segmentation solutions to improve effectiveness of acquisition and early months on book marketing campaigns\nInteract with business stakeholders across the organization to promote usage of advanced analytical solutions\nExplore new modeling tools and techniques and develop new solutions to add value to Mutual of Omaha\nManage all aspects of model development process, including model initiation, model design, model documentation and ongoing performance monitoring\nPerform ad hoc analysis to support internal audit requests\nDevelop strong partnership with multiple internal stakeholders, including targeting, model governance teams and Legal and Compliance\nPerform other duties and/or special projects as assigned\nBe a thought leader in driving rigor in all analytical efforts in support of Direct to Consumer campaigns including targeting, segmentation and testing\nPartner with peers to optimize the performance of the Direct to Consumer channel by testing and synthesizing key learnings around prospecting, mail frequency, cadence etc\nLead a team of Analysts to accomplish team goals\n\nMinimum Qualifications\n\n5+ years of experience as a data analyst of which 2+ years of experience in predictive model development, preferably in marketing or risk\n3+ year proven data mining and/or applicable programming skills with SAS, SQL, R, Python or other comparable languages\nBachelor's degree in Statistics\nExperienced in operationalizing targeting models\nRobust understanding of statistical techniques and their application in business\nComfortable with data extraction, data manipulation, synthesis and creating presentations\nPrior experience with analytical initiatives with demonstrated ability to problem solve and think critically; ability to recognize key leverage points in an analysis\nAbility to lead and motivate a team, strive for excellence and hold a high bar\nSelf-motivated and driven with an acute sense of ownership * Be a team player\n\nPreferred Qualifications\n\nHands on modeling experience\nExperience with Big Data tools (Hadoop, Spark etc.)\nPrior experience managing a team\n\nIf you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at 1-************. We are available Monday through Friday 7 am to 4:30 pm CST.\n For all other inquiries, contact our HR Helpline at 1-************, option 4.\n Mutual of Omaha and its affiliates are an Equal Opportunity /Affirmative Action Employer, Minorities/Female/Disabled/Veteran\n To All Recruitment Agencies: We do not accept unsolicited agency resumes and we are not responsible for any fees related to unsolicited resumes.\n\n Advertised: Aug 15, 2018 09:00 AM Central Daylight Time"},{"jobtitle":"Sr. Data Analyst","companyname":"FedEx Services","companyid":"1670","address":"","geo":"Memphis, TN, US","postDate":"Nov 12 2018","views":"45","applicants":"8","employees":"10001","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Computer Software","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nCompany: FedEx Services\nJob Title: Sr. Data Analyst\nJob Requisition Number: RC96136\nLocations:\nMemphis, Tennessee 38125\n United States\n\n Under moderate supervision, designs and implements processes and solutions associated with a wide variety of data sets used for data/text mining, and analysis to enable informed business decisions. Gains insight into key business problems and deliverables by applying statistical analysis techniques to examine structured and unstructured data from multiple disparate sources. With moderate direction, creates solutions from initial concept to production. Communicates results to a broad range of audiences. Effectively uses current and emerging technologies to evaluate trends and develop actionable insights and recommendations to management, via understanding of the business model and the information available for analysis. Typically uses data, statistical and quantitative analysis, limited modeling, and fact-based management to drive decision making. Mentors less senior staff. Works in cross functional projects and programs. Routinely presents to management.\n\nSkills/Knowledge Considered a Plus\n\nAbility to synthesize, analyze, and visualize large sums of data to tell a story\nExperience with the following tools: Python, SQL, Spotfire, SAS\nCustomer Service knowledge or experience\nFinance Knowledge or experience\n\n\nMinimum Qualifications\n\nBachelor's degree in information systems, computer science, or a quantitative discipline such as mathematics, engineering, operations research, economics or Finance. Five (5) years work experience in measurement and analysis,quantitative business problem solving, operations analysis,marketing analysis, simulation development and/or predictive analytics. Proficient in analytics software and applications. Good interpersonal skills. Good written and oral communication skills.\n\n Domicile / Relocation Information:\n This position was located in Memphis, Tennessee. Relocation assistance may be available for this position, but is a business decision.\n\nApplication Criteria / Deadline\n\nUpload current copy of Resume and answer job screening questionnaire by close of business on November 14, 2018.\n\nPaycode\n\nSK\n\n Want a career where you are empowered to make a difference? Want to work for a company that is environmentally responsible? Want to grow and develop on the job? If so, FedEx is the place for you! Every day FedEx delivers for its customers with transportation and business solutions. FedEx serves more than 220 countries and territories around the globe. We can serve this global network due to our outstanding team of FedEx employees. FedEx has over 400,000 talented employees who are tasked with making every FedEx experience outstanding. FedEx has been recognized on many different lists both for business success and for being a great employer.\n\n Here are some of the recognitions FedEx has received from the past couple of years:\n\nFORTUNE “World’s Most Admired Companies” – 2016\nCorporate Responsibility Magazine “100 Best Corporate Citizens” – 2016\nInformationWeek “Elite 100” – 2016\nWomen’s Business Enterprise National Council “America’s Top Corporations for Women’s Business Enterprises” - 2016\nReputation Institute “World’s Most Reputable Companies” – 2015\nBlack Enterprise “40 Best Companies For Diversity” – 2015\n\n\nWhen 400,000 employees around the globe are all working together it is amazing what we can achieve! FedEx connects people and ideas. If you would like to make a difference on a global scale while receiving top notch benefits, competitive pay, and plenty of opportunities to develop, click ‘Apply’ and tell us more about yourself.\n\n EEO Statement - FedEx is an equal opportunity/affirmative action employer (minorities/females/disability/veterans) that is committed to diversifying its workforce."},{"jobtitle":"Data Engineer (Entry Level)","companyname":"Princeton IT Services, Inc","companyid":"716360","address":"","geo":"Jersey City, NJ, US","postDate":"Nov 12 2018","views":"","applicants":"0","employees":"11-50","jobDetails":[{"level":"Entry level","industry":["Information Technology & Services","Computer Software","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nWe are looking for a Data Engineer (Entry-Level) for a client leading financial bank. Please see the job details below:\n\nPosition: Data Engineer (Entry Level)\n\nLocation: Jersey City NJ\n\nJob Length: 6 Months\n\nPosition Type: Contract C2C\n\nJob Summary\n\nEntry-Level Data Scientists extract knowledge or insights from structured or unstructured data. They draw upon the practice of data analysis, using predictive analytics, data mining, pattern recognition, data modeling, machine learning and various statistical methods in order to solve large scale optimization problems and to understand the meaning behind vast data sets\n\nQualifications & Characteristics\n\nBS in computer science, informations systems, or a related discipline\nGreat problem solving skills, debugging, troubleshooting, and designing & implementing solutions to complex technical issues\nExcellent verbal and written communication skills\nVery good team player\nStrong technical and analytical abilities, a knack for driving impact and growth, and some experience with programming/scripting in a language such as Java or Python\nBasic understanding of statistical programming in a language such as R, SAS, or Python\nInterest in, understanding of, or experience with Design Thinking Methodology\nInterest in, understanding of, or experience with Agile development methodology\n\n\n\nResponsibilities\n\nImplementing and validating predictive models, creating and maintaining statistical models with a focus on big data\nCommunicate with internal and external clients to understand business needs and provide analytical solutions\nUsing statistical concepts such as regression, time series, mixed model, Bayesian methods, clustering, etc., to analyze data and provide insights\nWork in an Agile, collaborative environment, partnering with other scientists, engineers, and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors\n\n\nKey Skills: Python, R, Data Science\n\n Regards,\n\n Abhijeet Mahajan\n\n Princeton IT Services\n\n Contact: 212-507-9352 | www.princetonits.com\n\n\nprovided by Dice python,r,data science,data engineer"},{"jobtitle":"Digital Data Analyst","companyname":"Great Wolf Resorts, Inc.","companyid":"","address":"","geo":"Chicago, IL, US","postDate":"Nov 12 2018","views":"3","applicants":"0","employees":"","jobDetails":[{"level":"Associate","industry":["Marketing & Advertising","Online Media","Public Relations & Communications"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nDescription\n\nThe Digital Data Analyst is the point analyst for both descriptive and prescriptive analytics supporting digital marketing, website analytics (and other digital guest experiences), testing and optimization efforts, in addition to developing cutting edge visualizations.\n\n You will team with both marketing and commercial operations across the business to analyze information and identify key insights that will drive growth. You will identify the data and infrastructure required to generate cohesive analysis to better understand our customers and product impact. You will provide actionable insights and recommendations on all analytic and financial activities for area of business including agile ad hoc analysis and long term Project-based production of business insights.\n\n In addition to these core functions, your additional responsibilities will be to:\n\nCollaborate with both internal stakeholders and external vendors involved in project definition, design and planning\nDevelop hypotheses, gather data, brainstorm strategic options and create recommendations around strategic initiatives\nOwn and rationalize marketing, web data and information across the organization\nOperate as a visualization lead and Subject Matter Expert across the organization\nCollect, Analyze and Synthesize complete information from disparate sources into a clear and compelling story in visualizations\nBuild key success metrics to evaluate the impact of various projects, improvements and services that we provide\nDevelop tactical analysis of our online business to strategically analyze current planning resources and develop actionable analysis\n\n\n\nRequirements\n\nRequired Qualifications:\n\n2+ years of experience in operational analytics\n\nExperience with range of Advanced Analytics techniques; statistical analysis skills; SQL, Tableau, Alteryx and other ETL/ELT knowledge and experience\nGoogle Analytics, A/B testing and multivariate testing\nStrong desire to tell analytical journeys and stories through the use of visualization tools\n\n\n\nPreferred Qualifications\n\nAbility to effectively build relationships across the business at all levels\nCreative thinker who is intellectually curious with a demonstrated passionate about learning\nSelf-starter, entrepreneurial, high-energy who can take initiative in a fast-moving environment\nProficient in various programming languages, including SQL, R, and Python (and others)\nDevelop critical business analysis skills -- ability to hone in on real business impact and sorting through anecdotal reasoning, comfortable working with analysts and quantitative analysis\nProvide strong technical understanding of current and emerging internet technologies and the operations of a commercial Website\nFunction as a highly effective leader in a matrix environment given the role of serving various business partners on the enterprise and business unit teams\nIdentify and model data to support personalization across digital channels; collaborate with product management, development, digital marketing, and data science to implement and enhance personalization efforts.\nUse of Google Analytics and other analytic and statistical tools to provide in-depth statistical analyses to leverage data when making business decisions\n\nCommunicate insights to key internal stakeholders and executive leadership team\n\n\n\nEducation\n\nBachelor's Degree Required (Concentration in a quantitative field preferred including Business, Engineering, Math, Statistics, Economics, Operations Research)\nMaster's Degree Preferred"},{"jobtitle":"Digital Data Analyst","companyname":"Great Wolf Resorts","companyid":"","address":"","geo":"Madison, WI, US","postDate":"Nov 12 2018","views":"5","applicants":"1","employees":"","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Computer Software","Internet"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nDescription\n\nThe Digital Data Analyst is the point analyst for both descriptive and prescriptive analytics supporting digital marketing, website analytics (and other digital guest experiences), testing and optimization efforts, in addition to developing cutting edge visualizations.\n\n You will team with both marketing and commercial operations across the business to analyze information and identify key insights that will drive growth. You will identify the data and infrastructure required to generate cohesive analysis to better understand our customers and product impact. You will provide actionable insights and recommendations on all analytic and financial activities for area of business including agile ad hoc analysis and long term Project-based production of business insights.\n\n In addition to these core functions, your additional responsibilities will be to:\n\nCollaborate with both internal stakeholders and external vendors involved in project definition, design and planning\nDevelop hypotheses, gather data, brainstorm strategic options and create recommendations around strategic initiatives\nOwn and rationalize marketing, web data and information across the organization\nOperate as a visualization lead and Subject Matter Expert across the organization\nCollect, Analyze and Synthesize complete information from disparate sources into a clear and compelling story in visualizations\nBuild key success metrics to evaluate the impact of various projects, improvements and services that we provide\nDevelop tactical analysis of our online business to strategically analyze current planning resources and develop actionable analysis\n\n\n\nRequirements\n\nRequired Qualifications:\n\n2+ years of experience in operational analytics\n\nExperience with range of Advanced Analytics techniques; statistical analysis skills; SQL, Tableau, Alteryx and other ETL/ELT knowledge and experience\nGoogle Analytics, A/B testing and multivariate testing\nStrong desire to tell analytical journeys and stories through the use of visualization tools\n\n\n\nPreferred Qualifications\n\nAbility to effectively build relationships across the business at all levels\nCreative thinker who is intellectually curious with a demonstrated passionate about learning\nSelf-starter, entrepreneurial, high-energy who can take initiative in a fast-moving environment\nProficient in various programming languages, including SQL, R, and Python (and others)\nDevelop critical business analysis skills -- ability to hone in on real business impact and sorting through anecdotal reasoning, comfortable working with analysts and quantitative analysis\nProvide strong technical understanding of current and emerging internet technologies and the operations of a commercial Website\nFunction as a highly effective leader in a matrix environment given the role of serving various business partners on the enterprise and business unit teams\nIdentify and model data to support personalization across digital channels; collaborate with product management, development, digital marketing, and data science to implement and enhance personalization efforts.\nUse of Google Analytics and other analytic and statistical tools to provide in-depth statistical analyses to leverage data when making business decisions\n\nCommunicate insights to key internal stakeholders and executive leadership team\n\n\n\nEducation\n\nBachelor's Degree Required (Concentration in a quantitative field preferred including Business, Engineering, Math, Statistics, Economics, Operations Research)\nMaster's Degree Preferred"},{"jobtitle":"Business Intelligence/ETL Specialist","companyname":"Guardian Life","companyid":"164085","address":"","geo":"New York City, NY, US","postDate":"Nov 12 2018","views":"8","applicants":"4","employees":"5001-10000","jobDetails":[{"level":"","industry":["Financial Services","Insurance"],"jobtype":"Full-time","function":["Finance"]}],"description":"Job description\nA BOUT GUARDIAN\n\nEvery day, Guardian gives 26 million Americans the security they deserve through our insurance and wealth management products and services. Since our founding in 1860, our long-term view has helped our customers prepare for whatever life brings whether starting a family, planning for the future or taking care of employees. Today, we’re a Fortune 250 mutual company and a leading provider of life, disability and other benefits for individuals, at the workplace and through government sponsored programs. The Guardian community of ~9000 employees and our network of over 2750 financial representatives is committed to serving with expertise when, where and how our clients need us. Our commitments rest on a strong financial foundation, which at year-end 2017 included $8.0 billion in capital and $1.6 billion in operating income. For more information, please visit guardianlife.com or follow us on Facebook, LinkedIn , Twitter and YouTube .\n\n Guardian is an equal opportunity employer. All qualified applicants will be considered for employment without regard to age, race, color, creed, religion, sex, affectional or sexual orientation, national origin, ancestry, marital status, disability, military or veteran status, or any other classification protected by applicable law.\n\n Guardian® is a registered trademark of the Guardian Life Insurance Company of America\n\nPosition Responsibilities\n\nData Analytics/Reporting\n\nConduct data analysis in support of a variety of analytic solutions.\nCreate and produce forecasts, reports, ad hoc requests, dashboards, etc.\nPrepare monthly dashboard reports, identifying trends and presenting thoughtful, actionable solutions.\nDocument and train end users on reports and dashboards.\nETL/Data Blending\nTransform and utilize data in the data warehouse by creating, automating and documenting new tables in a post-load process. These new tables will transform the data from a transactional view to a more user-friendly business view. These tables can be used for direct usage for descriptive and predictive analytics\nApply the business rules on raw data in the data warehouse, data cleansing, data blending to bring data into the shape for profiling, dashboards, insights via project basis.\nApplying masking routine on the personally identifiable/sensitive data when necessary\nContinuously apply Data Governance processes including monitoring of the data quality with appropriate business areas\nProvide data modeling, mining, pattern analysis, anomaly detection and data visualization to address customer needs with front-end tools\nDocumenting the data blending process along with the specifications and workflow/data lineage for future automation usage\nMaintaining/adding to already made data dictionary for predictive analytics data profiling/modeling and/or any downstream usage\nPartners with IT, Database Administrators and business owners to ensure optimized data transformation and efficiencies.\nDevelop relationships with business team members by being proactive, displaying an increasing understanding of the business processes and by recommending innovative solutions\n\n\nPrimary Location\n\nUnited States-New York-New York\n\nJob\n\nFinance\n\nSchedule\n\nFull-time\n\nShift\n\nDay Job\n\nJob Type\n\nStandard\n\nTravel\n\nNo\n\nJob Posting\n\nNov 8, 2018, 8:26:13 AM\n\nOverall Qualifications\n\n CANDIDATE QUALIFICATIONS\n\nBachelor’s Degree in Computer Science / Engineering, IT, or Data Analytics from an accredited university\nHands-on proficiency in one or more scripting languages (e.g., Java, Python, Scala, R, Shell scripting)\n5+ years’ experience working with databases and hands-on proficiency in SQL\n5+ years of relevant experience in ETL or data analyst role, including data mining and/or ETL development\n2+ years’ experience developing management reporting dashboards using Tableau\nDatabase Development – Hadoop\nExperience with relational databases: Sybase ASE, SQL Server, Oracle, MySQL\nExcellent written and verbal communication skills\n\nEvery day, Guardian gives 26 million Americans the security they deserve through our insurance and wealth management products and services. Since our founding in 1860, our long-term view has helped our customers prepare for whatever life brings whether starting a family, planning for the future or taking care of employees. Today, we’re a Fortune 250 mutual company and a leading provider of life, disability and other benefits for individuals, at the workplace and through government sponsored programs. The Guardian community of ~9000 employees and our network of over 2750 financial representatives is committed to serving with expertise when, where and how our clients need us. Our commitments rest on a strong financial foundation, which at year-end 2017 included $8.0 billion in capital and $1.6 billion in operating income. For more information, please visit guardianlife.com or follow us on Facebook, LinkedIn, Twitter and YouTube.\n\n Guardian® is a registered trademark of the Guardian Life Insurance Company of America.\n\n Guardian is an equal opportunity employer. All qualified applicants will be considered for employment without regard to age, race, color, creed, religion, sex, affectional or sexual orientation, national origin, ancestry, marital status, disability, military or veteran status, or any other classification protected by applicable law.\n\n Guardian2018"},{"jobtitle":"Sr. Data Analyst","companyname":"Fitbit","companyid":"","address":"","geo":"San Francisco, CA, US","postDate":"Nov 12 2018","views":"15","applicants":"3","employees":"","jobDetails":[{"level":"Associate","industry":["Electrical & Electronic Manufacturing","Medical Device","Consumer Goods"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nSr. Data Analyst\n\nat Fitbit\n\n US - San Francisco\n\n At Fitbit, our mission is to help people lead healthier, more active lives by empowering them with data, inspiration and guidance to reach their goals.\n\n We started our journey in 2007—as a team of two with one big idea. Since then, we’ve grown to over 1,500 employees, sold over 60mm devices, and built a health and fitness community across the globe. In fact, the Fitbit Community has taken enough steps to walk from the Sun to Pluto! Offering award-winning products, a top-rated mobile app and an easy-to-use online dashboard, Fitbit provides personalized experiences that help our users reach their goals. With a reenergized focus on innovative devices, interactive experiences, and enterprise health we are transforming the way consumers and businesses see health & fitness.\n\n From your first steps as a Fitbitter, you will be at the forefront of developing new products. Our culture combines the spirit of startup with the perks of being public. We offer a competitive benefits package and amazing perks like unlimited snacks, Friday happy hours, onsite workout classes, and a strong focus on a healthy work-life balance. As part of our team, you’ll have the opportunity to grow your career, contribute your ideas to life-changing products and services, and—above all—have fun doing it.\n\n Fitbit’s HQ campus is located in the heart of San Francisco with office locations in Boston, San Diego and around the world. Think you’ve found your fit?\n\nWhat You'll Work On\n\nApply your expertise in quantitative analysis, data mining and presentation of data to see beyond the numbers and understand how our users interact with our core/business products.\nPartner with Customer Support, Research, Product Specialist, Community, Social and Engineering teams to identify trends and opportunities\nInform, influence and support our product decisions using insight on customer experience\nDesigning and evaluating experiments monitoring key metrics, understanding root cause of changes in metrics\nBuilding and analyzing dashboards and reports\nUnderstanding the customer support ecosystems, user behaviors, and long term trends\nIdentify levers to help move key metrics\nEvaluating and identifying metrics\nBuilding models of user behaviors for analysis\n\n\n\nRequired Skills\n\n5+ years experience in an analytics/data science role\nBachelors, Masters degree in quantitative discipline (Economics, Finance, Statistics, Engineering, Computer Science or MBA with emphasis in analytics)\nProficient at analyzing large multi-dimensional data sets using data/statistical tools such as R, Python, SAS, SPSS and Excel.\nExperience utilizing tools like Tableau, HighCharts, Qlikview\nLinux skills (shell scripting, Java, PHP, etc.)\nA strong passion for data, charts, analysis, trends, and evangelizing data usage\nAn appreciation for Fitbit’s products\nAbility to draw conclusion from data and provide recommendations\nPresentation skills including creating Keynote/PowerPoint presentations\n\n\nFitbit is proud to be an equal opportunity employer. We recruit, hire, train, promote, pay, and administer all personnel actions without regard to race, color, ancestry, national origin, citizenship, religion, age, sex (including pregnancy, childbirth, and medical conditions related to pregnancy, childbirth, or breastfeeding), sex stereotyping (including assumptions about a person’s appearance or behavior, gender roles, gender expression, or gender identity), sexual orientation, gender, gender identity, gender expression, marital status, medical condition, mental or physical disability, military or veteran status, genetic information or other statuses protected by law. We interpret these protected statuses broadly to include both the actual status and any perceptions and assumptions made regarding these statuses.\n\n San Francisco applicants: Pursuant to the San Francisco Fair Chance Ordinance Fitbit will consider for employment qualified applicants with arrest and conviction records.\n\n Individuals seeking employment at Fitbit are considered without regards to race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, gender identity, or sexual orientation."},{"jobtitle":"BI Data/Reporting Analyst","companyname":"Astreya","companyid":"","address":"","geo":"Mountain View, CA, US","postDate":"Nov 12 2018","views":"6","applicants":"3","employees":"","jobDetails":[{"level":"Associate","industry":["Construction","Information Technology & Services","Telecommunications"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\n## Skills\n\nAbility to Adapt and Quickly Adjust to Change\nDescription\n\nCompany *\n\n Astreya Partners are at the cusp of the new way of working. We provide IT services and Managed Performance to some of the most exciting companies on the planet. Our delivery model helps our clients be *Positively productive *by matching exceptional people to on-site teams delivering world class IT service. With engineers in over 30 countries and 70 cities around the world we are a truly global company working with truly global clients.\n\n If you are an ambitious and driven individual with a passion for data, tools and problem solving of vexing operational challenges, then this BI Data Analyst is for you! You will be working within a very dynamic and evolving Insights team as part of our largest global support program.\n\n You will be traversing a vast landscape of evolving tools and technologies to harness large sets of data to produce enhance reporting, live dashboard and analysis results for Managers across the globe. You will work collaboratively alongside peer analysts to produce and maintain insight deliverables. You will work directly with operational managers, client program managers and cross functional stakeholders to gather requirements and produce data in consumable formats and end-point.\n\n This role will also partake in BI initiatives to continually improve the process of data management, transformation and visualization of raw data into meaningful information and insights.\n\nYou Will Have The Opportunity To\n\nWrite, review, optimize SQL queries, views, and set stored/scheduled procedures to extract data\nDesign, develop, publish and maintain dashboards in Tableau or similar\nBe an MS Office Excel Ninja (Pivot tables, Power Pivot, formulas, VBA /Macros)\nTest, validate and enhance report output\nWork simultaneously across multiple data sources and reporting tools\nCreate scripts for importing, exporting, cleansing, analyzing, mapping and converting data\nAnalyze performance data and provide intelligent synthesis, interpretation and provide recommendations where appropriate\nBuild visualization data in charts, graphs and tables\n\n\n\nRequirements\n\n3 years+ of strong analytical skills with the ability to collect, organise, analyse, and disseminate significant amounts of information with attention to detail and accuracy\nAbility to learn new software and tools in an efficient manner\nCritical-thinking skills and the ability to identify trends in the data and come up with key takeaways and recommendations\nStrong interpersonal skills, oral communication skills, and problem solving abilities\nBA/BS/MS degree with strong academic record\n\n\n\nAdditional Experience In (but Not Required)\n\nR and/or Python scripting language\nUnderstanding or prior use of Cloud SQL and Cloud storage technology\n\n\nWhat can Astreya offer you?\n\nWorking with some of the biggest firms in the world as part of the Astreya delivery network\nEmployment in the fast growing IT space providing you with brilliant career options for years to come\nIntroduction to the new ways of working and awesome technologies\nCareer paths to help you establish where you want to go\nA company-wide mentoring program to advise you along the way\nOnline training courses through CBT-nuggets to upskill you\nPerformance management system to provide you with meaningful, actionable feedback\nDedicated management to provide you with a point of leadership and care\nInternal promotion focus. We love to build people from within.\nNumerous on-the-job perks\nPeer Recognition\nMarket competitive rates and benefits\nEducation\nBachelor's\n\nExperience: Associate (4 - 7 years)\n\nEmployment Type: Full-time\n\nWebsite: http://www.astreya.com\n\nIndustry: Staffing and Recruiting"},{"jobtitle":"Data Analyst","companyname":"Astreya","companyid":"","address":"","geo":"Sunnyvale, CA, US","postDate":"Nov 12 2018","views":"17","applicants":"6","employees":"","jobDetails":[{"level":"Associate","industry":["Construction","Information Technology & Services","Telecommunications"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\n## Skills\n\nData Analytics\nBig Data Query\nDATA VISUALIZATION\nSQL\nSCRIPTING\nDescription\n\nCompany *\n\n Astreya Partners are at the cusp of the new way of working. We provide IT Services and Managed Performance to some of the most exciting companies on the planet. Our delivery model helps our clients be Positively Productive by matching exceptional people to on-site teams delivering world class IT service. With professionals in over 35 countries and 70 cities around the world, we are a truly global company working with global clients.\n\nClient Overview\n\nThe Global Infrastructure Group (GIG) is responsible for end-to-end planning & delivery of the client's production compute infrastructure. This position will support theData Center Capacity Allocation and Planning team (GIG-CAP), which is responsible for long range datacenter capacity planning and the allocation of new capacity to product areas through quarterly capacity sales.\n\nPosition Overview\n\nWe are searching for a Data Analyst to join our Data Center Global team in Sunnyvale, CA. This is a full-time Mon-Fri, long-term need for our team. You would be working closely with Technical Program Managers and other Data Analysts to build on business reporting needs. This is a great fit for someone who has the ability and passion to lead data reporting projects utilizing project management and business operations skills. We need sound data analysis skills and someone who is passionate about data in an engineering space.\n\nResponsibilities\n\nQuerying and analyzing data center delivery performance data using tools and functions such as SQL, Dashboards, and Google spreadsheets.\nUse statistical methods to analyze data and generate useful business reports\nAuditing and maintaining capacity delivery performance reports\nResolving issues involving capacity delivery metrics derived for data center project delivery\nFollow-up with internal teams to solve internal data problems\nResolving minor issues regarding risk identification and management in relation to delivery of data center capacity with guidance from other team members\nManage multiple projects and effectively communicate status updates with Project Managers\nDetail and explain methodology used in analyses as requested by Project Managers\nGenerate various visual charts and reports pertaining to data center capacity\nDaily, weekly, and quarterly reports to support the data center operations needs\nCreation and maintenance of proprietary dashboards reports, utilizing internal tools such as PLX reports, SQL Scripting, and Google spreadsheets related to data center projects.\n\n\n\nQualifications\n\nBachelor’s Degree in Mathematics or Computer Engineering\n2-3yrs experience as a data analyst\n2-3yrs experience with Data Mining or Big Data Query\n1-2yrs experience in dashboard creation/maintenance\nExperience with: SQL, R, Tableau, Excel, (Python is a plus)\nAbility to createstrategies that optimize statistical efficiency and quality\nAbility to thrive in a faced paced and ever changing environment\nAttention to detail, organization, versatility is a must\n\n\nWhat can Astreya offer you?\n\nWorking with some of the biggest firms in the world as part of the Astreya delivery network\nEmployment in the fast growing IT space providing you with brilliant career options for years to come\nIntroduction to the new ways of working and awesome technologies\nCareer paths to help you establish where you want to go\nA company-wide mentoring program to advise you along the way\nOnline training courses through CBT-nuggets to upskill you\nPerformance management system to provide you with meaningful, actionable feedback\nDedicated management to provide you with a point of leadership and care\nInternal promotion focus. We love to build people from within.\nNumerous on-the-job perks\nPeer Recognition\nMarket competitive rates and benefits\nEducation\nBachelor's\nLanguages\nEnglish\n\nEmployment Type: Full-time\n\nWebsite: http://www.astreya.com\n\nIndustry: Staffing and Recruiting"},{"jobtitle":"Data Science Engineer","companyname":"Abercrombie & Fitch Co.","companyid":"5410","address":"","geo":"Columbus, Ohio Area","postDate":"Nov 12 2018","views":"53","applicants":"8","employees":"10001","jobDetails":[{"level":"Associate","industry":["Retail"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\n\nInformation Technology at Abercrombie & Fitch is fundamental to designing, sourcing, developing, and delivering fashion-forward merchandise to our customers. We are committed to implementing new strategic and systematic approaches to generate dynamic technology solutions for our growing business. As an expert on the Data Science team, a Data Engineer is responsible for setting up datasets for data mining, building predictive models, and building insight apps. Our Data Science focus surrounds core retail areas including planning, merchandising, inventory management and real estate. This position will work closely with other Data Science team members and our business partners.\n\nWhat will you be doing?\n\nUse data engineering skills to build mineable datasets.\nMine prepared datasets for initial descriptive or anomalous insights.\nBuild accurate and reproducible supervised & unsupervised models.\nWork with business owners to understand context within datasets & processes.\nDeliver insight to leadership, helping drive strategic business decisions.\nHypothesize, experiment & drive insight by any means necessary.\nDrive innovation by evaluating business processes and identifying data science solutions.\n\nWhat will you need to bring?\n\nA self-starter with a can-do attitude and resilient work ethic.\n3+ years’ experience with coding in Python (pandas, numpy, scipy, etc).\n1+ years’ experience with data warehousing/BI technologies including one or more of the following or similar: Hadoop (i.e. HBASE, Hive, MapReduce, Sqoop, Spark, etc), Netezza and/or DataStage (ETL).\nSome experience developing complex SQL and database views in a large data warehouse environment.\nKnowledge of web app development with high-level framework (like Flask or Shiny).\nExperience munging/wrangling data to create workable datasets from messy or noisy data sets.\nExperience with data processing techniques such as dimensionality reduction, normalization, imputation, and feature extraction.\nExperience developing reproducible prediction/forecasting model(s) such as deep learning, neural nets, decision trees, GLM, ARIMA, regression, etc.\nWell-practiced in version control with git. \nExperience with virtual environments or dockers for containerization.\n4-year degree in math, statistics, engineering, or information technology\n2+ years’ full-time work experience\n\nNice to Haves\n\nExperience with coding in R (dplyr, Shiny, ggplot, sparklr, etc)\nExperience with unguided problem formulation or hypothesis development.\nExperience with optimization techniques such as genetic algorithms, simulated annealing, etc.\nExperience with data visualization (with tools like matplotlib, Tableau, ggplot, plotly, etc).\nKnowledge of retail problems such as product classification, demand forecasting, supply chain optimization, etc.\nKnowledge of NLP and text analytics.\nKnowledge of web-scraping.\n\n\nDesired Skills and Experience\nAdditional Information\n\n\n\nABERCROMBIE & FITCH CO. IS AN EQUAL OPPORTUNITY / AFFIRMATIVE ACTION EMPLOYER © ABERCROMBIE & FITCH CO. 2012"},{"jobtitle":"Data Engineer Manager","companyname":"Harnham","companyid":"280603","address":"","geo":"San Francisco, California","postDate":"Nov 12 2018","views":"173","applicants":"49","employees":"51-200","jobDetails":[{"level":"Mid-Senior level","industry":["Information Technology & Services","Hospital & Health Care","Cosmetics"],"jobtype":"Full-time","function":["Engineering","Information Technology","Health Care Provider"]}],"description":"Job description\n\nData Engineer Manager\n\n\n\n\nSan Francisco Bay Area, CA\n\n\n\n\n$140,000 - $170,000 + Bonus + Equity\n\n\n\n\nAn opportunity has arisen to work as a Data Engineer Manager for a B2B SaaS Company! This is a chance to become the face of Data Engineering for a company that reaches millions of people worldwide. This is a fast-paced, cutting-edge role utilizing real-time streaming and Cloud technology with the opportunity to make a real impact!\n\n\n\n\nThe Company:\n\nOne of the top B2B SaaS company is looking for a Data Engineer Manager to join them in San Francisco. You will have data engineers reporting directly to you, working with Senior stakeholders and clients to build out the data infrastructure along with managing data analysis solutions. You will gain the opportunity to manage a team and be a part of the strategic discussions for engineering capabilities at the company. The company is looking for a Manager who exemplifies their core values, with the ability to engage with varying stakeholders. If you are a Senior Engineer or Manager, looking for a step up and the chance to really make an impact on businesses across the nation, this could be the role for you.\n\n\n\n\nThe Role:\n\nAs the Data Engineer Manager, your responsibilities will include:\n\nMentor and lead data engineers\nParticipate in strategic discussions for continued advancement of data infrastructure\nDesign, build and launch robust data pipelines and platform to ingest data and deployment of ML products/model\nDesign, build and launch highly scalable analytic tools\nPartner with other teams and intern stakeholder to gather requirements\n\n\n\n\nYour Skills & Experience:\n\nBachelor’s degree or high qualification in Computer Sciences or relevant degree\n3+ years of being a data engineer\nProduction level code in Python is a must\nPrior experience managing/leading a team \nStrong commercial experience in Spark, Kafka, or Kinesis is essential\nExperience with GCP or AWS is necessary\nStrong communication skills and teamwork\nDemonstrable ability to work with real-time data sets and reducing latency\n\n\n\n\nBenefits:\n\nSalary is $140,000 - $170,000, + bonus + equity\n\n\n\n\nHOW TO APPLY:\nPlease register your interest by sending your CV to Jason Nguyen () via the Apply link on this page.\n\n\n\n\nKEYWORDS\n\nData Engineer, Analytics, Spark, Python, Kafka, GCP, ETL, CRM"},{"jobtitle":"Data Engineer -","companyname":"Great American Insurance Company","companyid":"","address":"","geo":"Cincinnati, OH, US","postDate":"Nov 12 2018","views":"","applicants":"0","employees":"","jobDetails":[{"level":"Entry level","industry":["Information Technology & Services","Insurance","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nOverview\n\n Be Here. Be Great. Working for a leader in the insurance industry means opportunity for you. Great American Insurance Group, a member of American Financial Group, is a Fortune 500 company consistently recognized as a top place to work. We combine a \"small company\" culture where your ideas will be heard with \"big company\" expertise to help you succeed. With over 30 specialty property and casualty operations and a variety of financial services, there are always opportunities here to learn and grow.\n\n Great American's Predictive Analytics division is looking for a Data Engineer to join their growing and dynamic team.\n\nResponsibilities\n\nWork with project team and business stakeholders to determine data requirements for analysis\nAcquire and manipulate internal and external data to create clean reproducible data sets to facilitate predictive modeling\nBuild comprehensive data sets from various source systems including Hadoop, Oracle warehouses/marts, SQL Server, API’s, XLS, etc.\nWork with Information Technology to develop production solutions to bring predictive analytics to the enterprise\nResearch and evaluate new methods and tools to improve data gathering processes\nDesign and implement database structures for modeling solutions\nComplete descriptive analyses on various data sets\nResearch business unit queries regarding model outputs; this includes score shifts, missing items, reason messages, etc.\n\nQualifications\n\nSuperior organizational leadership skills.\nIntegrates multiple concepts across job functions with a goal of overall benefit to the organization.\nAbility to communicate, develop and leverage strategic business relationships across the organization and externally.\nRequires advanced technical and business knowledge.\nSelf-motivated team player who excels in a collaborative environment.\nContributes beyond job role and responsibilities.\nExcellent problem solving skills.\n\nRequired\n\nStrong SQL and database knowledge (Oracle preferred)\nUnderstanding of ETL techniques and processes\nStrong Excel knowledge/experience including Macros and VB development\nSOAP and REST web service experience testing and development\n\nPreferred\n\nPrevious experience in the P&C insurance industry\nReport development/design experience (Tableau / Cognos preferred)\nStrong Software Engineering practices developing enterprise applications – Java, Spring, XML, JDBC/JPA/Hibernate\nFamiliar with approximate string matching techniques (fuzzy matching)\nHadoop Development– interfacing with data stored in Hadoop environment (Familiar with technologies including: Hive, Pig, Spark, HDFS, Sqoop, Flume, HAWQ, Zeppelin)\nExperience with Informatica Data Quality Suite & Infomatica Data Integration Suite (PowerCenter)\nExperience in Linux\nExperience with R/R-Studio\nText Mining experience utilizing Python or R a plus\n\nEducation: Bachelor’s degree or higher in Information Technology, Informatics, Computer Science, Information Systems, or equivalent experience\n\n Experience: 0-6 years of relevant experience\n\n Connect With Us!\n\nNot ready to apply? Build your career profile here to !"},{"jobtitle":"Senior Data Engineer","companyname":"Accuity","companyid":"205627","address":"","geo":"New York, New York, United States","postDate":"Nov 12 2018","views":"10","applicants":"0","employees":"501-1000","jobDetails":[{"level":"Mid-Senior level","industry":["Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\n\nJob Purpose\n\n \n\nAs a SBS’ Data Engineer, you will conduct full lifecycle activities to include requirements analysis and design, develop analysis and reporting capabilities, and continuously monitor performance and quality control plans to identify improvements. You will also maintain, tune and explain our algorithmic scoring model to clients as it relates to entity resolution, enhanced due diligence of customers, and Know Your Customer (KYC) reviews.\n\n \n\nEssential Responsibilities\n\nProvide project management support on compliance related projects and initiatives to ensure they progress toward a common goal in alignment with agreed timelines.\n\nIdentify, analyze, and interpret trends or patterns in complex data sets\n\nUse labeled data to train and tune our scoring model for different data sets\n\nAssuring the integrity of project data, including data extraction, storage, manipulation, processing and analysis\n\nUtilize knowledge of data analysis, data engineering, and data science to develop and improve business processes\n\nUnderstand, plan, and communicate business priorities based on agreed upon commitments and available resources\n\nWork with team in creating and delivering ad-hoc reporting as well as automating ongoing reporting to meet client needs\n\nResponsible for maintaining and creating consistent data definitions as well as monitoring and auditing data quality\n\n\n\n\nQualifications/Skills\n\n\n\n\nExperience with data query and business intelligence, i.e., SQL, and/or statistical software required\nComfortable learning new systems/software applications\nSuperior quantitative and analytical skills including the ability to gather and interpret various types of data\nStrong problem solving skills.\nExcellent organizational skills.\nAbility to work with minimal supervision\nAbility to communicate effectively both verbally and in writing\n\n\n\n\nEducation/Experience\n\n\n\n\nMin. 5 yrs. exp. in MS SQL Server – A MUST\nProven experience managing several major projects involving diverse business, operations and technology groups\nExperience with Python, C#, or VBA a plus\n\n \n\nWorking Conditions\n\n\n\n\nAbility to travel as needed.\n\nWork is in an office environment, sustained posture in a seated positon for prolonged periods of time; works with computer equipment for prolonged periods of time.\n\nThis position reports typically reports to a supervisor.\n\n \n\n \n\n \n\n "},{"jobtitle":"Big Data and AI Engineer -","companyname":"Pfizer Canada Inc.","companyid":"","address":"","geo":"San Diego, CA, US","postDate":"Nov 12 2018","views":"15","applicants":"4","employees":"","jobDetails":[{"level":"Entry level","industry":["Biotechnology","Hospital & Health Care","Pharmaceuticals"],"jobtype":"Full-time","function":["Engineering","Information Technology"]}],"description":"Job description\nAs a member of the Pfizer Analytics Lab team, a component of Pfizer’s Business Technology organization, the Data Engineer will join a team of highly collaborative data scientists & engineers dedicated to leveraging data and advanced analytics to create a healthier world. This team member will contribute their dynamic perspective and knowledge to data engineering and advanced analytics, inspire colleagues and peers to develop and implement critical data driven solutions within Pfizer’s drug discovery efforts.\n\n Specifically, this group is focused on developing a set of capabilities designed to enable highly efficient exploration, experimentation, and rapid hypothesis generation based on internal, public, and commercially available datasets to continue supporting Pfizer’s data driven, forward thinking approach to data science\n\n Day-to-day, the Data Engineer will\n\nBuild services and tooling around “scraping” databases, loading logs, fetching data from external stores or APIs\nAutomate data consumption from other source systems, files etc.\nCollaborate with other engineering, cloud infrastructure , security and product management teams to understand requirements and develop highly scalable system designs and architecture\nIntegrate new data management technologies and software engineering tools into existing structures\nCreate custom software components and analytics applications\nEmploy a variety of languages and tools to marry systems together\nParticipate in the assessment of new technologies as well as identifying next-generation solution architectures.\nDevelop efficient analytic pipelines that include components related to data acquisition, exploratory analysis, feature engineering, modeling, and interactive storytelling.\nShared-ownership of advancing team's data engineering capabilities through the ability to implement and execute on state-of-the-art approaches\nCo-develop re-usable components that will serve as the foundation for a scalable approach for Pfizer’s analytic maturation\nPartner with other Business Technology teams to define and execute technology POCs using innovative technologies to advance Pfizer’s analytic capabilities\nDirectly engage with key business stake-holders (Director level)\nInformal leadership of project teams comprised of Associate/Sr. Associate level colleagues\n\nQualifications\n\nBachelor’s Degree inComputer Science, Operations Research, physics, applied mathematics, statistics required\n\n Advanced Degree in Computer Science, Operations Research, physics, applied mathematics, statistics or related field strongly preferred\n\n5 years’ experience working as a Data/ML Engineer\n3 years working with semi-structured and unstructured data\n2 years working in a cloud based ecosystem, preferably Amazon Web Services.\nAbility to thrive in a fast-paced multi-disciplinary environment; with the ability to effectively communicate with a diverse audience\nAbility to create technical examples, prototypes, and demonstrations based on rapidly changing data sets\nExcellent written and verbal communication skills\n\nTechnical Qualification\n\nProven experience in at least two of the three following categories:\n\n Data Science / Machine Learning\n\nExpertise with general-purpose statistics/machine learning algorithms and at least one of the following sub-disciplines: Natural Language Processing, Deep Learning, Network Analysis.\nExpertise with the implementation of algorithms within Python, R or Scala\nExpertise with model tuning, validation and evaluation\n\nData Engineering\n\nExpertise with SQL development, database administration and performance tuning\nExpertise with data manipulation and extraction using modern programming languages (Java, C++, C#, Python, Scala, Spark, etc.)\nExperience with Unix/Linux development – package management, knowledge of filesystems, performance monitoring/troubleshooting\nExperience with sourcing data from APIs; experience building APIs is a plus\nExperience with a variety of data stores for unstructured and columnar data as well as traditional database systems, for example, ElasticSearch, MongoDB, Cassandra, HBase, MySQL, Postgres and Vertica\n\nMachine Learning Engineering\n\nExperience building production implementations of data science and engineering pipelines\nBuilding and running high throughput real-time and batch data processing pipelines using Spark, Flink, Storm, Kafka or equivalent technologies\n\nEEO & Employment Eligibility\nPfizer is committed to equal opportunity in the terms and conditions of employment for all employees and job applicants without regard to race, color, religion, sex, sexual orientation, age, gender identity or gender expression, national origin, disability or veteran status. Pfizer also complies with all applicable national, state and local laws governing nondiscrimination in employment as well as work authorization and employment eligibility verification requirements of the Immigration and Nationality Act and IRCA. Pfizer is an E-Verify employer.\n\n Sunshine Act\nPfizer reports payments and other transfers of value to health care providers as required by federal and state transparency laws and implementing regulations. These laws and regulations require Pfizer to provide government agencies with information such as a health care provider’s name, address and the type of payments or other value received, generally for public disclosure. Subject to further legal review and statutory or regulatory clarification, which Pfizer intends to pursue, reimbursement of recruiting expenses for licensed physicians may constitute a reportable transfer of value under the federal transparency law commonly known as the Sunshine Act. Therefore, if you are a licensed physician who incurs recruiting expenses as a result of interviewing with Pfizer that we pay or reimburse, your name, address and the amount of payments made currently will be reported to the government. If you have questions regarding this matter, please do not hesitate to contact your Talent Acquisition representative.\n\nOther Job Details\n\nEligible for Employee Referral Bonus\nThis position can sit in La Jolla, CA, New York, NY or Collegeville, PA\n\nPfizer is an equal opportunity employer and complies with all applicable equal employment opportunity legislation in each jurisdiction in which it operates."},{"jobtitle":"Sr. Associate, Data Engineer, Financial Services with KPMG","companyname":"Not Just a Job Search","companyid":"18154965","address":"","geo":"Seattle, WA, US","postDate":"Nov 12 2018","views":"1","applicants":"0","employees":"2-10","jobDetails":[{"level":"Associate","industry":["Management Consulting","Financial Services","Accounting"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nThe position listed below is not with Not Just a Job Search but with KPMG\n\n Sr. Associate, Data Engineer, Financial Services **New York, New York** **Requisition #:** 37016 **Practice Area:** Business Support Services **Location:** Irvine, CA; Atlanta, GA; New York, NY; Philadelphia, PA; Seattle, WA Innovate. Collaborate. Shine. Lighthouse ? KPMG's Center of Excellence for Advanced Analytics ? has both applied data science, AI, and big data architecture capabilities. Here, you'll work with a diverse team of sophisticated data and analytics professionals to explore the solutions for clients in a platform-diverse environment. This means your ability to find answers is limited only by your creativity in leveraging a vast array of techniques and tools. Be a part of a high-energy, diverse, fast-paced, and innovative culture that delivers with the agility of a tech startup and the backing of a leading global consulting firm. For you, that translates into the chance to work on a wide range of projects ? covering technologies and solutions from AI to optimization ? and the power to have a real impact in the business world. So, bring your creativity and pioneering spirit to KPMG Lighthouse. KPMG is currently seeking a Sr. Associate to join our- Center of Excellence for Advanced Analytics to work with our Financial Services team. Responsibilities: + Rapidly prototype, develop, and optimize D&A implementations to tackle the BI/EDW/Big Data and Data Science needs for a variety of Fortune 1000 corporations and other major organizations + Design, develop and maintain D&A solutions on premise/cloud/KPMG-hosted/hybrid infrastructure; Be the team champion of some mainstream BI/EDW/Big Data toolsets like Tableau, Alteryx, Informatica, Pentaho, Er-Win, and Power Designer + Play the role of data owner in cross-disciplinary teams; Build logical/physical data models; Discover, profile, acquire, process, model and own data for the solutions + Implement data processing pipelines, data mining/science algorithms, and visualization engineering to help clients distill insights from rich data sources, including social media, news, internal/external documents, emails, financial data, client data and operational data + Actively be involved in research and experiment of leading/emerging BI/EDW/Big Data methodologies such as serverless data lake, AWS Redshift, Athena, Glue, GCP BigQuery, and MS PowerBI and apply them to real client solutions + Be the data engineering SME in the process for pursuing innovations, target solutions, and extendable platforms for Lighthouse, KPMG and client Qualifications: + Minimum of three years of relevant data engineering experience in related industries, preferably professional services; Experience and knowledge of RDBMS design, data modeling, MPP EDW system implementation; Have completed two plus production BI/EDW/Big data projects with the ability to communicate complex technical concepts to non-technical personals at all levels + Bachelor's Degree, Master's Degree or PhD from an accredited college/ university in Computer Science, Computer Engineering or related field + Hands-on experience and knowledge in: BI/EDW/Big Data toolsets (Tableau, Alteryx, Informatica, Pentaho, Er-Win, Power Designer); Mainstream cloud infrastructures (AWS, MS Azure and GCP; their D&A-related Microservices); Implementing data lake and serverless data lake; Proficient-level fluency of SQL + Hands-on experience of Linux/Unix/Windows/.NET; Market-leading fluency in several programming languages: Bash/ksh/PowerShell; Python/Perl/R; Ability to pick up and learn new technologies quickly + Hands-on experience and knowledge in distributed computing architecture, massive-parallel processing big data platforms like Hadoop, MapReduce, HDFS, Spark, Hive/Impala, H-Base/MongoDB/Casandra and Teradata/Netezza/Redshift + Ability to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package. KPMG is an affirmative action-equal opportunity employer. KPMG complies with all applicable federal, state and local laws regarding recruitment and hiring. All qualified applicants are considered for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other category protected by applicable federal, state or local laws. Thecontains further information regarding the firm's compliance with federal, state and local recruitment and hiring laws. No phone calls or agencies please. **Our Benefits** **Health** KPMG offers a range of medical insurance options to meet your needs as well as prescription drug coverage, health care flexible spending accounts, and dependent day care flexible spending accounts. **Personal Time Off (PTO)** Up to 30 PTO Days per year (depending on job classification/level/years of service). **Financial** + 401(k) and Pension Plans + Dependent Care Flexible Spending Account + Health Care Flexible Spending Account + Mortgage Assistance Program + HomeBenefits@Work Program + Hyatt Legal Plan * Benefits vary by employment status. Associated topics: call center, guest, healthcare, inside sales, insurance sales, insurance sales agent, outside sales, phone, sales agent, sales position"},{"jobtitle":"Data Analyst - Retail Operations -","companyname":"Carter’s, Inc.","companyid":"","address":"","geo":"Atlanta, GA, US","postDate":"Nov 12 2018","views":"6","applicants":"0","employees":"","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Retail","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nJob Description\n\nResponsible for strategic and analytical support of Workforce Management and cross-functional initiatives, including labor deployment, forecasting, payroll distribution, and in-store technology.\n\nDevelop advanced analytics and visualization tools to optimize the WFM application for increased sales, potential costs savings while providing a best-in-class customer experience. Example analyses include Dynamic Field performance, Cost / Benefit, Store Payroll impact, Forecasting sales, Revenue $, Gross Margin $ and % Impact, etc\nUtilize data for developing standardized reporting to provide comprehensive analytics into field performance from our current labor model. Provide insight and direction into changes needed to drive increased customer satisfaction\n\nPartner with various departments that drive workload within the store to collect data inputs to our labor model. Develop standardized reporting to provide comprehensive visibility into performance to our current labor model.\n\nDrive growth and customer satisfaction. Evaluate and contribute to store training for building business acumen and analyzing in-store KPIs (e.g. CTS, Conversion, AT), as well as initiatives to incentivize store teams\n\nAnalyze data surrounding new technologies to provide insight and store-level perspective to business leaders\n\nBe a champion for change management. Communication of past, current, and future expectations for the field is critical within the projects and initiatives of the organization\n\nDrive growth and customer satisfaction. Evaluate and contribute to store training for building business acumen and analyzing in-store KPIs (e.g. CTS, Conversion, AT), as well as initiatives to incentivize store teams\n\nProvide ongoing and ad hoc analytical support to the Retail Senior Leadership Team\n\nSupport Store Operations needs to the business accordingly with current processes and procedures.\n\nCommunication with external clients regarding store systems, including defect identification and issue resolution\n\nCommunicate with store and field leadership as needed to gather data to meet project research goals\n\nPresentation skills needed to review analytics with various business partners\n\n\nExperience And Skills\n\nBachelors degree in Business, Finance, Economics or a related field\n3+ years combined experience with Proficiency in advanced analytics and visualization tools preferred (SQL, Python, R)\n\nExcellent verbal and written communication skills. Possess a collaborative approach to problem-solving\n\nExcellent organizational and leadership skills, as well as strong customer focus and with strong ability to deal with ambiguity\n\nDetail-oriented, flexible, and able to work well under pressure in a fast paced environment\n\nAbility to be accurate with details, facts and supporting data. Ability to review data analysis, quantify results and recommend appropriate action based upon conclusions.\n\nComputer proficiency: Microsoft Office with a very strong skillset with Excel\n\n"},{"jobtitle":"Business Intelligence/ETL Specialist","companyname":"Guardian Life","companyid":"164085","address":"","geo":"New York, US-NY","postDate":"Nov 12 2018","views":"43","applicants":"8","employees":"5001-10000","jobDetails":[{"level":"Mid-Senior level","industry":["Insurance"],"jobtype":"Full-time","function":["Analyst","Information Technology"]}],"description":"Job description\n\nABOUT GUARDIAN\n Every day, Guardian gives 26 million Americans the security they deserve through our insurance and wealth management products and services. Since our founding in 1860, our long-term view has helped our customers prepare for whatever life brings whether starting a family, planning for the future or taking care of employees. Today, we’re a Fortune 250 mutual company and a leading provider of life, disability and other benefits for individuals, at the workplace and through government sponsored programs. The Guardian community of ~9000 employees and our network of over 2750 financial representatives is committed to serving with expertise when, where and how our clients need us. Our commitments rest on a strong financial foundation, which at year-end 2017 included $8.0 billion in capital and $1.6 billion in operating income. For more information, please visit guardianlife.com or follow us on Facebook, LinkedIn, Twitter and YouTube.\n Guardian is an equal opportunity employer. All qualified applicants will be considered for employment without regard to age, race, color, creed, religion, sex, affectional or sexual orientation, national origin, ancestry, marital status, disability, military or veteran status, or any other classification protected by applicable law.\nGuardian® is a registered trademark of the Guardian Life Insurance Company of AmericaPOSITION RESPONSIBILITIES\n Data Analytics/Reporting\nConduct data analysis in support of a variety of analytic solutions.\nCreate and produce forecasts, reports, ad hoc requests, dashboards, etc.\nPrepare monthly dashboard reports, identifying trends and presenting thoughtful, actionable solutions.\nDocument and train end users on reports and dashboards.\nETL/Data Blending\nTransform and utilize data in the data warehouse by creating, automating and documenting new tables in a post-load process. These new tables will transform the data from a transactional view to a more user-friendly business view. These tables can be used for direct usage for descriptive and predictive analytics\nApply the business rules on raw data in the data warehouse, data cleansing, data blending to bring data into the shape for profiling, dashboards, insights via project basis.\nApplying masking routine on the personally identifiable/sensitive data when necessary\nContinuously apply Data Governance processes including monitoring of the data quality with appropriate business areas\nProvide data modeling, mining, pattern analysis, anomaly detection and data visualization to address customer needs with front-end tools\nDocumenting the data blending process along with the specifications and workflow/data lineage for future automation usage\nMaintaining/adding to already made data dictionary for predictive analytics data profiling/modeling and/or any downstream usage\nPartners with IT, Database Administrators and business owners to ensure optimized data transformation and efficiencies.\nDevelop relationships with business team members by being proactive, displaying an increasing understanding of the business processes and by recommending innovative solutions\n\n\nDesired Skills and Experience\n\nCANDIDATE QUALIFICATIONS\n\nOverall Qualifications:\n\nBachelor’s Degree in Computer Science / Engineering, IT, or Data Analytics from an accredited university\nHands-on proficiency in one or more scripting languages (e.g., Java, Python, Scala, R, Shell scripting)\n5+ years’ experience working with databases and hands-on proficiency in SQL\n5+ years of relevant experience in ETL or data analyst role, including data mining and/or ETL development\n2+ years’ experience developing management reporting dashboards using Tableau\nDatabase Development – Hadoop\nExperience with relational databases: Sybase ASE, SQL Server, Oracle, MySQL\nExcellent written and verbal communication skills\n\n\nEvery day, Guardian gives 26 million Americans the security they deserve through our insurance and wealth management products and services. Since our founding in 1860, our long-term view has helped our customers prepare for whatever life brings whether starting a family, planning for the future or taking care of employees. Today, we’re a Fortune 250 mutual company and a leading provider of life, disability and other benefits for individuals, at the workplace and through government sponsored programs. The Guardian community of ~9000 employees and our network of over 2750 financial representatives is committed to serving with expertise when, where and how our clients need us. Our commitments rest on a strong financial foundation, which at year-end 2017 included $8.0 billion in capital and $1.6 billion in operating income. For more information, please visit guardianlife.com or follow us on Facebook, LinkedIn, Twitter and YouTube.\n\n Guardian® is a registered trademark of the Guardian Life Insurance Company of America.\n\n Guardian is an equal opportunity employer. All qualified applicants will be considered for employment without regard to age, race, color, creed, religion, sex, affectional or sexual orientation, national origin, ancestry, marital status, disability, military or veteran status, or any other classification protected by applicable law.\n Guardian2018"},{"jobtitle":"Mantas Senior Business & Data Analyst","companyname":"Barclays","companyid":"1426","address":"","geo":"Whippany, NJ, US","postDate":"Nov 12 2018","views":"1","applicants":"0","employees":"10001","jobDetails":[{"level":"","industry":["Banking","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nJob Title: Mantas Senior Business & Data Analyst\n\n Location: 400 Jefferson Park, Whippany, NJ\n\nAbout Us\n\nBarclays is a transatlantic consumer, corporate and investment bank offering products and services across personal, corporate and investment banking, credit cards and wealth management, with a strong presence in our two home markets of the UK and the US. Our goal is to become the bank of choice by providing superior services to customers and clients and supporting our stakeholders via a commercially successful business that generates long-term sustainable returns.\n\nAbout Barclays In The US\n\nBarclays offers corporate and investment banking and credit card services in the US. Our 10,000 US colleagues are located in offices across the country, with headquarters in New York City. In 2017, Barclays announced plans to create a world-class campus in Whippany, New Jersey, for our Technology, Operations and Functional teams in the US. Other principal locations include Delaware, Nevada, Ohio and Maine.\n\nAbout Compliance Technology\n\nThe Compliance Technology delivers Business Change and Technology transformation to protect the bank, its customers, and its employees, as well as society at large, from the negative effects of Financial Crime. We manage the delivery of transformation, and provide oversight and quality assurance for the implementation of the Financial Crime Target Operating Model (TOM) across the Bank in partnership with Business clusters. We act as the central hub for technical and strategic delivery for Financial Crime Business Change and Technology delivery. We manage the relationships and business demand by understanding the needs of our stakeholders in Financial Crime and across the Bank, and implementing the required transformation to deliver against Barclays’ Financial Crime agenda. Our dedicated Financial Crime ‘Run the Bank’ team is fully aligned to the business’ operations and needs and their focus is to protect the ‘production environment’, manage all Financial Crime applications and services in line with agreed business boundaries and SLAs, and provide full transparency to business owners on application performance and risks.\n\nAbout The Transaction Monitoring Program\n\nThe Financial Crime Transformation Transaction Monitoring Program consists of a number of Financial Crime Transaction Monitoring projects, such as Mantas Correspondent Banking, Actimize SAM (Suspicious Activity Monitoring), Fortent (this list is not meant to be inclusive but illustrative). This program is a highly visible delivery vehicle supporting the Financial Crime function and is critical as Barclays is embarking on a multi-year transformation journey across the 3 lines of defense. The Transaction Monitoring area plays an important role in this strategy.\n\n Overall Purpose of role\n\nDevelop Oracle SQL and PL/SQL components to build custom ETL solutions extending the Mantas transaction monitoring platform.\nPerform development in Core JAVA and J2EE technologies to build backend processes and GUI utility applications.\nConvert functional specifications into technical specifications for the upcoming business requirements.\nEngage in developing, maintaining, modifying and documenting various applications specs within the project teams & comply with Barclays policies and procedures.\nCoordinate with ORACLE team to install and configure Mantas components and scenarios.\nDesign and develop custom applications based on MANTAS/OFSAA data model\nPerform OFSAA case management user interface code changes and Case workflow configurations\nPerform necessary upgrades of various system components to adhere to the technology standards of the firm.\nWork with UAT testing team and RTB to provide necessary UAT and L3 support whenever required.\nImplement projects based on regulatory requirements and create detailed technical plans for production releases\nDesign and develop new dashboards and reports required for AML investigations\nDeputize for project manager on need basis\n\nYour Role\n\nInteract with Business and external teams to gather the project requirements\nEvaluate user needs and software requirements to complete feasibility of design within time and cost constraints\nConvert functional specifications into technical specifications for the upcoming business requirements.\nPerform coding and unit testing for various jurisdictions of the Mantas transaction monitoring platform\nPerform development activities using the Oracle database, Informatica, Unix shell scripting and JAVA / J2EE technologies\nPerform OFSAA case management user interface code changes and Case workflow configurations\nDesign custom application components for Mantas and other Compliance products and conduct code reviews\nPrepare testing certification strategy & execution plan, perform system testing and assist business users in UAT.\nPerform data modeling and facilitate data acquisition from upstream applications ensuring data accuracy and completeness\nDevelop, customize and optimize MANTAS scenario rational changes and threshold changes\nPerform data analysis, data mining and data migration activities & write reporting queries\nCo-ordinate with various teams to plan, setup and maintain the capacity of database and application infrastructure\n\nStakeholder Management and Leadership\n\nBuild and maintain effective relationships with internal and external stakeholders at peer and senior levels by interacting with colleagues at all levels in a peer-like manner, using both formal and informal communications channels to understand their issues, help identify areas and opportunities for improvement;\nAbility to build strong networks and use established relationships to collect, disseminate and study information; establish/communicate direction/strategy and secure buy-in for desired purpose\nStrong interpersonal and influencing skills to achieve goals without direct control over resources;\nCommunicate to all stakeholders (including Senior Management) on a timely basis in a clear way to facilitate, coordinate, and arbitrate cross-functional macro level topics with key stakeholders;\nGlobal mindset & respect of time zones and other cultures;\nAbility to network with different people and groups and develop solid working relationships across diverse teams and geographies.\n\nDecision-making and Problem Solving\n\nIdentifies the key issues in a complex situation, and comes to the heart of the problem quickly;\nGathers relevant information before making a determination\nConsiders positive and negative impacts of decisions prior to making them;\nTakes decisions with an eye to the impact on others and on the organization;\nProposes a course of action or makes a recommendation based on all available information;\nChecks assumptions against facts;\nDetermines that the actions proposed will satisfy the expressed and underlying needs for the decision;\n\nBasic Qualifications/Skills (Must Be Quantifiable)\n\n12+ years of experience in designing ETL solutions using data warehousing tools like Informatica, etc\n12+ years of experience in Oracle database technologies such as SQL server, Oracle PL/SQL or similar databases.\n6+ years of experience of working with the Compliance function within an Investment Bank\n5+ years of hands on experience in JAVA / J2EE and related technologies such as Core JAVA, Spring, HTML, Tomcat / Weblogic.\n5 +years of experience in Mantas/OFSAA or other Compliance / Financial Crime platforms such as Actimize, Norkom.\n4 year college degree in Computer Science or related subject.\n\nPreferred Qualifications/Skills\n\nExpert in MANTAS Developer’s toolkit, Scenario Manager and Scenario wizard\nKnowledge of MANTAS Data ingestion processes (both JAVA and ETL based ingestions)\nProficient in integrating customizations to MANTAS/OFSAA applications\nExpert in ETL, OLAP, OLTP, dimension modeling techniques\nProficient in Design and Development of Data virtualization for Reporting tools\nExperience in designing user Interface mock-ups & Sand Box reasoning\nExperience in advanced OBIEE dashboards and reports development\nAbility to understand business requirements and develop software solutions.\nStrong data reasoning skills and ability to present the findings to the business users.\nDemonstrable ability to communicate and build relationships with members of the business and technology communities.\nQuick learner; strong analytical and problem-solving skills, with the ability to deal with numerous tasks simultaneously and with frequently changing priorities.\nMust be independent and creative in approach to problems and issues; assertive, tenacious, proactive\nExcellent oral and written communication skills, particularly in documenting requirements and specifications.\nExcellent MS Office skills (esp. Visio, Excel, Word) and presentation skills (PowerPoint).\nWorking knowledge of project scheduling, estimation and tracking\n\nRisk and Control Objective\n\n All Barclays colleagues have to ensure that all activities and duties are carried out in full compliance with regulatory requirements, Enterprise Wide Risk Management Framework and internal Barclays Policies and Policy Standards.\n\n Your Application\n\n To be considered for this role, click on the apply button now.\n\n Barclays Values & Diversity\n\n Dynamic working gives everyone at Barclays the opportunity to integrate professional and personal lives, if you have a need for flexibility then please discuss this with the hiring manager. We are an equal opportunity employer and we are opposed to discrimination on any grounds. It is the policy of Barclays to ensure equal employment opportunity without discrimination or harassment on the basis of race, color, creed, religion, national origin, or citizenship status, age, sex, sexual orientation, gender identity or expression, marital or domestic/civil partnership status, disability, veteran status, genetic information, or any other basis protected by law.\n\nPrimary Location\n\nUS-New Jersey-Whippany\n\nJob Type\n\nPermanent/Regular\n\nPosting Range\n\n7 Nov 2018"},{"jobtitle":"Sr. Data Analyst- Revenue Analytics","companyname":"RentPath, LLC","companyid":"","address":"","geo":"Atlanta, GA, US","postDate":"Nov 12 2018","views":"4","applicants":"1","employees":"","jobDetails":[{"level":"Associate","industry":["Online Media","Internet","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nJoin a winning team. Become a part of something meaningful\n\n Looking to join a company in the midst of a digital transformation where the consumer is king and talent, technology and data are our greatest resources?\n\n Keep reading to see if this opportunity is of interest to you!\n\n RentPath is looking for a Sr. Analyst Revenue Analytics to be a part of the enterprise FP&A organization and work closely with Sales, Sales Ops, IT and Finance across all levels of management. You will be responsible for designing and building a best-in-class revenue analytics capabilities that will inform and enable strategic decision support through data and fact-based analysis. This is a fantastic opportunity for an experienced professional to join a dynamic, high-growth environment and accelerate their development.\n\n RentPath is a leading digital marketplace connecting millions of consumers with apartments, condos and houses for rent through its network of websites and mobile apps. RentPath’s category-leading brands include Apartment Guide, Rent.com, Lovely, Rentals.com, and RentalHouses.com.\n\n A Day in the Life\n\nImagine this as your day to day role and responsibilities……\n\nDrive revenue KPIs analyzing key metrics and proactively digging into the details to develop insights about drivers of performance, customer behavior (churn, retention, price sensitivity, etc.) and associated risks & opportunities\nCollaborate with Sales & B2B Marketing with product level revenue & subscriber analytics\nDrive reporting of and insights from key revenue performance metrics & communicate revenue performance & metrics effectively to business leadership\nConduct actionable data analytics on critical projects and investments such as new product innovation, sales initiatives, etc.\nDevelop reporting tools and dashboards to support day-to-day revenue management. Be strong at data assimilation, visualization and leverage and improve current systems to increase productivity and accuracy.\nTake ownership role for data accuracy and integrity across the reporting interfaces. Changes impacting the data & definitions resulting from changes in products & processes (Sales, Billing, Accounting, etc.) will have to be tracked and reflected real-time across all reporting tools.\n\nWhat We Need From You\n\nExperience with digital media businesses and ability to demonstrate a strong grasp of the fundamentals of subscription business model preferred\nHigh proficiency in Excel, relational databases and building decision support models\nSelf-starter that adapts well to change in a fast-paced, dynamic workplace and works well in cross-functional teams/projects\nAnalytical prowess, strategic thinking and detail-oriented\nGreat attitude, willingness to perform and get things done\nBachelor’s degree in Finance, Statistics or Economics preferred. MBA or other advanced degrees a plus.\nAbility to work with IT / Business Service team directly for process improvement projects\nDemonstrate the ability to work on and prioritize multiple projects while also meeting goals and deadlines.\nStrong problem solving, planning, quality control, adaptability and customer service skills\nSolid verbal and written communication skills with all levels of management. Ability to communicate complex information in a clear and concise manner.\n\nStill interested? Then let’s see your resume…..just upload it and a Recruiter will check it out as soon as possible.\n\n Why Choose RentPath ?\n\nWe’re a place where you can make an important difference, from day one. You’ll have the opportunity to grow and build, both professionally and in the communities we serve. You’ll work with smart, diverse, and unpretentiouspeople, as we help renters find and enjoy their ideal home. In fact, we consider ourselves a very well-funded start-up that also has more than 40 years in the industry and strong financial performance. The challenge of leading our digital transformation has attracted talent from leading companies like Google, Microsoft, and Expedia. Will you be next?\n\n One of our unique strengths is the diversity of our community. We want to treat each associate fairly and provide equal employment opportunities regardless of a person’s race, color, religion, gender or gender identity, sexual orientation, age, marital status, national origin, veteran or disability status, or any other characteristic.\n\nprovided by Dice Power BI, Data Mining, SQL, Python,Excel, Dashboarding KPI, Data Visualization\n"},{"jobtitle":"Lead Specialist - Big Data Analyst","companyname":"Energy Transfer","companyid":"","address":"","geo":"Houston, TX, US","postDate":"Nov 12 2018","views":"8","applicants":"0","employees":"","jobDetails":[{"level":"Associate","industry":["Construction","Oil & Energy","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nEnergy Transfer Partners - We are one of the largest MasterLimited Partnerships with one of the most diversified portfolios of energyassets in the United States, totaling more than 71,000 miles of natural gas,crude oil, natural gas liquids and refined products pipelines, traversing 36states with associated terminalling, storage and fractionation facilities.\n\nEssential Functions\n\nWork with the BI team to enhance, augment, and shape our Data Strategy with new data sources from inside and outside the organization, and new technologies and methodologies.\nDevelop and implement creative use cases for our data and the latest BI technologies including IOT, Big Data, Machine Learning, and AI.\nTrain and spread BIG Data methodologies and technologies to the team and the rest of the organization.\nLeverage functional/business requirements to design and develop end-to-end solutions including ETL, governance, presentation, data mining, machine learning as may be needed.\nDevelop methods to deliver BI governance metrics (i.e. usage, memory, space, queries, etc.)\nWork with the business users to capture the business/functional requirements\nLead prototype efforts in various BI tools for capability assessment and demonstrations.\nContribute toward evolving company's analytical self-service/ad hoc reporting capabilities using existing or future toolsets.\nPrepare appropriate documentation and ensure that new functionality is properly transitioned to reporting users.\nWork with business partners and internal staff on resolving platform production defects and performance issues.\nPropose optimal ways to address business demands for BI with a goal of delivering maximum overall value for BI investments.\nParticipate and develop BI landscape strategy including optimal setup to support multiple/parallel project deliverables.\nMaintain strong and effective working relationships with SAP Applications owners, IT Infrastructure team and OS/Network Team.\nDevelop, document, and adhere to standard procedures and best practices.\nEnsure requirements are being met in accordance with corporate compliance standards.\n\nEssential Requirements\n\nAt least 5 years of experience developing BI solutions within the Microsoft BI Stack (MS SQL Server/SSIS/SSAS/SSRS).\nAt least 2 years of relevant industry experience such as crude, natural gas, NGL storage and/or other energy transportation.\nAt least 2 years of direct experience or close working relationship with DevOps engineering and previous big data experience with multiple programming languages and technologies.\nBachelor's degree from an accredited college or university in Computer Science, Computer Engineering, or a related field.\nFluency in MS SQL query language, ability to write stored procedures, views, indexes, etc.\nExperience with consuming and developing REST API, JSON, XML, and/or JavaScript.\nUnderstanding of cloud and distributed systems principles, including load balancing, networks, scaling, in-memory vs. disk.\nExperience with large-scale, big data methods, such as Hadoop, Spark, Hive, Impala, or Storm.\nProficient in developing and executing test scenarios including regression testing.\nStrong tracking, coordination and project planning skills\nAbility to identify and implement programing logic and/or application improvements\nMust be able to work on multiple simultaneous tasks with limited supervision\nQuick learner, motivated self-starter, team player\nExcellent customer service, interpersonal, verbal and written communication, and team collaboration skills\nAble to follow change management procedures and internal guidelines\nStrong time-management skills, initiative, commitment, and ability to work under pressure to meet tight deadlines while maintaining high quality standards and best practices.\nExcellent analytical and problem solving skills, strong organizational skills, attention to detail\n\nPreferred Skills\n\nExperience warehousing or reporting against SCADA or other IOT environments.\nConfidence in several programming languages such as R, Python, Scala, or Java, with the ability to pick up new languages and technologies quickly.\nData Science/Advanced Analytics (ex: Predictive Analytics, Text Analytics, and analysis of unstructured data).\nVisualization experience with Tableau or Power BI.\nData modeling with SAP BW on HANA with HANA Studio and HANA Views.\nITIL Certification or experience using Remedy application is a plus.\nSystem administration skills with SSRS, Tableau, or Business Objects.\n\nSpecial Characteristics/Job Requirements\n\nParticipate in a weekly on-call rotation several times a year.\n\nEqual Opportunity Employer/ Disability/Vet\n\n SDL2017\n\n"},{"jobtitle":"Data Engineer","companyname":"DBI Staffing","companyid":"62563","address":"","geo":"Greater New York City Area","postDate":"Nov 12 2018","views":"225","applicants":"201","employees":"11-50","jobDetails":[{"level":"Associate","industry":["Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nThe ideal candidate will have an extensive knowledge of statistics and quantitative finance, with a focus on their application to fixed income markets.\nExperience in a programming language (Python, Java, C++, or R) is another key consideration.\nThe position is part of the Applied Research & Development team, supporting the Pricing and Analytics business.\nThe primary responsibility for this role within the organization will be to contribute to R&D projects associated with the creation or validation of new product development initiatives and to support the model development of Liquidity Indicators.\nThe candidate must also possess the ability to respond to time-critical inquiries from management and must be able to engage with market participants on various aspects of our models and applicability of the service to suit their business needs.\nThe flexibility to adapt to changing requirements is also essential.\n\n\n\n\nDuties and Responsibilities\n\nGather data from various sources (SQL, Oracle or CSV files) and develop models using statistical packages found in R, Python or Excel/VBA\nCollaborating with a team of skilled quantitative analysts and data scientists supporting our business development efforts with an exciting new set of products and services\nApply statistical and machine learning models to develop practical solutions supporting the financial marketplace\nWork cross-functionally across the organization, effectively collaborating and communicating, to achieve business objectives\nSupport sales and product teams by discussing models and methodology with clients\nContribute to the shared learning and growth of the R&D organization, leveraging creativity and discipline to efficiently solve critical business problems\nLead initiatives where independent research and modeling is required to pitch concepts to a broader group\n\n\n\n\nKnowledge and Experience\n\nBachelor’s Degree Required\nExperience in modeling behavior of financial instruments by either statistical and/or machine learning methods.\nExcellent analytical, verbal and written communication skills\nProficient in practical applications of statistical methods and quantitative methods\nExperience retrieving data from structured databases (SQL/Oracle) and flat csv files\nProficient in a general-purpose programming language such as Python or Java with the ability to learn other languages as needed\nComprehensive understanding of financial markets, valuation concepts and financial products\nIndependent self-starter while being a team player with the willingness to take direction from management\nCapable of working the hours necessary to achieve daily objectives\nStrong communication and analytical skills to clearly express ideas and specify product or model requirements when collaborating with our development teams"},{"jobtitle":"Sr. Data Analyst with FitBit","companyname":"Not Just a Job Search","companyid":"18154965","address":"","geo":"San Francisco, CA, US","postDate":"Nov 12 2018","views":"7","applicants":"0","employees":"2-10","jobDetails":[{"level":"Associate","industry":["Computer Software","Internet","Health, Wellness & Fitness"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nThe position listed below is not with Not Just a Job Search but with FitBit\n\n At Fitbit, our mission is to help people lead healthier, more active lives by empowering them with data, inspiration and guidance to reach their goals. We started our journey in 2007?as a team of two with one big idea. Since then, we've grown to over 1,500 employees, sold over 60mm devices, and built a health and fitness community across the globe. In fact, the Fitbit Community has taken enough steps to walk from the Sun to Pluto! Offering award-winning products, a top-rated mobile app and an easy-to-use online dashboard, Fitbit provides personalized experiences that help our users reach their goals. With a reenergized focus on innovative devices, interactive experiences, and enterprise health we are transforming the way consumers and businesses see health & fitness. From your first steps as a Fitbitter, you will be at the forefront of developing new products. Our culture combines the spirit of startup with the perks of being public. We offer a competitive benefits package and amazing perks like unlimited snacks, Friday happy hours, onsite workout classes, and a strong focus on a healthy work-life balance. As part of our team, you'll have the opportunity to grow your career, contribute your ideas to life-changing products and services, and?above all?have fun doing it. Fitbit's HQ campus is located in the heart of San Francisco with office locations in Boston, San Diego and around the world. Think you've found your fit? What You'll Work On: Apply your expertise in quantitative analysis, data mining and presentation of data to see beyond the numbers and understand how our users interact with our core/business products. Partner with Customer Support, Research, Product Specialist, Community, Social and Engineering teams to identify trends and opportunities Inform, influence and support our product decisions using insight on customer experience Designing and evaluating experiments monitoring key metrics, understanding root cause of changes in metrics Building and analyzing dashboards and reports Understanding the customer support ecosystems, user behaviors, and long term trends Identify levers to help move key metrics Evaluating and identifying metrics Building models of user behaviors for analysis Required Skills 5+ years experience in an analytics/data science role Bachelors, Masters degree in quantitative discipline (Economics, Finance, Statistics, Engineering, Computer Science or MBA with emphasis in analytics) Proficient at analyzing large multi-dimensional data sets using data/statistical tools such as R, Python, SAS, SPSS and Excel. Experience utilizing tools like Tableau, HighCharts, Qlikview Linux skills (shell scripting, Java, PHP, etc.) A strong passion for data, charts, analysis, trends, and evangelizing data usage An appreciation for Fitbit's products Ability to draw conclusion from data and provide recommendations Presentation skills including creating Keynote/PowerPoint presentations Fitbit is proud to be an equal opportunity employer. We recruit, hire, train, promote, pay, and administer all personnel actions without regard to race, color, ancestry, national origin, citizenship, religion, age, sex (including pregnancy, childbirth, and medical conditions related to pregnancy, childbirth, or breastfeeding), sex stereotyping (including assumptions about a person's appearance or behavior, gender roles, gender expression, or gender identity), sexual orientation, gender, gender identity, gender expression, marital status, medical condition, mental or physical disability, military or veteran status, genetic information or other statuses protected by law. We interpret these protected statuses broadly to include both the actual status and any perceptions and assumptions made regarding these statuses. San Francisco applicants: Pursuant to the San Francisco Fair Chance Ordinance Fitbit will consider for employment qualified applicants with arrest and conviction records.SDL2017"},{"jobtitle":"Data Analyst with Calance US","companyname":"Not Just a Job Search","companyid":"18154965","address":"","geo":"Torrance, CA, US","postDate":"Nov 12 2018","views":"10","applicants":"1","employees":"2-10","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Computer Software","Staffing & Recruiting"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nThe position listed below is not with Not Just a Job Search but with Calance US\n\n FOR IMMEDIATE DETAILS ABOUT THIS POSITION, contact ANY of us direct, referencing the job# below: Kindest Regards: RASHMI KHULLAR: MICHELL CASEY: SUMIT KUMAR: JOANNE SMITH: KIANA AREVALO: E M A I L: ===================== ===================== ** We will NOT accept 3rd Party/Corp to Corp (C2C) consultants ** Position: Data Analyst JOB REF#: 15565 Duration: 12+ Months (On-going Contract) Location: Torrance, CA 90501 (on-site only) Rate: Open, depends on exp level Calance is a 1st tier vendor with 35 consultants working on-site for this global client. Although this is a contract role, the average consultant has been on project between 5-7 years. All work will be performed on-site and you MUST be available for a face to face interviews. RESPONSIBILITIES INCLUDE: Work with stakeholders to identify opportunities for leveraging company data to drive business solutions. Analyze data from company databases to drive optimization and improvement of customer experience, marketing techniques and business strategies. Assess the effectiveness and accuracy of new data sources and data gathering/cleansing techniques. Develop custom data models and algorithms to apply to data sets. Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes. Coordinate with different functional teams to implement models and monitor outcomes. Develop processes and tools to monitor and analyze model performance and data accuracy. REQUIRED SKILLS/EXPERIENCE: (Resume must reflect this experience) 5+ years as a Data Analyst, manipulating data sets and building statistical models and software/tools. Experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, and/or social network analysis. Experience database querying, using statistical computer languages: R, Python, and/or SQL. Experience using web services: Redshift, S3, Spark, and/or DigitalOcean. Experience creating and using machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, and/or neural networks. Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, and/or Facebook Insights Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, and/or MySQL Experience visualizing/presenting data for stakeholders using: Periscope, Business Objects, D3, and/or ggplot. Experience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets. Experience working with and creating data architectures. Worked with a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks. Advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications. Familiar with a variety of the field's concepts, practices, and procedures. Relies on extensive experience and judgment to plan and accomplish goals. Must have a stable work history, working in a similar role Must have EXCELLENT oral communication skills Education: Bachelor's degree; Math, Economics, Statistics, Management Information Systems or Computer Science preferred. Other Must Have's: Must reside LOCALLY (S. California) area MUST be available for a face to face interview W2-Hourly Benefits Offerings: H1 Transfers/Green Card processing is available (No C2C/3rd Party Agencies) Medical/Dental/Vision benefits (HMO/PPO) 401K Retirement program Paid Bi-Weekly/Direct Deposit Flex Spending Plan Voluntary Life, AD&D, STD or LTD plans Recruiter: Calance Recruiters Phone: - provided by DiceData Analyst, statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, and/or social network analysis, R, Python, and/or SQL., web services: Redshift, S3, Spark, DigitalOcean, analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc."},{"jobtitle":"Data Analyst - Data Insights","companyname":"Apple","companyid":"162479","address":"","geo":"Cupertino, CA, US","postDate":"Nov 12 2018","views":"51","applicants":"15","employees":"10001","jobDetails":[{"level":"","industry":["Consumer Electronics"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nSummary\n\nPosted: Nov 7, 2018\n\nWeekly Hours: 40\n\nRole Number: 200006356\n\nAt Apple, we work every single day to create products that enrich people’s lives. Our Advertising Platforms group makes it possible for people around the world to easily access informative and imaginative content on their devices while helping publishers and developers promote and monetize their work. Our technology and services power advertising in Apple News and Search Ads in the App Store. Our platforms are highly performant, deployed at scale, and set new standards for enabling effective advertising while protecting user privacy. Our technology and services power advertising in Apple News and Search Ads in the App Store. Our platforms are highly performant, deployed at scale, and set new standards for enabling effective advertising while protecting user privacy. The Ad Platforms Data Insights team is seeking an analyst to join in developing the next generation of analytical solutions working with Sales, Marketing, Product, Engineering, and Leadership. In this role you will work as a key member of a data-centric team to drive the exploration, analysis, development, execution, and measurement of analytical solutions that are critical to running the business. You’ll be responsible for turning the huge amounts of data generated by user searches, app content, and App Store context into business insights that improve the customer experience for the end-user as well as drive discovery and productivity for app developers. A successful candidate will have experience in applied research with expertise in pattern mining, anomaly detection, text analytics, predictive modeling, classification, and optimization. The role requires both a broad knowledge of existing data mining algorithms and creativity to invent and customize when necessary. You'll dig in and get your hands dirty. The theory behind the techniques are just the beginning. You'll be working on projects where practical applications of these approaches get applied in real-world scenarios. Successful analytics teams involve data scientists and data engineers working hand in hand to build insightful and efficient solutions. In your role, you will be a key player in a multi-functional team that delivers insights that have direct and measurable impact.\n\nKey Qualifications\n\n2-5 years of recent experience in a business analyst or data analyst role. Preferably experience in the digital advertising industry or related field\nBachelor of Arts or Science in a quantitative field of study including business, statistics, math, economics or a related discipline; graduate degree a plus\nAbility to operate comfortably and effectively in a fast-paced, highly cross-functional, rapidly changing environment.\nProgramming skills in SQL required; Python, or Java/Scala preferred\nExperience developing data visualizations, dashboards, and reporting in Tableau or a similar reporting tool\nComfortable with advanced analytics tools such as Pandas, R, and Spark\nExperience in exploratory data analysis and familiarity with advanced quantitative analysis and statistical techniques\nComfortable working with modern data technologies. Familiarity with database modeling and data warehousing principles\nAbility to work effectively with data science and engineering partners to meet the data needs of the business, translating business needs into analytical requirements\nExperience engaging with the business and leadership on problem definition\nAbility to communicate the results of analyses in a clear and effective manner with product and leadership teams to influence the overall strategy of the product\nFamiliarity with data science exploration, analysis, feature selection, model development, and evaluation a plus\nFamiliarity with agile methods such as scrum\n\n\nDescription\n\nSupport Product Marketing, Sales, and/or the Executive Team with analytics for product performance and customer insight Empower the global Sales, Marketing, or Product teams with insights to inform and fulfill their strategic objectives and goals for every fiscal quarter Quantify the impact of product, sales, and marketing initiatives on customer success and future behavior Responsible for business analytics work through all phases, including data quality, data analysis, data visualization, and presentation of results and deliverables Monitor usage metrics, understanding business-based explanations for large scale trends and patterns in customer lifecycle behavior Develop reusable analytics and assets working closely with Data Technology team to ensure scalability and industrialization of analytical outputs\n\nEducation & Experience\n\nBS\n\n"},{"jobtitle":"Sr. Associate, Data Engineer, Financial Services with KPMG","companyname":"KPMG","companyid":"","address":"","geo":"Seattle, WA, US","postDate":"Nov 12 2018","views":"","applicants":"0","employees":"","jobDetails":[{"level":"Associate","industry":["Management Consulting","Financial Services","Accounting"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nThe position listed below is not with Not Just a Job Search but with KPMG\n\n Sr. Associate, Data Engineer, Financial Services **New York, New York** **Requisition #:** 37016 **Practice Area:** Business Support Services **Location:** Irvine, CA; Atlanta, GA; New York, NY; Philadelphia, PA; Seattle, WA Innovate. Collaborate. Shine. Lighthouse ? KPMG's Center of Excellence for Advanced Analytics ? has both applied data science, AI, and big data architecture capabilities. Here, you'll work with a diverse team of sophisticated data and analytics professionals to explore the solutions for clients in a platform-diverse environment. This means your ability to find answers is limited only by your creativity in leveraging a vast array of techniques and tools. Be a part of a high-energy, diverse, fast-paced, and innovative culture that delivers with the agility of a tech startup and the backing of a leading global consulting firm. For you, that translates into the chance to work on a wide range of projects ? covering technologies and solutions from AI to optimization ? and the power to have a real impact in the business world. So, bring your creativity and pioneering spirit to KPMG Lighthouse. KPMG is currently seeking a Sr. Associate to join our- Center of Excellence for Advanced Analytics to work with our Financial Services team. Responsibilities: + Rapidly prototype, develop, and optimize D&A implementations to tackle the BI/EDW/Big Data and Data Science needs for a variety of Fortune 1000 corporations and other major organizations + Design, develop and maintain D&A solutions on premise/cloud/KPMG-hosted/hybrid infrastructure; Be the team champion of some mainstream BI/EDW/Big Data toolsets like Tableau, Alteryx, Informatica, Pentaho, Er-Win, and Power Designer + Play the role of data owner in cross-disciplinary teams; Build logical/physical data models; Discover, profile, acquire, process, model and own data for the solutions + Implement data processing pipelines, data mining/science algorithms, and visualization engineering to help clients distill insights from rich data sources, including social media, news, internal/external documents, emails, financial data, client data and operational data + Actively be involved in research and experiment of leading/emerging BI/EDW/Big Data methodologies such as serverless data lake, AWS Redshift, Athena, Glue, GCP BigQuery, and MS PowerBI and apply them to real client solutions + Be the data engineering SME in the process for pursuing innovations, target solutions, and extendable platforms for Lighthouse, KPMG and client Qualifications: + Minimum of three years of relevant data engineering experience in related industries, preferably professional services; Experience and knowledge of RDBMS design, data modeling, MPP EDW system implementation; Have completed two plus production BI/EDW/Big data projects with the ability to communicate complex technical concepts to non-technical personals at all levels + Bachelor's Degree, Master's Degree or PhD from an accredited college/ university in Computer Science, Computer Engineering or related field + Hands-on experience and knowledge in: BI/EDW/Big Data toolsets (Tableau, Alteryx, Informatica, Pentaho, Er-Win, Power Designer); Mainstream cloud infrastructures (AWS, MS Azure and GCP; their D&A-related Microservices); Implementing data lake and serverless data lake; Proficient-level fluency of SQL + Hands-on experience of Linux/Unix/Windows/.NET; Market-leading fluency in several programming languages: Bash/ksh/PowerShell; Python/Perl/R; Ability to pick up and learn new technologies quickly + Hands-on experience and knowledge in distributed computing architecture, massive-parallel processing big data platforms like Hadoop, MapReduce, HDFS, Spark, Hive/Impala, H-Base/MongoDB/Casandra and Teradata/Netezza/Redshift + Ability to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package. KPMG is an affirmative action-equal opportunity employer. KPMG complies with all applicable federal, state and local laws regarding recruitment and hiring. All qualified applicants are considered for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other category protected by applicable federal, state or local laws. Thecontains further information regarding the firm's compliance with federal, state and local recruitment and hiring laws. No phone calls or agencies please. **Our Benefits** **Health** KPMG offers a range of medical insurance options to meet your needs as well as prescription drug coverage, health care flexible spending accounts, and dependent day care flexible spending accounts. **Personal Time Off (PTO)** Up to 30 PTO Days per year (depending on job classification/level/years of service). **Financial** + 401(k) and Pension Plans + Dependent Care Flexible Spending Account + Health Care Flexible Spending Account + Mortgage Assistance Program + HomeBenefits@Work Program + Hyatt Legal Plan * Benefits vary by employment status. Associated topics: call center, guest, healthcare, inside sales, insurance sales, insurance sales agent, outside sales, phone, sales agent, sales position"},{"jobtitle":"Data Analyst III with ADP","companyname":"Not Just a Job Search","companyid":"18154965","address":"","geo":"El Paso, TX, US","postDate":"Nov 12 2018","views":"10","applicants":"1","employees":"2-10","jobDetails":[{"level":"Associate","industry":["Marketing & Advertising","Information Technology & Services","Computer Software"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nThe position listed below is not with Not Just a Job Search but with ADP\n\n Data Analyst III Req Number:165114 Category:Technology Posted Date:October 25, 2018 Work Location(s):Alpharetta,GA,US Tempe,AZ Alpharetta,GA Augusta,GA El Paso,TX Norfolk,VA ADP is hiring a **Data Analyst III. We?re looking for a Business Systems Analyst (NLP Natural Language Processing)/ Text Analytics Analyst that will be responsible for key business metrics and reporting that drives decision making and process improvement for the Business Unit.** A champion for standardizing and automating internal client-facing reports provided to Business Units. Be a change agent within the Business Unit?s closed loop administration to ensure accurate and high quality data is collected and analyzed on a consistent basis. Leverage a variety of analytical tools to provide information that is flexible, responsive and nimble to changing business needs. The Data Analyst is responsible for Client Experience Analysis/Providing Actionable Insight to the front line leaders. **At ADP we are driven by your success.** We engage your unique talents and perspectives. We welcome your ideas on how to do things differently and better. In your efforts to achieve, learn and grow, we support you all the way. If success motivates you, you belong at ADP. We strive for every interaction to be driven by our **CORE** values: **Insightful Expertise, Integrity is Everything, Service Excellence, Inspiring Innovation, Each Person Counts, Results-Driven, & Social Responsibility.** **RESPONSIBILITIES:** + Analytics/ Consulting/Communicating + Conducts NPS project initiation activities + Uncover complex client experience opportunities, through the use of data insights + Analyze existing client systems, interface requirements, business process and operational needs. + Assess client experience data including client feedback (qualitative & quantitative), predictive modeling, and client behaviors and profiling + Gather, assemble, analyze and deliver actionable insights and recommendations. + Provides professional consulting in the areas of tool customizations, business processes, analytics, complex custom reports and special projects + Responsible for researching benchmarked and attainable validated systemic tools to evaluate HR performance, resulting in metrics that help senior leaders drive Service Excellence. + Develop meaningful analytic conclusions and recommends innovative and actionable solutions + Work with Business Unit champions and Subject Matter Experts (SMEs) to define requirement related to reporting, analytics, trending and communications. + Coordinates and consults with Corporate IT for customization work + Develops adhoc inquiries to assist in reporting, categorization and analysis + Provides demos and training for champions and SMEs, including documentation as required for reporting, analysis, trending and communication. + Works and counsels with business units on system and service configuration tools, tool adaptation and business best practice solutions. + Determines best methodology and oversees the accurate and timely conversion of survey data, reporting and analytics. + Business Unit and Center of Excellence teams will work collaboratively to standardize all aspects of analytics and reporting. + Train appropriate uses on analytical tools to ensure widespread adoption of best practices in collecting and analyzing data for actionable recommendations to leaders. + Performs other related duties as assigned. **QUALIFICATIONS REQUIRED:** + 8 to 12 Years of Directly Related Experience + Bachelor?s Degree or its equivalent in education and experience with a Major Area of Concentration in BS in Finance, Accounting, Statistics **Preference will be given to candidates who have the following** : + Excellent quantitative and analytical skills, and strong attention to detail. + Tableau, SQL, CX Analytics, Python, R. + Excellent project management skills. + Strong verbal and interpersonal skills, with demonstrated ability to work with and communicate at all levels of staff and management. + Ability to interpret data into actionable recommendations. + Strong Excel skills required, including data modeling and ad hoc analysis. + Knowledge of text mining tools/techniques. + Can easily build relationships across multiple functions and business Units. **Software in the Cloud. Experts on the Ground:** **ADP powers the working world with comprehensive solutions that drive business success.** Consistently named one of the ?Most Admired Companies? by _FORTUNE?_ Magazine, and recognized by _Forbes?_ as one of ?The World?s Most Innovative Companies,? ADP has over a half-million clients around the globe and 65 years of experience as one of the largest providers of human capital management solutions world-wide. At ADP, we believe that diversity fuels innovation. ADP is committed to equal employment opportunities regardless of race, color, genetic information, creed, religion, sex, sexual orientation, gender identity, lawful alien status, national origin, age, marital status, or protected veteran status. We support an inclusive workplace where associates excel based on personal merit, qualifications, experience, ability, and job performance."},{"jobtitle":"Associate, Data Engineer","companyname":"KPMG US","companyid":"1079","address":"","geo":"Dallas, TX, US","postDate":"Nov 12 2018","views":"56","applicants":"9","employees":"10001","jobDetails":[{"level":"Mid-Senior level","industry":["Management Consulting"],"jobtype":"Full-time","function":["General Business"]}],"description":"Job description\nRequisition Number: 37100 - 83\n\nDescription\n\nInnovate. Collaborate. Shine. Lighthouse – KPMG's Center of Excellence for Advanced Analytics – has both applied data science, AI, and big data architecture capabilities. Here, you'll work with a diverse team of sophisticated data and analytics professionals to explore the solutions for clients in a platform-diverse environment. This means your ability to find answers is limited only by your creativity in leveraging a vast array of techniques and tools. Be a part of a high-energy, diverse, fast-paced, and innovative culture that delivers with the agility of a tech startup and the backing of a leading global consulting firm. For you, that translates into the chance to work on a wide range of projects – covering technologies and solutions from AI to optimization – and the power to have a real impact in the business world. So, bring your creativity and pioneering spirit to KPMG Lighthouse.\n\n KPMG is currently seeking an Associate, Data & Analytics Engineer to join our KPMG Lighthouse - Center of Excellence for Advanced Analytics.\n\nResponsibilities\n\nRapidly prototype, develop, and optimize D&A implementations to tackle the BI/EDW/Big Data and Data Science needs for a variety of Fortune 1000 corporations and other major organizations\nDevelop and maintain D&A solutions on premise/cloud/KPMG-hosted/hybrid infrastructure; be the team champion of some mainstream BI/EDW/Big Data toolsets like Tableau, Alteryx, Informatica, Pentaho, Er-Win and Power Designer\nPlay the role of data owner in cross-disciplinary teams; Build logical/physical data models\nDiscover, profile, acquire, process, model, and own data for the solutions; Implement data processing pipelines, data mining/science algorithms, and visualization engineering to help clients distill insights from rich data sources, including social media, news, internal/external documents, emails, financial data, client data and operational data\nHelp in research and experiment of leading/emerging BI/EDW/Big Data methodologies, such as serverless data lake, AWS Redshift, Athena, Glue, GCP BigQuery, and MS PowerBI and apply them to real client solutions\nFrom data engineering point of view, help in the process for pursuing innovations, target solutions, and extendable platforms for Lighthouse, KPMG and client\n\n\nQualifications\n\nMinimum of one year of relevant data engineering experience in related industries, preferably professional services with experience or knowledge of RDBMS design, data modeling, MPP EDW system implementation; Ability to pick up and learn new technologies quickly\nBachelor's Degree, Master's Degree or PhD from an accredited college/ university in Computer Science, Computer Engineering or related field\nHands-on experience and knowledge in: BI/EDW/Big Data toolsets (Tableau, Alteryx, Informatica, Pentaho, Er-Win, and Power Designer); Linux/Unix/Windows/.NET; Market-leading fluency of SQL and several programming languages (Bash/ksh/PowerShell; Python/Perl/R)\nHands-on experience and knowledge in distributed computing architecture, massive-parallel processing big data platforms like Hadoop, MapReduce, HDFS, Spark, Hive/Impala, H-Base/MongoDB/Casandra and Teradata/Netezza/Redshift\nHands-on experience or knowledge in mainstream cloud infrastructures: AWS, MS Azure and GCP; their D&A related Microservices; Ability to implement data lake and serverless data lake\nAbility to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future\n\nKPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package. KPMG is an affirmative action-equal opportunity employer. KPMG complies with all applicable federal, state and local laws regarding recruitment and hiring. All qualified applicants are considered for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other category protected by applicable federal, state or local laws. The attached link contains further information regarding the firm's compliance with federal, state and local recruitment and hiring laws. No phone calls or agencies please."},{"jobtitle":"Data Analyst - Retail Operations - Atlanta","companyname":"OSHKOSH BGOSH","companyid":"9631450","address":"","geo":"Atlanta, GA, US","postDate":"Nov 12 2018","views":"22","applicants":"5","employees":"201-500","jobDetails":[{"level":"Associate","industry":["Apparel & Fashion","Consumer Goods","Retail"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nJob Description\n\nCarter's, Inc. is the largest branded marketer in North America of apparel exclusively for babies and young children. The Company owns the Carter's and OshKosh B'gosh brands, two of the most recognized brands in the marketplace. These brands are sold in leading department stores, national chains, and specialty retailers domestically and internationally. They are also sold through more than 1,000 Company-operated stores in the United States, Canada, and Mexico and online at , , and . The Company's Just One You and Genuine Kids brands are available at Target, its Child of Mine brand is available at Walmart, and its Simple Joys brand is available on Amazon. The Company also owns Skip Hop, a global lifestyle brand for families with young children. Carter's is headquartered in Atlanta, Georgia. Additional information may be found at .\n\n Responsible for strategic and analytical support of Workforce Management and cross-functional initiatives, including labor deployment, forecasting, payroll distribution, and in-store technology.\n\nDevelop advanced analytics and visualization tools to optimize the WFM application for increased sales, potential costs savings while providing a best-in-class customer experience. Example analyses include Dynamic Field performance, Cost / Benefit, Store Payroll impact, Forecasting sales, Revenue $, Gross Margin $ and % Impact, etc\nUtilize data for developing standardized reporting to provide comprehensive analytics into field performance from our current labor model. Provide insight and direction into changes needed to drive increased customer satisfaction\n\nPartner with various departments that drive workload within the store to collect data inputs to our labor model. Develop standardized reporting to provide comprehensive visibility into performance to our current labor model.\n\nDrive growth and customer satisfaction. Evaluate and contribute to store training for building business acumen and analyzing in-store KPIs (e.g. CTS, Conversion, AT), as well as initiatives to incentivize store teams\n\nAnalyze data surrounding new technologies to provide insight and store-level perspective to business leaders\n\nBe a champion for change management. Communication of past, current, and future expectations for the field is critical within the projects and initiatives of the organization\n\nDrive growth and customer satisfaction. Evaluate and contribute to store training for building business acumen and analyzing in-store KPIs (e.g. CTS, Conversion, AT), as well as initiatives to incentivize store teams\n\nProvide ongoing and ad hoc analytical support to the Retail Senior Leadership Team\n\nSupport Store Operations needs to the business accordingly with current processes and procedures.\n\nCommunication with external clients regarding store systems, including defect identification and issue resolution\n\nCommunicate with store and field leadership as needed to gather data to meet project research goals\n\nPresentation skills needed to review analytics with various business partners\n\n\nExperience And Skills\n\nBachelors degree in Business, Finance, Economics or a related field\n3+ years combined experience with Proficiency in advanced analytics and visualization tools preferred (SQL, Python, R)\n\nExcellent verbal and written communication skills. Possess a collaborative approach to problem-solving\n\nExcellent organizational and leadership skills, as well as strong customer focus and with strong ability to deal with ambiguity\n\nDetail-oriented, flexible, and able to work well under pressure in a fast paced environment\n\nAbility to be accurate with details, facts and supporting data. Ability to review data analysis, quantify results and recommend appropriate action based upon conclusions.\n\nComputer proficiency: Microsoft Office with a very strong skillset with Excel\n\n\nCarters is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity, sexual orientation, national origin, genetics, disability, age, veteran status, or any other status protected by federal, state, or local law."},{"jobtitle":"Senior Data Engineer","companyname":"Fanatics, Inc.","companyid":"68543","address":"","geo":"San Mateo, CA, US","postDate":"Nov 05 2018","views":"166","applicants":"23","employees":"1001-5000","jobDetails":[{"level":"Associate","industry":["Marketing & Advertising","Consumer Goods","Retail"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nFanatics is the global leader in licensed sports merchandise that changes the way fans purchase their favorite team apparel and jerseys through an innovative and tech-infused approach to making and selling fan gear in today’s on-demand culture. We have the world’s largest collection of officially licensed fan gear from all the leagues, teams and players our fans love. We operate more than 300 online and offline stores including e-commerce business with all major professional sports leagues (NFL, MLB, NBA, NHL, NASCAR, MLS, PGA), major media brands (NBC Sports, CBS Sports, FOX Sports) and over 150 collegiate and professional team properties. We partner with over 1000 vendors including Adidas, Nike, Reebok and Under Armor.\n\n Our inventory team is building inventory intelligence data pipelines that extract and process raw data into useful data analytics to meet our business’s growing activities and potential. The pipelines are the core to our merchandising replenishment tool with forecasting statistics for our buyers to stock inventory and other business intelligence applications. We also build automation tools and monitoring systems to improve our development cycle.\n\n We are seeking for a Senior Data Engineer who has strong architectural skills and upkeeps scalability, availability and excellence when building the next generation of our data pipelines and platform. You are an expert in various data stores and data stream libraries, appreciate the value of clear communication and collaboration, and devote to continual capacity planning and performance fine-tuning for emerging business growth. As the Senior Data Engineer, you will architect and build inventory intelligence data pipelines and application platform that drive business decisions.\n\n What Will You Do?\n\n\nArchitect and build inventory intelligence data pipelines and platform that can parse raw data algorithmically from different data sources, and deliver quality real-time analytical reports for all our replenishment team and our business analytics\nDevelop clean, safe, testable and cost-efficient solutions; Build fast and reliable pipeline, platform with underlying data model that can scale according to business needs and growth\nWork with backend engineers to create services that can ingest and supply data to and from external sources, provide data streaming solutions and ensure data quality and timeliness\nWork with product manager to translate business requirements into scalable solutions, prioritize workload and deliver quality and functional products on a timely manner that can grow over time\nMake well-informed decisions with deep knowledge of both the internal and external impacts to teams and projects\nUnderstand the system you are building, foresee shortcomings ahead of time and be able to resolve or compromise appropriately\n\n\nWhat Are We Looking For?\n\n\nExcellent understanding of data structures, algorithms and distributed systems\nKnowledge of common design patterns used in Big Data processing\nStrong development experience using OO programming languages: Scala, Java, C++\nProficiency in big data technologies: AWS, Spark, Flink, Hive, Hadoop\nExperience with and deep understanding of traditional, NoSQL and columnar databases such as Oracle, MySQL, PostgreSQL, DynamoDB, Redshift, Vertica\nKnowledge and experience in designing and developing RESTful services, data modeling & mining, ETL, data warehouse, deployment and infrastructure management, and performance tuning\nExperience in partnering with architects, engineers in data environments that are complex, enterprise wide, multi-tenant, and host large scale of data\nAbility to build systems that balance scalability, availability and latency while solving different problems\nAdvocator of continual deployment and automation tools that can help improve the lives of our engineers\nA good communicator and team player who has a proven track record of building strong relationships with management, co-workers and customers.\nA desire to learn and grow, push yourself and your team, share lessons with others and provide constructive and continuous feedbacks, and receptive to feedback from others"},{"jobtitle":"Data Analyst - Retail Operations","companyname":"Carters Inc.","companyid":"14242","address":"","geo":"Atlanta, GA, US","postDate":"Nov 05 2018","views":"687","applicants":"103","employees":"10001","jobDetails":[{"level":"Associate","industry":["Consumer Goods","Apparel & Fashion","Retail"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nJob Description\n\nCarter's, Inc. is the largest branded marketer in North America of apparel exclusively for babies and young children. The Company owns the Carter's and OshKosh B'gosh brands, two of the most recognized brands in the marketplace. These brands are sold in leading department stores, national chains, and specialty retailers domestically and internationally. They are also sold through more than 1,000 Company-operated stores in the United States, Canada, and Mexico and online at www.carters.com, www.oshkoshbgosh.com, and www.cartersoshkosh.ca. The Company's Just One You and Genuine Kids brands are available at Target, its Child of Mine brand is available at Walmart, and its Simple Joys brand is available on Amazon. The Company also owns Skip Hop, a global lifestyle brand for families with young children. Carter's is headquartered in Atlanta, Georgia. Additional information may be found at www.carters.com.\n\n Responsible for strategic and analytical support of Workforce Management and cross-functional initiatives, including labor deployment, forecasting, payroll distribution, and in-store technology.\n\nDevelop advanced analytics and visualization tools to optimize the WFM application for increased sales, potential costs savings while providing a best-in-class customer experience. Example analyses include Dynamic Field performance, Cost / Benefit, Store Payroll impact, Forecasting sales, Revenue $, Gross Margin $ and % Impact, etc\n\nUtilize data for developing standardized reporting to provide comprehensive analytics into field performance from our current labor model. Provide insight and direction into changes needed to drive increased customer satisfaction\n\nPartner with various departments that drive workload within the store to collect data inputs to our labor model. Develop standardized reporting to provide comprehensive visibility into performance to our current labor model.\n\nDrive growth and customer satisfaction. Evaluate and contribute to store training for building business acumen and analyzing in-store KPIs (e.g. CTS, Conversion, AT), as well as initiatives to incentivize store teams\n\nAnalyze data surrounding new technologies to provide insight and store-level perspective to business leaders\n\nBe a champion for change management. Communication of past, current, and future expectations for the field is critical within the projects and initiatives of the organization\n\nDrive growth and customer satisfaction. Evaluate and contribute to store training for building business acumen and analyzing in-store KPIs (e.g. CTS, Conversion, AT), as well as initiatives to incentivize store teams\n\nProvide ongoing and ad hoc analytical support to the Retail Senior Leadership Team\n\nSupport Store Operations needs to the business accordingly with current processes and procedures.\n\nCommunication with external clients regarding store systems, including defect identification and issue resolution\n\nCommunicate with store and field leadership as needed to gather data to meet project research goals\n\nPresentation skills needed to review analytics with various business partners\n\n\n\n\nRequired Experience\n\nBachelors degree in Business, Finance, Economics or a related field\n\n3+ years combined experience with Proficiency in advanced analytics and visualization tools preferred (SQL, Python, R)\n\nExcellent verbal and written communication skills. Possess a collaborative approach to problem-solving\n\nExcellent organizational and leadership skills, as well as strong customer focus and with strong ability to deal with ambiguity\n\nDetail-oriented, flexible, and able to work well under pressure in a fast paced environment\n\nAbility to be accurate with details, facts and supporting data. Ability to review data analysis, quantify results and recommend appropriate action based upon conclusions.\n\nComputer proficiency: Microsoft Office with a very strong skillset with Excel\n\n\n\nCarters is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity, sexual orientation, national origin, genetics, disability, age, veteran status, or any other status protected by federal, state, or local law.\n Visit http://carters.submit4jobs.com/ today\n\n Keyword: retail, WFM, analysis, SQL, Excel"},{"jobtitle":"Data Engineer","companyname":"Amazon","companyid":"1586","address":"","geo":"Seattle, WA, US","postDate":"Nov 05 2018","views":"28","applicants":"3","employees":"10001","jobDetails":[{"level":"","industry":["Computer Software","Information Technology & Services","Internet"],"jobtype":"Full-time","function":["Strategy/Planning","Analyst","Information Technology"]}],"description":"Job description\nAmazon is looking for a Data Engineer for the Fulfillment by Amazon and Amazon Global Selling business. We help simplify global trade by building solutions and products for small-medium businesses to expand their business internationally.\n\n Over the next 12 months, the team is focused intently on designing and building out a new data platform to meet the needs of the business and technology teams to enable the data driven decisions by our leadership and help provide the best possible selling platform for our Sellers.\n\n This is a very unique opportunity to work on building one of the world's largest Data Platforms - the one platform to rule them all! You'll be working with the Business users, Machine Learning teams, Data Science teams and Development teams in building this common data platform. You should be passionate about working with complex datasets and be someone who loves to bring data together to answer strategic business questions. You should have deep expertise in the design, creation, management and business use of large analytical datasets and the proven ability to provide self-serve tools that allow end users to translate data into meaningful insights. In this role, you will be part of end-to-end development of the new Data Platform for all of FBA/AGS and you’ll play an integral role in strategic decision making.\n\n You should have excellent business and communication skills to be able to work with business owners, SDEs, Product Managers and the Leadership to understand the requirements.\n\nResponsibilities Include\n\nInterface with other technology teams to extract, transform, and load data from a wide variety of data sources.\nFamiliarity with SQL, AWS Stack (S3, Redshift, RDS, MySQL)\nInterface with business customers to gather requirements\nModel data and metadata to support quarterly, weekly and ad-hoc reporting\nOwn the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc… to drive key business decisions\nLearn and understand a broad range of Amazon’s data resources and know when, how, which to use and which not to use\nCreate self-service interfaces using business intelligence tools such as Looker to improve reporting and analysis processes, and increasing automation of data requests\nCreate the strategic direction for all data needs as this fast growing, multi-billion dollar business scales.\nImplement big data solutions for distributed computing\nFamiliarity with Machine Learning and Data Science\n\n\nBasic Qualifications\n\nMS Degree in Computer Science, Electrical Engineering (EE/ECE) or related field\n5+ years of relevant experience in data modeling, data mining, SQL/BI architecture using AWS Stack of technologies, Unix Scripting and Looker.\nExperience with building multidimensional data models to serve as foundation for growing analytical needs\nExperience working with business customers to drive requirements analysis\nAdvanced SQL writing skills and solid experience with ETL\nCoding skills in Python, Java or other languages.\nStrong attention to detail, excellent organization skills, and ability to manage concurrent projects while still delivering timely and accurate results.\n\n\nCompany - Amazon Services LLC\n Job ID: A614157"},{"jobtitle":"Scientific Data Analyst","companyname":"Stanford University","companyid":"1792","address":"","geo":"Stanford, CA, US","postDate":"Nov 05 2018","views":"70","applicants":"4","employees":"10001","jobDetails":[{"level":"Associate","industry":["Non-profit Organization Management","Higher Education","Hospital & Health Care"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nThe Stanford Cognitive and Systems Neuroscience Laboratory in the Department of Psychiatry and Behavioral Sciences is seeking a Scientific Data Analyst. This is an exciting opportunity to work with a multidisciplinary research team (http://scsnl.stanford.edu) on a wide range of studies of human brain function and dysfunction. The successful candidate will assist lab members with neuroimaging and behavioral data analysis, data organization, and management. The Scientific Data Analyst would be responsible for programming and optimizing pipelines for data quality control, imaging data preprocessing and statistical and computational analyses pipelines for large scale multimodal brain imaging data, including but not limited to resting – state and task – based fMRI, diffusion MRI, and volumetric data, behavior data and biological (e.g. hormonal, genetic) data.\n\n Interested candidates are encouraged to submit their CV, a statement of research interests and career goals, and contact information for three references.\n\nDuties Include\n\nWork under consultative or self-initiated direction to assess and produce relevant, standard, or custom information (reports, charts, graphs and tables) from structured data sources by querying data repositories and generating the associated information. Distribute and disseminate reports to applicable agencies, researchers, management and other internal end-users.\nDevise methods for identifying data patterns, trends in available information sources using a variety of qualitative and quantitative techniques. Determine and recommend additional data collection and reporting requirements.\nDesign and customize reports based upon data in the database.\nCreate non-routine databases and their related information summary; develop algorithms and statistical model; and perform statistical analyses appropriate to complex data and reporting requirements.\nServe as a resource for non-routine inquiries such as requests for statistics or surveys.\nLead the implementation of data standards and common data elements for data collection.\nCollaborate with technical staff to standardize and systemize routine reports, dashboards, and metrics.\nMay test prototype software and participate in approval and release process for new software.\n- Other duties may also be assigned\n\nDesired Qualifications\n\nMaster’s or Ph.D. degree in biomedical engineering, computer science, psychics, computational neuroscience, quantitative psychology or related field preferred.\nProficient with multiple neuroimaging analysis platforms (e.g. HCP Pipeline, FreeSurfer, SPM, FSL AFNI, GIFT)\nStrong programing skills and comfort with diverse computing environments (e.g. MatLab, Python, UNIX/BASH languages)\nStrong background in statistics and statistical software scripting (e.g. R, Python)\nExperience with data visualization\n\nEducation & Experience (required)\n\nBachelors degree and three years of relevant experience or combination of education and relevant experience. Experience in a quantitative discipline such as economics, finance, statistics or engineering.\n\nKnowledge, Skills And Abilities (required)\n\nIn-depth knowledge and experience using and applying analytical software, database management system software, database reporting software, database user interface and query software, and data mining software.\nExpert ability to collect data using a variety of methods, such as data mining and hardcopy or electronic documentation study, to improve or expand databases.\nBasic statistical ability.\nStrong listening, verbal and written communication skills.\nAbility to manage multiple activities in a deadline-oriented environment; highly organized, flexible and rigorous attention to detail.\nAbility to use logic to calculate data; efficiently construct a database or scrutinize the form of a question.\nAbility to work with data of varying levels of quality and validity.\nDemonstrated ability to produce data in a clear and understandable manner meeting user requirements.\nAbility to work effectively with multiple internal and external customers.\nAbility to take a leadership role on projects and with users/clients.\n"},{"jobtitle":"Data Engineer - Internal Tools and Services","companyname":"Samba TV","companyid":"1019086","address":"","geo":"San Francisco, CA, US","postDate":"Nov 05 2018","views":"7","applicants":"1","employees":"201-500","jobDetails":[{"level":"","industry":["Internet","Marketing & Advertising","Research"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nSamba TV, recognized by Inc. Magazine as one of the fast growing companies in the US and one of the \"most interesting ad-tech upstarts of the year\" by Business Insider, is seeking to hire a software engineer to join our Data Engineering department.\n\n Samba TV is uniquely positioned at the forefront of the TV revolution. The way people discover, watch, and engage with television has fundamentally changed, and we're connecting the dots to help better understand audience trends and viewership habits for marketers.\n\n The Internal Tools and Services team is one of several teams in the Data Engineering department. Our team builds and maintains the tools and frameworks that power SambaTV's core data pipeline. We are looking for someone passionate and motivated to make an impact in the design and architecture of Samba TV's data platform.\n\n In your role, you will become intimately familiar with the way we define, schedule, and monitor data pipelines with the objective of creating tools that improve development speed and increase visibility into the availability and properties of our growing collection of datasets. You will be expected to work closely alongside members of the Data Science and Audience Analytics teams, leveraging your data expertise to help improve data models and processing algorithms while closely observing the bottlenecks in the development process to gather feedback needed to further improve our data platform tools.\n\nResponsibilities\n\nAnalyze and improve the efficiency, scalability, and stability of data collection, storage, and retrieval processes for our core systems.\nBuild and maintain core data infrastructure, such as Spark clusters, workflow scheduling frameworks, relational and time series databases.\nWork with data scientists, data analysts and other business partners developing tools and frameworks to support self-service data pipeline creation and management.\nImprove observability and monitoring of production processes by instrumenting existing code and creating services that expose the state of pipeline jobs and datasets to internal consumers.\nFocus on the performance of individual jobs in our processing pipelines; understanding the algorithms that power them and the trade offs and bottlenecks that affect their runtime and resource consumption.\nMentor members of other data teams that are eager to improve their software engineering skills; be a role model who exemplifies coding and software design best practices.\n\n\n\nRequirements\n\nIntermediate to advanced knowledge of Python, or alternatively mastery of another modern programming language with the strong desire to become an advanced Pythonista.\nWe are a distributed team working from Warsaw and San Francisco offices. Thus, you should have excellent communications skills, especially in written form.\nYou should be comfortable working directly with Data Science, Audience Analytics, and other internal consumers to bridge product requirements with Data Engineering.\nExcellent problem solving skills and ability to interpret and analyze data. Having a strong mathematical inclination is a major plus.\nPrevious experience with Apache Spark or similar large-scale data processing frameworks is also a major plus.\n\n\nOur Technology\n\nPython as our primary language.\nAmazon Web Services for compute and storage.\nApache Spark as our primary processing engine.\nJenkins and Luigi for workflow scheduling.\nAnsible for configuration management.\nDatabases: PostgreSQL, Elasticsearch, InfluxDB."},{"jobtitle":"Data Analyst III with ADP","companyname":"ADP","companyid":"","address":"","geo":"El Paso, TX, US","postDate":"Nov 05 2018","views":"7","applicants":"0","employees":"","jobDetails":[{"level":"Associate","industry":["Marketing & Advertising","Information Technology & Services","Computer Software"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nThe position listed below is not with Not Just a Job Search but with ADP\n\n Data Analyst III Req Number:165114 Category:Technology Posted Date:October 25, 2018 Work Location(s):Alpharetta,GA,US Tempe,AZ Alpharetta,GA Augusta,GA El Paso,TX Norfolk,VA ADP is hiring a **Data Analyst III. We?re looking for a Business Systems Analyst (NLP Natural Language Processing)/ Text Analytics Analyst that will be responsible for key business metrics and reporting that drives decision making and process improvement for the Business Unit.** A champion for standardizing and automating internal client-facing reports provided to Business Units. Be a change agent within the Business Unit?s closed loop administration to ensure accurate and high quality data is collected and analyzed on a consistent basis. Leverage a variety of analytical tools to provide information that is flexible, responsive and nimble to changing business needs. The Data Analyst is responsible for Client Experience Analysis/Providing Actionable Insight to the front line leaders. **At ADP we are driven by your success.** We engage your unique talents and perspectives. We welcome your ideas on how to do things differently and better. In your efforts to achieve, learn and grow, we support you all the way. If success motivates you, you belong at ADP. We strive for every interaction to be driven by our **CORE** values: **Insightful Expertise, Integrity is Everything, Service Excellence, Inspiring Innovation, Each Person Counts, Results-Driven, & Social Responsibility.** **RESPONSIBILITIES:** + Analytics/ Consulting/Communicating + Conducts NPS project initiation activities + Uncover complex client experience opportunities, through the use of data insights + Analyze existing client systems, interface requirements, business process and operational needs. + Assess client experience data including client feedback (qualitative & quantitative), predictive modeling, and client behaviors and profiling + Gather, assemble, analyze and deliver actionable insights and recommendations. + Provides professional consulting in the areas of tool customizations, business processes, analytics, complex custom reports and special projects + Responsible for researching benchmarked and attainable validated systemic tools to evaluate HR performance, resulting in metrics that help senior leaders drive Service Excellence. + Develop meaningful analytic conclusions and recommends innovative and actionable solutions + Work with Business Unit champions and Subject Matter Experts (SMEs) to define requirement related to reporting, analytics, trending and communications. + Coordinates and consults with Corporate IT for customization work + Develops adhoc inquiries to assist in reporting, categorization and analysis + Provides demos and training for champions and SMEs, including documentation as required for reporting, analysis, trending and communication. + Works and counsels with business units on system and service configuration tools, tool adaptation and business best practice solutions. + Determines best methodology and oversees the accurate and timely conversion of survey data, reporting and analytics. + Business Unit and Center of Excellence teams will work collaboratively to standardize all aspects of analytics and reporting. + Train appropriate uses on analytical tools to ensure widespread adoption of best practices in collecting and analyzing data for actionable recommendations to leaders. + Performs other related duties as assigned. **QUALIFICATIONS REQUIRED:** + 8 to 12 Years of Directly Related Experience + Bachelor?s Degree or its equivalent in education and experience with a Major Area of Concentration in BS in Finance, Accounting, Statistics **Preference will be given to candidates who have the following** : + Excellent quantitative and analytical skills, and strong attention to detail. + Tableau, SQL, CX Analytics, Python, R. + Excellent project management skills. + Strong verbal and interpersonal skills, with demonstrated ability to work with and communicate at all levels of staff and management. + Ability to interpret data into actionable recommendations. + Strong Excel skills required, including data modeling and ad hoc analysis. + Knowledge of text mining tools/techniques. + Can easily build relationships across multiple functions and business Units. **Software in the Cloud. Experts on the Ground:** **ADP powers the working world with comprehensive solutions that drive business success.** Consistently named one of the ?Most Admired Companies? by _FORTUNE?_ Magazine, and recognized by _Forbes?_ as one of ?The World?s Most Innovative Companies,? ADP has over a half-million clients around the globe and 65 years of experience as one of the largest providers of human capital management solutions world-wide. At ADP, we believe that diversity fuels innovation. ADP is committed to equal employment opportunities regardless of race, color, genetic information, creed, religion, sex, sexual orientation, gender identity, lawful alien status, national origin, age, marital status, or protected veteran status. We support an inclusive workplace where associates excel based on personal merit, qualifications, experience, ability, and job performance."},{"jobtitle":"Data Engineer - Torrance","companyname":"iSpace","companyid":"29848","address":"","geo":"Torrance, CA, US","postDate":"Nov 05 2018","views":"4","applicants":"1","employees":"501-1000","jobDetails":[{"level":"Entry level","industry":["Information Technology & Services","Computer Software","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nLocation: Torrance, CA Job Description:\nInterprets results using a variety of techniques, ranging from simple data aggregation via statistical analysis to complex data mining independently.\nDesigns, Develops, implements and maintains business solutions. Works with main clients and project and business leaders to identify analytical requirements.\nProvides tutorship to junior analysts\nAcademic/Experience/Competency:\nBachelor's degree; Math, Economics, Statistics, Management Information Systems or Computer Science preferred.\nFamiliar with a variety of the field's concepts, practices, and procedures.\nRelies on extensive experience and judgment to plan and accomplish goals.\nPerforms a variety of tasks.\nMay lead and direct the work of others.\nA wide degree of creativity and latitude is expected.\nBusiness Experience:\n4-6 Years of relevant technical or business work experience\nDaily Tasks Performed:\nWork with stakeholders to identify opportunities for leveraging company data to drive business solutions.\nMine and analyze data from company databases to drive optimization and improvement of customer experience, marketing techniques and business strategies.\nAssess the effectiveness and accuracy of new data sources and data gathering/cleansing techniques.\nDevelop custom data models and algorithms to apply to data sets.\nUse predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.\nCoordinate with different functional teams to implement models and monitor outcomes.\nDevelop processes and tools to monitor and analyze model performance and data accuracy.\nWants:\nStrong problem-solving skills with an emphasis on product development.\nExperience using statistical computer languages (R, Python, Sql, etc.) to manipulate data and draw insights from large data sets.\nExperience working with and creating data architectures.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\nKnowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\nExcellent written and verbal communication skills for coordinating across teams.\nA drive to learn and master new technologies and techniques.\nWe're looking for someone with 5-7 years of experience manipulating data sets and building statistical models, and is familiar with the following software/tools:\nKnowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.\nExperience querying databases and using statistical computer languages: R, Python, Sql, etc.\nExperience using web services: Redshift, S3, Spark, DigitalOcean, etc.\nExperience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.\nExperience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.\nExperience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.\nExperience visualizing/presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, etc.\n\nClick here to Apply@ (310) 563-3846."},{"jobtitle":"Data Analyst","companyname":"UNICON International, Inc.","companyid":"","address":"","geo":"Torrance, CA, US","postDate":"Nov 05 2018","views":"12","applicants":"3","employees":"","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Computer Software","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nWe are currently accepting resumes for a Data Analyst in Torrance, CA . The selected candidate will perform the following duties: - Interprets results using a variety of techniques, ranging from simple data aggregation via statistical analysis to complex data mining independently - Designs, Develops, implements and maintains business solutions - Works with main clients and project and business leaders to identify analytical requirements - Provides tutorship to junior analysts - Performs a variety of tasks - May lead and direct the work of others - Relies on extensive experience and judgment to plan and accomplish goals - Work with stakeholders to identify opportunities for leveraging company data to drive business solutions- Mine and analyze data from company databases to drive optimization and improvement of customer experience, marketing techniques and business strategies - Assess the effectiveness and accuracy of new data sources and data gathering/cleansing techniques - Develop custom data models and algorithms to apply to data sets - Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes - Coordinate with different functional teams to implement models and monitor outcomes - Develop processes and tools to monitor and analyze model performance and data accuracy Required Skills and Experience: - Bachelor's degree; Math, Economics, Statistics, Management Information Systems or Computer Science preferred - 4-6 Years of relevant technical or business work experience - Strong problem solving skills with an emphasis on product development- Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets - Experience working with and creating data architectures - Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks - Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications - Excellent written and verbal communication skills for coordinating across teams - A drive to learn and master new technologies and techniques- 5-7 years of experience manipulating data sets and building statistical models, and is familiar with the following software/tools: Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc. - Experience querying databases and using statistical computer languages: R, Python, SLQ, etc. - Experience using web services: Redshift, S3, Spark, DigitalOcean, etc. - Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc. - Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc. - Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. - Experience visualizing/presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, etc. - Familiar with a variety of the field's concepts, practices, and procedures - A wide degree of creativity and latitude is expected UNICON International, Inc. is an Equal Opportunity Employer. If you are interested in working for an organization where honesty, integrity and quality are among the core principles then click apply today! Keywords: R, Python, SLQ, Data analyst - provided by Dice\n R, Python, SLQ, Data analyst"},{"jobtitle":"Data Engineer","companyname":"iSpace","companyid":"29848","address":"","geo":"Torrance, CA, US","postDate":"Nov 05 2018","views":"33","applicants":"5","employees":"501-1000","jobDetails":[{"level":"Entry level","industry":["Information Technology & Services","Computer Software","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nTitle: Data Analyst Level III Location: Torrance, CA Job Description: Interprets results using a variety of techniques, ranging from simple data aggregation via statistical analysis to complex data mining independently. Designs, Develops, implements and maintains business solutions. Works with main clients and project and business leaders to identify analytical requirements. Provides tutorship to junior analysts Academic/Experience/Competency: Bachelor's degree; Math, Economics, Statistics, Management Information Systems or Computer Science preferred. Familiar with a variety of the field's concepts, practices, and procedures. Relies on extensive experience and judgment to plan and accomplish goals. Performs a variety of tasks. May lead and direct the work of others. A wide degree of creativity and latitude is expected. Business Experience: 4-6 Years of relevant technical or business work experience Daily Tasks Performed: Work with stakeholders to identify opportunities for leveraging company data to drive business solutions. Mine and analyze data from company databases to drive optimization and improvement of customer experience, marketing techniques and business strategies. Assess the effectiveness and accuracy of new data sources and data gathering/cleansing techniques. Develop custom data models and algorithms to apply to data sets. Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes. Coordinate with different functional teams to implement models and monitor outcomes. Develop processes and tools to monitor and analyze model performance and data accuracy. Wants: Strong problem-solving skills with an emphasis on product development. Experience using statistical computer languages (R, Python, Sql, etc.) to manipulate data and draw insights from large data sets. Experience working with and creating data architectures. Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks. Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications. Excellent written and verbal communication skills for coordinating across teams. A drive to learn and master new technologies and techniques. We're looking for someone with 5-7 years of experience manipulating data sets and building statistical models, and is familiar with the following software/tools: Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc. Experience querying databases and using statistical computer languages: R, Python, Sql, etc. Experience using web services: Redshift, S3, Spark, DigitalOcean, etc. Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc. Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc. Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. Experience visualizing/presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, etc. Please email resumes to Balu.Balachandar@ispace.com or call Balu @ (310) 563-3846. - provided by Dice\n R, Python, SQL, Data sets, Data Architecture"},{"jobtitle":"Sr. Data Analyst","companyname":"Fitbit","companyid":"1132117","address":"","geo":"San Francisco, CA, US","postDate":"Nov 05 2018","views":"767","applicants":"164","employees":"1001-5000","jobDetails":[{"level":"","industry":["Computer Software","Consumer Electronics","Health, Wellness & Fitness"],"jobtype":"Full-time","function":["Marketing","Product Management"]}],"description":"Job description\nAt Fitbit, our mission is to help people lead healthier, more active lives by empowering them with data, inspiration and guidance to reach their goals.\n\n We started our journey in 2007—as a team of two with one big idea. Since then, we’ve grown to over 1,500 employees, sold over 60mm devices, and built a health and fitness community across the globe. In fact, the Fitbit Community has taken enough steps to walk from the Sun to Pluto! Offering award-winning products, a top-rated mobile app and an easy-to-use online dashboard, Fitbit provides personalized experiences that help our users reach their goals. With a reenergized focus on innovative devices, interactive experiences, and enterprise health we are transforming the way consumers and businesses see health & fitness.\n\n From your first steps as a Fitbitter, you will be at the forefront of developing new products. Our culture combines the spirit of startup with the perks of being public. We offer a competitive benefits package and amazing perks like unlimited snacks, Friday happy hours, onsite workout classes, and a strong focus on a healthy work-life balance. As part of our team, you’ll have the opportunity to grow your career, contribute your ideas to life-changing products and services, and—above all—have fun doing it.\n\n Fitbit’s HQ campus is located in the heart of San Francisco with office locations in Boston, San Diego and around the world. Think you’ve found your fit?\n\nWhat You'll Work On\n\nApply your expertise in quantitative analysis, data mining and presentation of data to see beyond the numbers and understand how our users interact with our core/business products.\nPartner with Customer Support, Research, Product Specialist, Community, Social and Engineering teams to identify trends and opportunities\nInform, influence and support our product decisions using insight on customer experience\nDesigning and evaluating experiments monitoring key metrics, understanding root cause of changes in metrics\nBuilding and analyzing dashboards and reports\nUnderstanding the customer support ecosystems, user behaviors, and long term trends\nIdentify levers to help move key metrics\nEvaluating and identifying metrics\nBuilding models of user behaviors for analysis\n\n\n\nRequired Skills\n\n5+ years experience in an analytics/data science role\nBachelors, Masters degree in quantitative discipline (Economics, Finance, Statistics, Engineering, Computer Science or MBA with emphasis in analytics)\nProficient at analyzing large multi-dimensional data sets using data/statistical tools such as R, Python, SAS, SPSS and Excel.\nExperience utilizing tools like Tableau, HighCharts, Qlikview\nLinux skills (shell scripting, Java, PHP, etc.)\nA strong passion for data, charts, analysis, trends, and evangelizing data usage\nAn appreciation for Fitbit’s products\nAbility to draw conclusion from data and provide recommendations\nPresentation skills including creating Keynote/PowerPoint presentations\n\n\nFitbit is proud to be an equal opportunity employer. We recruit, hire, train, promote, pay, and administer all personnel actions without regard to race, color, ancestry, national origin, citizenship, religion, age, sex (including pregnancy, childbirth, and medical conditions related to pregnancy, childbirth, or breastfeeding), sex stereotyping (including assumptions about a person’s appearance or behavior, gender roles, gender expression, or gender identity), sexual orientation, gender, gender identity, gender expression, marital status, medical condition, mental or physical disability, military or veteran status, genetic information or other statuses protected by law. We interpret these protected statuses broadly to include both the actual status and any perceptions and assumptions made regarding these statuses.\n\n San Francisco applicants: Pursuant to the San Francisco Fair Chance Ordinance Fitbit will consider for employment qualified applicants with arrest and conviction records."},{"jobtitle":"Data Engineer II- FT- Informatics- INTEGRIS Corporate in OKC","companyname":"INTEGRIS Health","companyid":"17069","address":"","geo":"Oklahoma City, OK, US","postDate":"Nov 05 2018","views":"10","applicants":"0","employees":"5001-10000","jobDetails":[{"level":"Entry level","industry":["Insurance","Health, Wellness & Fitness","Hospital & Health Care"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nData Engineer II, Full Time, Informatics, INTEGRIS Corporate\n\n Job Code: 7367\n\nPosition Summary\n\nThe Data Engineer II designs and builds enterprise data models in tabular and multi-dimensional formats on Microsoft BI platform from structured and unstructured data sources to meet business data mining and analysis needs. Designs and builds analytical self-service tool sets for ease of use self-service BI for end-users and scales analytic self-service tools sets to meet organizational growth requirements. Models and designs data structures to ensure cross enterprise data source integrity, alignment and facility for multi-domain analysis bridging financial, quality, claims and operational data enabling novel analyses and ensuring effective return on data investments across the enterprise. Uses healthcare, financial and operational knowledge to augment outcome metrics with process metrics through mapping workflows to clinical and operational human interface systems. Uses enterprise model data structures to create machine learning APIs for improved alerting, population health segmentation, risk assessment and forecasting throughout the enterprise. Works with informatists to create discrete measurement of processes for inclusion in enterprise data model alongside outcome metrics for strategic improvement through real-time feedback to end-users. Incorporates an understanding of human systems engineering to design and implement effective data visualizations to drive behavior change and resulting in improvement of key business and healthcare processes. Provides direction and guidance and support to junior technical staff.\n\n INTEGRIS Health is an Equal Opportunity/Affirmative Action Employer.\n\nEssential Functions\n\nThe Data Engineer II essential functions include but are not limited to:\n\nPrepares executive briefings and presents findings to owning service lines and customers\nArchitects and implements enterprise data models in tabular and multi-dimensional formats on Microsoft BI platform\nLeads enterprise data coordination efforts to champion alignment between enterprise data model efforts and production reporting\nBuilds analytical self-service tool sets for ease of use self-service BI for end-users enterprise wide\nModels data to ensure across enterprise data source integrity, alignment and facility for multi-domain analysis\nIncorporates an understanding of human systems engineering to design and implement effective data visualizations for enterprise wide impact\nCreate machine learning APIs for improved alerting and forecasting across the enterprise\nConducts current state analysis and develops, recommends, and documents customer requirements\nIs able to write queries including compile, code, categorize, calculate, tabulate, audit and verification in a source control environment\nProvides direction and guidance and support to junior technical staff\nTransforms user requirements into logical structured computer program design\nArchitects advanced analytic systems\nReviews software upgrades and releases and follows established guidelines for system change control\nFollows established guidelines for reviewing and resolving incidents, requests, and tasks to ensure high customer engagement and satisfaction\nProvides support to staff and vendors as projects move from design and planning to operational status\nSupports BI workflows; provides strategic technical and analytical data source assessment of new financial, clinical, or enterprise systems software products to ensure long term viability, alignment and integration with existing analytical tool sets and enterprise data stores\nProvides ongoing and regular reviews of incidents, requests, and tasks to ensure high customer engagement and satisfaction\n\nAccountability\n\nReports to the Administrative Director of Provider Informatics, CMIO\n\nRequired Physical Demands (Subject To Reasonable Accommodation)\n\nKeyboarding/Dexterity: Frequently; activity exists from 1/3 to 2/3 of the time\n\n Standing/Walking: Occasionally; activity exists up to 1/3 of the time\n\n Strength (Lift/Carry/Push/Pull): Light (Exerting up to 20 pounds of force occasionally, or up to 10 pounds of force frequently)\n\n Talking (Must be able to effectively communicate verbally): Yes\n\n Seeing: Yes\n\n Hearing: Yes\n\n Color Acuity (Must be able to distinguish and identify colors): No\n\n This position may have additional or varied physical demand and/or respiratory fit test requirements. Please consult the Physical Demands Project SharePoint site or contact Risk Management/Employee Health for additional information.\n\nEnvironmental Conditions\n\nNormal office environment\n\n Position may require up to 10% travel to include all INTEGRIS facilities\n\n All applicants will receive consideration regardless of membership in any protected status as defined by applicable state or federal law, including protected veteran or disability status.\n\nQualifications\n\nBachelors degree in computer science, engineering or mathematics and 6 years of experience in a business related field or MBA or MS in a related field\nPrevious experience with financial, clinical or web based systems computing preferred\nPrevious experience in tabular or multidimensional data modeling on the Microsoft platform and experience with data mining with Hadoop clusters\nPrevious experience working in a source controlled team development environment\nSQL, C#, python coding experience required\nSAS, R, DAX, pig, hive, and C coding experience preferred\nMust be able to communicate effectively in English (verbal/written)\nMust obtain Epic certification or proficiency within 6 months of hire\nMust obtain MCSA Machine learning certification (exams 70-773/4) within 6 months of hire\nMust obtain MCSA BI Development certification (exams 70-767/8) within 12 months of hire\nMust maintain Epic certification or proficiency on current version\n"},{"jobtitle":"Data Engineer","companyname":"MSX International","companyid":"","address":"","geo":"Southfield, MI, US","postDate":"Nov 05 2018","views":"7","applicants":"1","employees":"","jobDetails":[{"level":"Entry level","industry":["Logistics & Supply Chain","Automotive","Management Consulting"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nMSX International is currently seeking a Data Engineer. The successful candidate must have the following skills and experience:\n\nSummary\n\nAs a Data Engineer you will support GRI's Global Data & Analytics team and will be responsible for creation and maintenance of databases, tables, data flows, and reporting dashboards covering every aspect of the company's activities. You will understand the nuances of the data and ensure that each field in each table is properly named, populated, documented, and used. You will maintain high data quality and integrity by identifying and eliminating ambiguity, duplication, data errors, and inefficient data flows. The data that you maintain is a key strategic and competitive advantage for GRI, and will form the backbone of analysis that drives the company's business decisions.\n\nEssential Duties And Responsibilities\n\nDesign, develop, document, and test advanced data systems that bring together data from disparate sources, making it available to data scientists, analysts, and other users using scripting and/or programming languages (Python, Java, C, etc.)\n\n Evaluate structured and unstructured datasets utilizing statistics, data mining, and predictive analytics to gain additional business insights\n\n Design, develop, and implement data processing pipelines at scale\n\n Present programming documentation and design to team members and convey complex information in a clear and concise manner\n\n Extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes\n\n Write and refine code to ensure performance and reliability of data extraction and processing.\n\n Communicate with all levels of stakeholders as appropriate, including executives, data modelers, application developers, business users, and customers\n\n Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests\n\n Partner with clients to fully understand business philosophy and IT Strategy; recommend process improvements to increase efficiency and reliability in ETL development\n\n Collaborate with Quality Assurance resources to debug code and ensure the timely delivery of products.\n\n Some of our technologies might include: HDFS, Cassandra, Spark, Java, Scala, Informatica, SQL Server, Oracle, Ab Initio, Kafka\n\nKnowledge, Skills, And Abilities\n\nA successful candidate will have hands-on experience in a multitude of domains; including, but not limited to database design, data warehousing, business intelligence, big data, database tuning, application optimization, security, virtual computing and storage, incident tracking, and general database administration\n\n Three or more years' experience including enterprise data warehouses, business intelligence, and MDM\n\n Knowledge and familiarity with concepts in predictive analytics\n\n Experience building and optimizing 'big data' data pipelines, architectures and data sets.\n\n Expert level knowledge of Microsoft SQL Server\n\n Expert level knowledge of SQL administration, engineering, and monitoring tools\n\n Expert level knowledge of designing, constructing, administering, and maintaining data warehouses\n\n Solid experience working with SSIS and SSRS or similar tools\n\n Solid experience with change control and agile methodologies\n\n Experience with Performance Tuning\n\n Passion for using data to effectively support business needs.\n\n Excellent written and verbal communication skills\n\n Ability to juggle and prioritize multiple projects simultaneously\n\n Must be a motivated self-starter who can work independently, but also seeks out opportunities to work collaboratively with others\n\n Must have experience working directly with senior business leaders to understand objectives and articulate the value of business intelligence solutions\n\n Must be comfortable dealing with changing priorities and timelines\n\nExperience With The Following Tools And Technologies Preferred\n\nCloudera Hadoop, Spark, Kafka, NiFi, Elastic Search, Hive, Solr\n\n Relational SQL and NoSQL databases\n\n Data visualization tools such as Tableau, Power BI or similar self-service BI products\n\n AWS cloud services such as EC2, EMR, RDS and Redshift\n\n Stream-processing systems such as Storm and Spark-Streaming\n\n Programming languages and related web technologies such as Python, Java, JavaScript, C++, JSON, R, etc.\n\n SUPERVISION\n\n No management responsibilities\n\n EDUCATION and TRAINING\n\n Bachelor's degree in Business Management, Computer Information Systems/Data Management, or other related fields is strongly preferred\n\n WORKING ENVIRONMENT\n\n 40 hours / week\n\n Limited travel is required\n\n Nothing in this job description restricts management's right to assign or reassign duties and responsibilities to this job at any time, and this job description is subject to change at any time\n\n 18-01170"},{"jobtitle":"Data Analyst","companyname":"MSX International","companyid":"","address":"","geo":"Dearborn, MI, US","postDate":"Nov 05 2018","views":"17","applicants":"4","employees":"","jobDetails":[{"level":"Associate","industry":["Logistics & Supply Chain","Automotive","Management Consulting"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nMSX International is currently seeking a Data Analyst. The successful candidate must have the following skills and experience:\n\nAssist in model development, evaluation, and deployment\nHave significant autonomy in conducting research and selecting modeling methodologies\nResearch and apply the latest quantitative techniques toward the solution of important business problems\nReview academic / industry literature, develop and test models, and gain insights from research findings\nPlay a key role in developing analytical solutions with the business engagement teams and business partners\nIdentify new and Client data sources and explore their potential use in developing actionable business insights\nTranslate ideas and theory into solutions the business can use to grow\nHelp maintain and enhance existing models\nProvide training courses and workshops on modeling skills, such as optimization, statistics, simulation etc.\nEnforce quality assurance in project process through technical governance, including identify data issues, model computational problems and provide the best solution\nHave the intellectual curiosity to identify new modeling technologies, methodologies, and software packages\nDemonstrated skills in system dynamic simulation, optimization, and machine learning\nDemonstrated skills in manipulation and data mining / pattern recognition of large structured and unstructured data sets\nHave sense of urgency, pay attention to detail, deliver results and drive excellence\nAbility and desire to quickly adapt to changing business objectives and apply new quantitative techniques and analytics technologies\nAbility to translate complex quantitative methods into easily understood results for all levels of business partners\nExcellent oral and written communication skills\nExperience doing quantitative research using techniques from one or more of the following areas: 1) machine / deep learning, 2) advanced econometrics / statistics, 3) simulation / system dynamics, 4) optimization / mathematical programming\nOne plus years of experience in data manipulation using software tools such as SQL and Alteryx\nOne plus years of experience in at least two of the following languages: R, Python, MATLAB, Java, Scala, Julia, C/C++/C#\n\nEducation Required\n\nPh.D. in a quantitative field such as Statistics, Economics, Mathematics, Physics, Operations Research, Computer Science, Cognitive Neuroscience, Quantitative Social Science, Quantitative Finance\nWill consider candidates with MS degrees and relevant work experience\n\n18-00641"},{"jobtitle":"Data Product Manager/ Analyst/ Scientist","companyname":"Apex Systems","companyid":"4787","address":"","geo":"Chicago, IL, US","postDate":"Nov 05 2018","views":"264","applicants":"28","employees":"1001-5000","jobDetails":[{"level":"Entry level","industry":["Information Technology & Services","Computer Software","Financial Services"],"jobtype":"Full-time","function":["Product Management","Marketing"]}],"description":"Job description\nJob Description\n\nJob #: 881025\n\nData Product Manager (1)\n\nSite: Chicago, IL.\n\nDescription: Job Summary\n Apex Systems, the nation’s 2nd largest IT Staffing firm, is in search of a Data Product Manager. The Data Product Manager will join a team that is on an upward trajectory to enhance the client’s competitive advantage through analytics. This position will contribute to our strategic vision of developing advanced analytics capabilities in support of developing and executing business strategy.\n\n As an ideal candidate —you are obsessed with data. You have natural curiosity and desire to build data products that can improve guest experience and revenue. You are focused on execution and getting things done even in situations with high level of ambiguity. You are an excellent communicator and collaborator and are able to work with a diverse group, get consensus, and drive the product forward. You have an entrepreneurial mind and thrive in an agile environment. You have a passion for using technology to solve problems in a user-centric way. You should have experience taking at least one product from conception to launch.\n\n This position reports to the Director, Analytics and Business Intelligence\n\nKey Responsibilities\n\nProactively work with business units and teams to understand and translate data-driven initiatives and potential ideas into fully developed data products and services\nCreate, manage, communicate & present data analytics strategy, vision and roadmap\nSynthesize ideas and suggestions from stakeholders and users to determine what to build based on business priorities, strategy and vision\nAdvise business units on how to leverage our existing enterprise wide analytics technologies, platforms and data assets in the most effective and efficient manner\nWork alongside Data Scientists, analysts and data engineers to develop data products and services.\nThe position responsibilities outlined above are in no way to be construed as all encompassing. Other duties, responsibilities, and qualifications may be required and/or assigned as necessary\n\n\n\nRequirements Of Data Product Manager\n\nBS degree, preferably in Computer Science, Information Systems or a related discipline or equivalent combination of education and experience. MS degree is plus\n6-10 years of experience in a large organization with responsibility and demonstrated success for developing Data and Analytics products or services\nExcellent communication skills and can confidently communicate to all levels of the business from operational to executive\nExperience in working with cross-functional teams to develop data products and services. Proven ability to build cross functional relationships\nExperience with all things data – exploration, analysis, blending and identification/mitigation of data quality issues\nAbility to dig into the fine details of projects but also articulate product strategy and vision at higher level\nExperience in working with mobile , web and transactional systems\nExperience with user-centric research and design programs.\nExperience with Scrum and working in an agile environment.\nFamiliarity with hospitality or travel industry is a plus.\nTechnology start-up experience, where the need to innovate and execute fast was imperative for success, is a plus.\nOne or more years programming in SQL, R and/or Python.\nExperience with R and/or Python is strongly desired\nExperience with Alteryx or similar analytics tool is preferred\nExperience with Tableau, D3 or other data visualization tools is desired\nFamiliarity with various database technologies—Graph, OLAP, Relational, etc.\nExperience with Microsoft Office suite, especially Word, Excel and Powerpoint.\n\n\n*Please note that as a contract employee with Apex Systems, you'd be eligible for Health, Dental, Vision and Life Insurance; Short Term Disability; Hospitalization Coverage; Direct Deposit; Weekly Pay; Training and Development Programs; Corporate Discounts/Perks and our Referral Program.*\n\nData Analyst - Analytics, Strategy and Innovation (3)\n\nDescription\n\nSite: Chicago, IL.\n\nDescription: Job Summary\n Apex Systems, the nation’s 2nd largest IT Staffing firm, is in search of a data analyst. The Data Analyst will join a team that is on an upward trajectory to enhance the client’s competitive advantage through analytics. This position will contribute to our strategic vision of developing advanced analytics capabilities in support of developing and executing business strategy. He/She will be a data “polyglot”, will fit into multiple roles and teams to help customers make data driven decisions. He/She will develop skills to take any data and organize it for building a model or also create descriptive/exploratory models. A candidate capable of driving projects to their successful outcomes with effective communication and interpersonal skills will do well.\n\n This position reports to the Manager, Analytics\n\n Collaborate with Project Managers and business stakeholders to execute Analytics projects. This includes outlining specific deliverables, provide input to project plans and milestones.\n\nKey Responsibilities\n\nAnalyze and model structured data using advanced statistical methods and implement algorithms and software needed to perform analyses\nPerform machine learning, natural language, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods\nLeverage data management processes and available infrastructure / Relation data soruces/API tools to develop POC capabilities/solutions\nWork alongside ETL engineers to establish an analytics platform to be used across the business\nUse good Data Engineering process – Preperation, Exploration, Blending, Validation and Quality Control\nThe position responsibilities outlined above are in no way to be construed as all encompassing. Other duities, responsibilities, and qualifications may be required and/or assigned as necessary\n\n\n\nRequirements Of Data Analyst\n\nAt least 3 years of professional experience as a Data Analyst\nExperience with Data Manipulation/wrangling techniques—Preparation, Exploration and Blending.\nExperience in supporting analytics projects in the following areas-- Consumer Insights, Brand Management, Customer Segmentation, Campaign Development, Web Analytics and Media/Message Mix Modeling\nKnowledge in a professional or academic setting on a range of analytical techniques (e.g. Supervised and Un-supervised machine learning techniques, graph data based analytics, statistical analysis, time series, geospatial, nlp, sentiment analysis, pattern detection to name a few)\nGood understanding of data manipulation/wrangling techniques\nExperience with command-line scripting, data structures and algorithms and ability to work in a Linux/Windows environment, processing large amounts of data in an on-premise and/or cloud environment\nExcellent verbal and written communication skills as well as interpersonal and influencing skills; ability to define and capture business needs along with articulating strategic implications of analytic results with clarity and persuasiveness in an audience appropriate manner.\nMasters in a quantitative field: computer science, econometrics, mathematics, statistics, analytics, or other related field\nOne or more years programming in SQL, R and/or Python.\nExperience with R and/or Python is strongly desired\nExperience with Spark is desired\nExperience with Alteryx is preferred\nExperience with Tableau or other data visualization tools is desired\nExpert in Microsoft Office suite, especially Word, Excel and Powerpoint\nFamiliarity with data warehousing concept\nExpert in Microsoft Office suite, especially Word, Excel and Powerpoint\nFamiliarity with IBM DB2 and SQL Server (SSRS, SSIS, SSAS) databases.\nFamiliarity with IBM SPSS and SAS tools for data exploration and mining is a plus\n\n\n*Please note that as a contract employee with Apex Systems, you'd be eligible for Health, Dental, Vision and Life Insurance; Short Term Disability; Hospitalization Coverage; Direct Deposit; Weekly Pay; Training and Development Programs; Corporate Discounts/Perks and our Referral Program.*\n\nData Scientist - Analytics, Strategy and Innovation (1)\n\nDescription\n\nSite: Chicago, IL.\n\nDescription: Job Summary\n Apex Systems, the nation’s 2nd largest IT Staffing firm, is in search of a Data Scientist. The Data Scientist will join a team that is on an upward trajectory to enhance the client’s competitive advantage through use of data to make decisions. Our vision is also to explore and understand our Customer data while building statistical models for both prediction and description of data for our customer.\n\n As the Data Scientist on the Analytics Team, you will have the opportunity to provide key input into the client’s analytics strategy. The Analytics Team is responsible for building a unified platform to handle the various data analysis workloads across the company. You will work with key stakeholders across all our business units to design, build, and operationalize their strategic analytics objectives. This is position will have significant influence into the future direction of the Analytics Team.\n\n A candidate capable of driving projects to their successful outcomes with effective communication and interpersonal skills will do well.\n\n This position reports to the Director, Analytics\n\nKey Responsibilities\n\nCollaborate with Project Managers and business stakeholders to execute Analytics projects. This includes outlining specific deliverables, provide input to project plans and milestones.\nAnalyze and model structured data using advanced statistical methods and implement algorithms and software needed to perform analyses\nPerform machine learning, natural language, and statistical analysis methods, such as classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and validation methods\nLeverage data management processes and available infrastructure / Relation data sources/API tools to develop POC capabilities/solutions\nWork alongside ETL engineers to establish an analytics platform to be used across the business\nUse good software engineering practices (appreciate the importance of good coding practices to DS, unit testing, version control using git, code review)\nAbility to conduct large scale projects and research through all stages: concept formulation, definition of metrics, determination of appropriate statistical methodology, research evaluation, and final research report\nMentor other team members as needed\nThe position responsibilities outlined above are in no way to be construed as all encompassing. Other duties, responsibilities, and qualifications may be required and/or assigned as necessary\n\n\n\nRequirements Of Data Analyst\n\nAt least 3 years of professional experience as a Data Scientist\nDetailed knowledge on a range of analytical techniques (e.g. Supervised and Un-supervised machine learning techniques, graph data based analytics, statistical analysis, time series, geospatial, nlp, sentiment analysis, pattern detection to name a few)\nGood understanding of data manipulation/wrangling techniques\nExperience with command-line scripting, data structures and algorithms and ability to work in a Linux/Windows environment, processing large amounts of data in an on-premise and/or cloud environment\nAutomate the model building process\nGood data modeling intuition\nProven ability to influence and work with cross-functional teams. Significant skill required to work effectively across internal functional areas in situations where clear parameters may not exist.\nStrong work ethic and personal integrity; self-directed and self-motivated with a highly developed curiosity and willingness to learn and to teach.\nExcellent verbal and written communication skills as well as interpersonal and influencing skills; ability to define and capture business needs along with articulating strategic implications of analytic results with clarity and persuasiveness in an audience appropriate manner\nMS/PhD in a quantitative field: computer science, econometrics, mathematics, statistics, analytics, or other related field\nThree or more years programming in R and/or Python\nThe candidate should have strong knowledge of database concepts and SQL\nExperience with Spark is desired\nExperience with h2o is preferred\nExperience with Alteryx is preferred\nExperience with Tableau or other data visualization tools is desired\nExpert in Microsoft Office suite, especially Word, Excel and PowerPoint\nFamiliarity with data warehousing concepts\nExpert in Microsoft Office suite, especially Word, Excel and PowerPoint\nFamiliarity with IBM DB2 and SQL Server (SSRS, SSIS, SSAS) databases.\nFamiliarity with IBM SPSS and SAS tools for data exploration and mining is a plus\n\n\n*Please note that as a contract employee with Apex Systems, you'd be eligible for Health, Dental, Vision and Life Insurance; Short Term Disability; Hospitalization Coverage; Direct Deposit; Weekly Pay; Training and Development Programs; Corporate Discounts/Perks and our Referral Program.*\n\n EEO Employer\n\n Apex is an Equal Employment Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at 844-463-6178"},{"jobtitle":"Senior Systems Analyst - Info Delivery","companyname":"Belk","companyid":"9499","address":"","geo":"Charlotte, NC, US","postDate":"Nov 05 2018","views":"34","applicants":"5","employees":"10001","jobDetails":[{"level":"","industry":["Apparel & Fashion","Retail"],"jobtype":"Full-time","function":["Engineering","Information Technology"]}],"description":"Job description\nThe Information Delivery team at Belk is embarking on an exciting multi-year journey to modernize our analytical foundation and transform the way our business uses these tools and technologies to derive more value. Our team is growing and this is your chance to gain or extend your experience with cloud-based data and BI platforms.\n\n We are looking for a high-performing individual that is creative, team-oriented, customer focused and results-driven. You should be passionate about delivering exceptional results and learning new technologies. If you want to join a team that values your input and will provide the opportunity for you to grow in your career, we want to hear from you.\n\n The Sr. Systems Analyst provides technical expertise related to information delivery application teams. Works with cross functional teams to define functional and technical requirements for new development and any support related changes to Analytics, Integration, Data Warehouse and other data specific applications. Designs and develops customization's, conversions, and interfaces to support Belk’s Analytical systems. Creates diagrams and flows to represent system design for project or enhancement requirements. Develops implementation strategy. Accountable and Responsible for production support of applications in for the Information delivery team.\n\nDesigns, develops, tests, correct, and document complex data related programs and scripts from agreed specifications, and subsequent iterations, using analytical standards and tools, to achieve a well-engineered result.\nClarifies functional and technical requirements and influences decisions that lead to accurate self-service analytical applications\nProvides estimates for work effort required.\nDesigns new, and modifies existing, customization's, conversions, and interfaces as necessary.\nAccountable and creates all technical deliverables including technical design specifications, diagrams, flows, and documentation of all configuration changes\nManages the source control repository for all analytical and data related applications.\nWorks with team to provide testing frameworks or conducts system testing as needed.\nDevelops detailed system implementation plan.\nDevelops prototypes and solutions.\nWorks with Security and Operations team to ensure solution compliance.\nWorks with internal and external vendor teams on all support/enhancement/project related activities.\nDesigns and develops support fixes, small enhancements and coding for major projects.\nDevelops components and creates packages to be promoted to production environment by Support/Ops teams.\nProvides testing support for defect fixes.\nProvides warranty period, and often post-warranty, production support for all analytical related applications.\nAssists management in identifying and managing risks, issues, and dependencies.\nDevelops or contributes to project deliverables, such as design documents, user stories and test scripts\nComplies with and demonstrate a sound knowledge of the Systems Development Life Cycle (SDLC) methodology for assigned projects and tasks.\nSupports the Project Manager in pre and post-implementation reviews and incorporating lessons learned into future work and standards.\nProvides input into design and architecture reviews.\nWorks collaboratively with IT, business team members partners, and vendors to understand the architecture and design and as warranted submit change requests for system improvements and resolve the production issues.\nTroubleshoot production issues of different criticalities with appropriate urgency and maintain the application uptime as per defined SLAs.\nPerform incident resolution against established SLAs and ensure proper documentation (SOP) of the solution procedure.\nManage service request queue monitor and fulfill business and product support requests\nRound the clock the commitment to maintain the application availability against business SLAs.\nProactively identify, diagnose, take corrective action and resolve application system incidents and problems.\nDocument, communicate and escalate technical issues, manage to resolution and articulate business impact.\nComply with and help create/update policies and procedures, including standard operating procedures (SOP).\n\n\nMinimum Education & Experience\n\nCollege or university degree in Information Systems, Computer Science or related field\n5+ years of experience as a Software Engineer/Developer, Application Analyst or Data Analyst, which includes hands-on experience with production support, incident response, bug fixes major and minor enhancements as it relates to Data Warehouse, ETL, ELT, Analytical Databases and BI/Analytical tools\n5+ years of experience with testing methodology specific to ETL, ELT, Analytical Databases and BI/Analytical applications\n5+ years of experience in technical design of major and minor enhancements, coding and testing the changes and deploying in production environments.\n\n\nKnowledge / Skills Requirements\n\n5+ years of demonstrated proficiency with SQL, PL/SQL and UNIX Shell Scripting\n5+ years of experience interrogating analytical databases with custom developed and optimized SQL. Preferred databases are Teradata, Oracle, Netezza or other enterprise level analytical database. Redshift, Snowflake or other cloud database experience highly desired.\nExperience developing and customizing dashboard, reports and other objects in an Enterprise class BI/Analytical tool such as MS Power BI, MicroStrategy, Tableau, OBIEE or SSRS. MicroStrategy and Tableau preferred.\nExperience with Advanced Query tool, SSIS, Informatica or other enterprise class data manipulation and transformation tools\nExperience in Java or equivalent object-oriented programming language a plus.\nExperience with Agile methodologies particularly Scrum and proven ability to train others in these processes.\nExperience assisting in the development of complex KPIs\nExperience with data mining and other advanced data processes a plus\nAbility to learn new applications quickly and support them in production.\nAbility to think on both broad and detailed levels\nExcellent analytical abilities. Demonstrated problem solving skills in complex system environment.\nHigh tolerance for ambiguity matched with desire to organize it\nStrong verbal, written and communication and presentation skills\nShould be a team player, with ability to work in a highly collaborative environment\nDemonstrated ability to quickly learn new programming languages and tools\n\n"},{"jobtitle":"Data & Applied Scientist","companyname":"Microsoft","companyid":"1035","address":"","geo":"Redmond, WA, US","postDate":"Nov 05 2018","views":"96","applicants":"9","employees":"10001","jobDetails":[{"level":"","industry":["Computer Hardware","Computer Software","Information Technology & Services"],"jobtype":"Full-time","function":["Engineering","Information Technology"]}],"description":"Job description\nThe Capacity, Supply Chain & Provisioning (CSCP) group within Azure engineering is an exciting and fast evolving engineering group within Microsoft and powering Microsoft’s Cloud First mission. CSCP is responsible for designing, building and operating Microsoft unified global datacenters; managing demand planning and capacity utilization of the unified infrastructure. CSCP supports over 200 online businesses including Azure, Bing, O365, OneDrive, Xbox and Windows branded services.\n\n Are you interested in guiding key business decisions around Microsoft Cloud (Azure) customer bases? Are you interested in honing your data engineering & analytics skills? Do you want to build a cutting-edge highly scalable analytics platform using latest technologies such as Azure Data Lake, Kusto, SQL Server, Power BI, Cosmos?\n\n Cloud Supply Chain & Provisioning Engineering (CSCP-E) Analytics team is looking for an experienced, self-driven, analytical Business Intelligence professional. In this role, you will be intelligent, near real time supply chain analytics platform that provides end to end detailed visibility into supply chain from capacity hand off to fulfillment and uses machine learning to provides insights into potential risks, performance that helps in continuous optimization and cost savings. Our goal is to build an intelligent Supply Chain Analytics platform that provide the right information to the right decision maker at the right time and enables supply chain ecosystem that delivers the right hardware at right times with lowest cost.\n\nResponsibilities\n\nThe right candidate will possess excellent business and communication skills, be able to work with business owners to develop and define key business questions, have experience in building large business intelligence systems. Your responsibility will include the following:\n\n\nDesign, implement and support Supply Chain & Deployment Analytical platform that will enable insights to analyze and measure the rhythm of business\nDeveloping ETL platform to acquire and integrate data from diverse sources like Azure Data Lake, Kusto, SQL Server, Cosmos, flat files etc.\nCreate Near Real Time Data Mart to support business operational requirement\nRecognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation\nCreate reports / dashboards using Microsoft technologies like Power BI.\nContinually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers\nCreate analytical model, performing analyses on data to identify trends, patterns, correlations, and providing insights from data. You will partner and collaborate with engineering groups, business stakeholders to predict Supply Chain & Deployment Milestones and identify risks that will help in proactive mitigation and smooth deployment\n\n\nQualifications\n\nSkills & Qualifications:\n\nBachelor’s degree in Computer Science, MIS, related technical field, or equivalent work experience.\nAt least 5 years of relevant work experience in analytics, data engineering, business intelligence or related field\nBoth technically deep and business savvy enough to interface with all levels and disciplines within the organization\nDemonstrable ability in data modeling, ETL development, and Data warehousing, or similar skills\nDemonstrable skills and experience using SQL with large data sets (e.g. Oracle, SQL Server, Redshift)\nProven track record of successful communication of analytical outcomes through written communication, including an ability to effectively communicate with both business and technical teams\n\n\nPreferred Experience/skills\n\nGraduate degree in computer science, business, mathematics, statistics, economics, or other quantitative field\n7+ years prior experience in a Data Engineer role with a technology company or financial institution.\nKnowledge of Advanced SQL and scripting for automation (e.g. Python, Perl or R)\nExperience with Azure Data Lake, Kusto, Tabular Cube (Analysis Services)\nFamiliarity with statistical models and data mining algorithms\nExperience with Hadoop or other map/reduce \"big data\" systems and services.\nExperience in Data Center Supply Chain business\nExceptional interpersonal and communications (verbal and written) skills.\n\n\nMicrosoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances.\n\n Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.\n\n Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work."},{"jobtitle":"Data Analyst","companyname":"Brooksource","companyid":"18476","address":"","geo":"Atlanta, Georgia, United States","postDate":"Nov 05 2018","views":"624","applicants":"305","employees":"201-500","jobDetails":[{"level":"Mid-Senior level","industry":["Information Technology & Services"],"jobtype":"Contract","function":["Information Technology","Management","Analyst"]}],"description":"Job description\n\nData Analyst\n\nMarietta, GA 30067\n\n3 month contract-to-hire\n\n\n\n\nPosition Purpose:\n\nAs an Analyst for the Home Services organization, you would be apart of analyzing the order process. You would identify, distinguish and analyze multiple components of a problem and then make conclusions using high-level quantitative skills to help drive projects and bring value to the Home Depot through store operations. This would include driving operations processes for specific areas of responsibilities and complete project tasks as assigned by managers. This team is constantly growing due to the nature of the business, and the need for Home Services. If you are a data-guru, a problem solver, and understand SQL/Tableau, please keep reading!\n\n\n\n\nMajor Tasks, Responsibilities & Key Accountabilities:\n\n20%-Review sales/financial analyses (what sold/did not sell; determine which categories have potential to move upward; cost/benefit analysis; data process modeling/analysis of problems, regression analysis).\n\n15%-Identify trends in consumer lifestyle and technology; conduct customer focus groups and analyze/synthesize findings. Scan business/industry trends; scan competitive landscape; analyze consumer data.\n\n25%-Interpret data based on specific knowledge of statistics and procedures used. Provide data to all Directors to support decision making. Provide input on forecast based on knowledge of product and technology.\n\n20%-Provide input on strategy based on knowledge of industry and technology trends. Provide customers with specialized information from a variety of resources. Facilitate workout problem-solving sessions with multiple groups of people.\n\n20%-Synthesize findings and derive conclusions from analyses and make oral/written recommendations to upper management. Execute tasks related to core operations projects and/or process improvements. Execute day to day processes related to their areas of responsibility. Communicate issues and roadblocks related to respective area.\n\n\n\n\n\nAdditional Qualifications: Preferred Qualifications:\n\n1+ years experience with analytical and data mining tools such as Tableau. Retail and/or Call Center knowledge preferred\n\n 2-4 years work experience in data mining, statistical analysis, auditing, and/or forecasting.\n\nExperience building reports/analyses with analytical tools (e.g. Excel, JMP, SAS, Mathematica, SPSS, Tableau, etc.)\n\nStrong relational database skills (Access, SQL Server, Postgres, etc.) and SQL skills (writing complex queries to pull large sets of data, performing analysis using SQL queries) \n\n Ability to process large amounts of data through high throughput computing tools (HTCondor, Hadoop, etc.)\n\nStrong knowledge in statistical analysis and model building using software (R, SAS, etc.)\n\nExperience in data visualization and building dashboards (Tableau, R, Excel, etc.)\n\nUnderstanding of Object Oriented Programming Language (C++, Java, Python, etc.) \n\nProficiency in Excel (Pivot Tables, V-Lookup, Macros, VBA, etc.) is a must"},{"jobtitle":"Data Engineer","companyname":"CapTech Ventures, Inc","companyid":"14241","address":"","geo":"Atlanta, GA, US","postDate":"Oct 29 2018","views":"28","applicants":"3","employees":"501-1000","jobDetails":[{"level":"Entry level","industry":["Information Technology & Services","Computer Software","Management Consulting"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nCompany Description\n\nCapTech is a national IT management consulting firm that bridges the gap between business and technology. We partner with some of the world's most successful companies to design, develop, and manage technical and digital solutions that delight customers, drive insights, and meet strategic objectives.\n\n At CapTech, you’ll experience a flat organizational structure based upon a culture of mutual respect. Here, your career path isn’t set in stone, and you have unlimited potential for growth and the resources to help you achieve your career goals. If you are creative, technically insightful, driven–and have a passion for the work that we do, then you might be a future CapTecher.\n\n For over five years, we have been in the Top 10 of Consulting Magazine’s Best Firms to Work For, including #2 for IT Firms and #5 for Work/Life Balance. We are also recognized by Vault.com’s Top 50 Consulting Firms and have been on the Inc. 5000 list of fastest growing companies for over 10 years.\n\nJob Description\n\nThe Data Engineer, Analytics role falls into the Data Management & Business Intelligence practice area at CapTech, through which our consultants provide a broad spectrum of services to help our clients define and implement a strategy to deliver lasting and mission-critical information capabilities. Our Data Integration consultants bridge the gap between the business and IT side of companies. By partnering with clients to fully understand both their business philosophy and IT strategy, CapTech consultants maintain the vision that data integration should be built to help the organization make better decisions by providing the right data at the right time.\n\nSpecific Responsibilities For The Data Engineer, Analytics Position Include\n\nDesign, develop, document, and test advanced data systems that bring together data from disparate sources, making it available to data scientists, analysts, and other users using scripting and/or programming languages (Python, Java, C, etc)\nEvaluate structured and unstructured datasets utilizing statistics, data mining, and predictive analytics to gain additional business insights\nDesign, develop, and implement data processing pipelines at scale\nPresent programming documentation and design to team members and convey complex information in a clear and concise manner.\nExtract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes.\nWrite and refine code to ensure performance and reliability of data extraction and processing.\nCommunicate with all levels of stakeholders as appropriate, including executives, data modelers, application developers, business users, and customers\nParticipate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.\nPartner with clients to fully understand business philosophy and IT Strategy; recommend process improvements to increase efficiency and reliability in ETL development.\nCollaborate with Quality Assurance resources to debug code and ensure the timely delivery of products.\nSome of our technologies might include: HDFS, Cassandra, Spark, Java, Scala, Informatica, SQL Server, Oracle, Ab Initio, Kafka.\n\n\nQualifications\n\nSpecific qualifications for the Data Engineer, Analytics position include:\n\nBachelor's Degree in Computer Science, MIS, or equivalent combination of education and experience preferred.\nDevelopment experience building ETL graphs using the Ab Initio GDE, EME and Co-Operating system\nStrong SQL development skills\nDevelopment experience with at least two different programming languages preferred (Python, Java, C, etc.)\nDevelopment experience with Unix tools and shell scripts\nDevelopment experience with at least two different database platforms (Teradata, Oracle, MySQL, MS SQL, etc.)\nMinimum of 3 years experience designing, developing, and testing software aligned with defined requirements\nExperience tuning SQL queries to ensure performance and reliability\nSoftware engineering best-practices, including version control (Git, TFS, JIRA, etc.) and test driven development\nExposure to Business Intelligence tools such as Business Objects, Informatica, SSRS, Cognos, MicroStrategy, Tableau, QlikView, SpotFire, etc.\n\n\nAdditional Information\n\n We offer challenging and impactful jobs with professional career paths. All CapTechers can keep their hands on technology no matter what position they hold. Our employees find their work exciting and rewarding in a culture filled with opportunities to have fun along the way.\n\n At CapTech we offer a competitive and comprehensive benefits package including, but not limited to:\n\nCompetitive salary with performance based bonus opportunities\nSingle and Family Health Insurance plans, including Dental coverage\nShort-Term and Long-Term disability\nMatching 401(k)\nCompetitive Paid Time Off\nTraining and Certification opportunities eligible for expense reimbursement\nTeam building and social activities\nMentor program to help you develop your career\n\nAt this time, CapTech cannot transfer nor sponsor a work visa for this position. Applicants must be authorized to work directly for any employer in the United States without visa sponsorship.\n\nCandidates must be eligible to work in the U.S. for any employer directly (we are not open to contract or “corp to corp” agreements).   \n CapTech is an equal opportunity employer.  \n CapTech is a Drug-Free work place. \n Candidates must have the ability to work at CapTech’s client locations.  \n All positions include the possibility of travel.\n CapTech has not contracted/does not contract with any outside vendors in its recruitment process. If you are interested in this position, please apply to CapTech directly."},{"jobtitle":"Senior Data Engineer","companyname":"CapTech Ventures, Inc","companyid":"14241","address":"","geo":"Richmond, VA, US","postDate":"Oct 29 2018","views":"15","applicants":"0","employees":"501-1000","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Computer Software","Management Consulting"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nCompany Description\n\nCapTech is a national IT management consulting firm that bridges the gap between business and technology. We partner with some of the world's most successful companies to design, develop, and manage technical and digital solutions that delight customers, drive insights, and meet strategic objectives.\n\n At CapTech, you’ll experience a flat organizational structure based upon a culture of mutual respect. Here, your career path isn’t set in stone, and you have unlimited potential for growth and the resources to help you achieve your career goals. If you are creative, technically insightful, driven–and have a passion for the work that we do, then you might be a future CapTecher.\n\n For over five years, we have been in the Top 10 of Consulting Magazine’s Best Firms to Work For, including #2 for IT Firms and #5 for Work/Life Balance. We are also recognized by Vault.com’s Top 50 Consulting Firms and have been on the Inc. 5000 list of fastest growing companies for over 10 years.\n\nJob Description\n\nThe Senior Data Engineer, Analytics role falls into the Data Management & Business Intelligence practice area at CapTech, through which our consultants provide a broad spectrum of services to help our clients define and implement a strategy to deliver lasting and mission-critical information capabilities. Our Data Integration consultants bridge the gap between the business and IT side of companies. By partnering with clients to fully understand both their business philosophy and IT strategy, CapTech consultants maintain the vision that data integration should be built to help the organization make better decisions by providing the right data at the right time.\n\nSpecific Responsibilities For The Senior Data Engineer Position Include\n\nDesign, develop, document, and test advanced data systems that bring together data from disparate sources, making it available to data scientists, analysts, and other users using scripting and/or programming languages (Python, Java, C, etc)\nEvaluate structured and unstructured datasets utilizing statistics, data mining, and predictive analytics to gain additional business insights\nDesign, develop, and implement data processing pipelines at scale\nPresent programming documentation and design to team members and convey complex information in a clear and concise manner.\nExtract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes.\nWrite and refine code to ensure performance and reliability of data extraction and processing.\nCommunicate with all levels of stakeholders as appropriate, including executives, data modelers, application developers, business users, and customers\nParticipate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.\nPartner with clients to fully understand business philosophy and IT Strategy; recommend process improvements to increase efficiency and reliability in ETL development.\nCollaborate with Quality Assurance resources to debug code and ensure the timely delivery of products.\nSome of our technologies might include: HDFS, Cassandra, Spark, Java, Scala, Informatica, SQL Server, Oracle, Ab Initio, Kafka.\n\n\nQualifications\n\nSpecific qualifications for the Senior Data Engineer, Analytics position include:\n\nBachelor's degree in Computer Science, Software Engineering, MIS or equivalent combination of education and experience\nDevelopment experience building ETL graphs using the Ab Initio GDE, EME and Co-Operating system\nStrong SQL development skills\nDevelopment experience with at least two different programming languages (Python, Java, C, etc.)\nDevelopment experience with Unix tools and shell scripts\nDevelopment experience with at least two different database platforms (Teradata, Oracle, MySQL, MS SQL, etc.)\nMinimum of 3 years experience designing, developing, and testing software aligned with defined requirements\nExperience tuning SQL queries to ensure performance and reliability\nSoftware engineering best-practices, including version control (Git, TFS, JIRA, etc.) and test driven development\nExposure to Business Intelligence tools such as Business Objects, Informatica, SSRS, Cognos, MicroStrategy, Tableau, QlikView, SpotFire, etc.\n\n\nAdditional Information\n\n We offer challenging and impactful jobs with professional career paths. All CapTechers can keep their hands on technology no matter what position they hold. Our employees find their work exciting and rewarding in a culture filled with opportunities to have fun along the way.\n\n At CapTech we offer a competitive and comprehensive benefits package including, but not limited to:\n\nCompetitive salary with performance based bonus opportunities\nSingle and Family Health Insurance plans, including Dental coverage\nShort-Term and Long-Term disability\nMatching 401(k)\nCompetitive Paid Time Off\nTraining and Certification opportunities eligible for expense reimbursement\nTeam building and social activities\nMentor program to help you develop your career\n\nAt this time, CapTech cannot transfer nor sponsor a work visa for this position. Applicants must be authorized to work directly for any employer in the United States without visa sponsorship.\n\nCandidates must be eligible to work in the U.S. for any employer directly (we are not open to contract or “corp to corp” agreements).   \n CapTech is an equal opportunity employer.  \n CapTech is a Drug-Free work place. \n Candidates must have the ability to work at CapTech’s client locations.  \n All positions include the possibility of travel.\n CapTech has not contracted/does not contract with any outside vendors in its recruitment process. If you are interested in this position, please apply to CapTech directly."},{"jobtitle":"Data Engineer","companyname":"Great Wolf Lodge","companyid":"37501","address":"","geo":"Madison, Wisconsin Area","postDate":"Oct 29 2018","views":"276","applicants":"24","employees":"5001-10000","jobDetails":[{"level":"Associate","industry":["Hospitality"],"jobtype":"Full-time","function":["Information Technology","Analyst"]}],"description":"Job description\n\nJob Summary:           \n\nThe Data Engineer is responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. The Data Engineer will create processes and data models to enable performance management reporting as well as data science, advanced analytics, and personalization efforts.\n\n \n\nThe Data Engineer will work closely with Technology, Finance, and Commercial Analytics to drive value through best in class data architecture and data model design.\n\n \n\nKey Responsibilities\n\nAct as data strategist responsible for the short and long term vision of data management, warehouse performance, and data architecture supporting both business intelligence and prescriptive analytics\nPartner with both internal stakeholders and external vendors involved in project definition, design and planning, and mapping the data journey from source through consumer (data visualization, application, or predictive model)\nGather, document, and analyze business requirements; establish and prioritize efforts to deliver data models that support business needs\nDesign, develop, test and deploy data models, data collection, and transformation components. Determine best point for transformations, calculations, and joins (e.g. data lake, data warehouse, or Tableau data source)\nTroubleshoot and support existing data workflow processes; deliver fixes and optimizations where appropriate\nWork closely with CIO, Chief Architect, and Chief Analytics Officer on data governance and planning - ensure scalability and sustainability of business intelligence data architecture\n\nRequired Qualifications:\n\n2+ years’ experience building data solutions including AWS S3, EMR, and Redshift, Tableau and Tableau server\nExpert SQL scripting skills; R, Python, or SAS preferred but not required\nAbility to effectively build relationships across the business at all levels\nSelf-starter, entrepreneurial, high-energy who can take initiative in a fast-moving environment\nStrong technical understanding of current and emerging business intelligence and analytics technologies\n\nEducation:\n\nBachelor's Degree in Technology, Computer Science, or Data Science preferred\n\n \n\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or veterans' status."},{"jobtitle":"Data Engineer (DWH)","companyname":"LinkedIn","companyid":"1337","address":"","geo":"Sunnyvale","postDate":"Oct 29 2018","views":"687","applicants":"276","employees":"10001","jobDetails":[{"level":"","industry":["Internet","Information Technology & Services"],"jobtype":"Full-time","function":["Engineering"]}],"description":"Job description\nLinkedIn is a deeply data driven company with data driving not only business decisions but also product features and direction -- data is deeply embedded in the LinkedIn DNA. The company has a diversified business model with revenue coming from Talent Solutions, Marketing Solutions and Premium Subscriptions products.\n\n The Data Analytics and Infrastructure team is responsible for building and maintaining the state-of-the-art ETL infrastructure that makes this data available and accessible to the entire company to make data driven decisions. The team works closely with Data scientists, Product Managers, Executives and other key parts of the business across the globe to understand their data requirements and build appropriate systems and platform that meet or exceed those needs. Data Analytics and Infrastructure team is committed to being an early adopter and contributor to open source big data technologies. Engineers are encouraged to think out of the box and play with latest technologies and explore their limits. LinkedIn is looking for a “Rockstar” Data Warehouse Engineer to help build, scale and maintain the critical data warehouse.\n\n Responsibilities\n\n • Contributing at a senior-level to the data warehouse design and data preparation by implementing a solid, robust, extensible design that supports key business flows.\n • Performing all of the necessary data transformations to populate data into a warehouse table structure that is optimized for reporting.\n • Establishing efficient design and programming patterns for engineers as well as for non-technical peoples.\n • Designing, integrating and documenting technical components for seamless data extraction and analysis on big data platform.\n • Ensuring best practices that can be adopted in Big Data stack and share across teams and BUs.\n • Providing operational excellence through root cause analysis and continuous improvement for Big Data technologies and processes and contributes back to open source community.\n • Contributing to innovations and data insights that fuel LinkedIn’s vision and mission.\n • Working in a team environment, interact with multiple groups on a daily basis (very strong communication skills).\n\n\n Basic qualifications\n\n • BS, MS or PhD in Computer Science or related technical discipline\n • 2+ years of relevant work experience\n • Working experience with Hadoop projects/infrastructure\n • Experience with data warehouse best practices in Big Data space\n • Experience in the Big Data space (Hadoop Stack like M/R, HDFS, Pig, Hive, Flume, Sqoop, etc.\n • Experience with at least one scripting language (Shell, Python, Perl etc.)\n • Experience with an OO programming language like Java.\n\n Preferred qualifications\n\n • 4+ years of relevant work experience\n • Experience working extensively in multi-petabyte DW environment\n • Experience in engineering large-scale systems in a product environment\n • Ability to write, analyze, and debug SQL queries\n • Exceptional Problem solving and analytical skills\n • Experience with Data Warehouse design, ETL (Extraction, Transformation & Load), architecting efficient software designs for DW platform.\n • Knowledge of database modeling and design in a Data warehousing context\n • Knowledge of NoSQL stores is a plus\n • Experienced in implementing data warehouses with MPP databases like Teradata. [is a plus]\n • Ideal candidates will have a deep understanding of technical and functional designs for Databases, Data Warehousing, Reporting, and Data Mining areas\n • Passion for about continuous learning, experimenting, applying and contributing towards cutting edge open source Big Data technologies and software paradigms\n"},{"jobtitle":"Data Engineer","companyname":"MoonVu","companyid":"","address":"","geo":"1111 Broadway, Oakland, California","postDate":"Oct 29 2018","views":"457","applicants":"222","employees":"","jobDetails":[{"level":"Entry level","industry":["Investment Banking","Investment Management","Capital Markets"],"jobtype":"Full-time","function":["Analyst","Finance","Supply Chain"]}],"description":"Job description\n\nMoonVu is looking for a Data Engineer that will help us discover the information hidden in vast amounts of data, and help us make smarter trading decisions. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems in the context of algorithmic selection/trading.\n\n\n\n\nResponsibilities\n\n·   Selecting/creating features from raw data, and building/optimizing classifiers using machine learning techniques\n\n·   Data mining using state-of-the-art methods\n\n·   Extending the data used in modeling with third party sources of information\n\n·   Processing, cleaning, and verifying the integrity of data used for analysis\n\n·   Doing ad-hoc analysis and presenting results in a clear manner\n\n·   Creating automated data consistency checks (e.g. between live/historical data) and unit testing techniques to ensure ongoing model performance\n\n\n\n\nSkills and Qualifications\n\n·   Experience with supervised/unsupervised machine learning techniques, especially tree-based algorithms and k-means clustering. Neural networks experience is a plus, especially with RNNs and CNNs\n\n·   Experience modeling and making sense of complex systems.\n\n·   Advanced skills in Python- especially Pandas. Must be able to output code in Python at a rapid rate\n\n·   Must have at least 4 years of coding experience. Doesn’t matter what language- applicant must have a strong underlying coding ability\n\n·   Must have strong applied statistics skills, such as understanding of distributions, hypothesis testing, and probability\n\n·   Must have a passion for trading/investing. Any past trading/investing experience, either personally or professionally, is a plus\n\n·   Great communication skills and experience with data visualization tools in Python\n\n·   Proficiency in SQL is a plus. Must be able to write basic queries at minimum\n\n·   Experience with high performance computing is a plus (e.g. cluster computing on AWS with Spark/Hadoop)"},{"jobtitle":"Data Analyst","companyname":"TBC Corporation","companyid":"","address":"","geo":"Palm Beach Gardens, FL, US","postDate":"Oct 29 2018","views":"17","applicants":"6","employees":"","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Retail","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nDescription\n\nGeneral Summary:\n\n Reporting to a manager of Strategic Analytics, the Data Analyst I will conduct business analysis / data science using various techniques, including: complex data preparation and manipulation, statistical analysis, explanatory analysis and predictive modeling to facilitate business decision-making across TBC Corporation.\n\n This high-profile position touches all aspects of TBC's business, encompassing data analysis work for Retail, eCommerce, Wholesale, Franchise, and shared services teams. With an eye to business value and impact, you will interact with leaders across the organization providing key insights to help them optimize their business.\n\n You will work directly with the internal or external clients to identify analytical requirements and work under a manager to determine the most appropriate analysis to facilitate business decision-making.\n\n You must be flexible in responding to changing priorities and able to manage several ongoing concurrent projects.\n\nPrimary Responsibilities\n\nWork independently on complex data analysis, business analytics, and data mining tasks on large data sources.\nInterpret data, analyze results using calculations, complex logic, statistical analysis and other quantities techniques.\nAcquire data from multiple data sources and maintain data for use in future analysis\nIdentify, analyze, and interpret trends or patterns in complex data sets.\nIdentify data anomalies and determine the most appropriate resolution\nUse data to create models that depict trends in the customer base and the consumer population as a whole.\nWork within multidisciplinary, cross-department teams on large-scale projects.\nAssist management in prioritizing business and information needs.\nAssist management in identifying and recommending new ways to save money by streamlining business processes\nPerform other duties as required or assigned.\n\nEducation\n\nMinimum Requirements\n\n High School Diploma Required.\n\n Bachelor's Degree in a quantitative field such as Data Science, Engineering, Mathematics, Computer Science, MIS, Statistics, Applied Mathematics, or other related field is preferred.\n\nExperience\n\n1-2 years of data analysis experience required.\n\n 1-2 years of experience with reporting packages (Tableau etc), programming (XML, Javascript, EDI and ETL frameworks) preferred.\n\n 1 year of knowledge and/or experience in statistics and the use of statistical packages for analyzing datasets (R, SPSS, SAS etc.) preferred\n\n 1 year experience with using SQL, Alteryx or other similar tools to assemble and prepare data from relational or multiple disparate sources preferred\n\nQualifications\n\nKnowledge of data mining, analysis, and modeling, of large scale, complex data sets.\nDemonstrated history of success, with a strong attention to detail.\nStrong quantitative, analytical, problem solving, and critical thinking skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with detail and accuracy.\nWorking knowledge of database and software tools to support data analysis and reporting.\nWorking knowledge of data querying and analytics tools, processes and methodology.\nExcellent verbal, written, and communication skills with the ability to effectively and clearly communicate and present ideas to senior leadership\nAbility to work independently as well as within a team environment\nAbility to balance multiple responsibilities and adapt to changing priorities\nAbility to learn in a fast-paced environment.\nGood time management, organizational and interpersonal skills.\nIntermediate Microsoft Office skills: MS Access, Excel, Word, PowerPoint.\nSelf-Starter.\n\nTBC Corporation TBC continuously offers strong career opportunities to those from inside as well as outside the auto services industry. We hire those with a passion for success and we will train them with proven processes that will take them there. Our employees share a very unique and lucrative opportunity to maximize their earnings with industry leading pay, incentives, and recognition programs when they deliver and exceed expected results."},{"jobtitle":"Associate Data Analyst","companyname":"Iron Mountain Information Management, LLC","companyid":"","address":"","geo":"Boston, MA, US","postDate":"Oct 29 2018","views":"13","applicants":"1","employees":"","jobDetails":[{"level":"Associate","industry":["Marketing & Advertising","Staffing & Recruiting","Human Resources"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nFounded in 1951, Iron Mountain Incorporated (NYSE: IRM) is the global leader in storage and information management services. Iron Mountain is committed to storing, managing and transforming what our customers value most, from paper records to data to priceless works of art and culture. Providing a full suite of solutions - records and information management, data management, digital solutions, data centers and secure destruction - Iron Mountain enables organizations to lower storage costs, comply with regulations, recover from disaster, and protect their data and assets from a complex world. Visit the company website at www.ironmountain.com for more information.\n\n Iron Mountain enables 94% of the Fortune 1000 to smartly and securely manage their physical and digital information assets. With unmatched innovation and collaboration, our teams create information management solutions for our customers’ data, no matter what format, location or lifecycle stage it’s in and no matter where it’s kept. We are more than 17,000 people strong and growing. We’ve been a trusted records management leader since 1951.\n\n Iron Mountain is an equal opportunity employer, and does not unlawfully discriminate on the basis of race, color, religion, sex, national origin, marital status, age, sexual orientation, gender identity characteristics or expression, disability, medical condition, U.S. Military or veteran status or other legally protected classifications in making employment decisions.\n\n Iron Mountain Canada is an employer broadly committed to providing an inclusive work environment that welcomes all people. Globally, we believe it is our diversity that contributes to our companies’ shared success. We work hard always to avoid discriminating on any grounds other than capability to perform the requirements of the job.\n\n Iron Mountain complies with the Accessibility for Ontarians with Disabilities Act and welcomes and encourages applications from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process.\n\n This Associate Data Analyst role is responsible for analyzing large, real-time and historical data sets, data mining, statistical analysis, and data visualization. Models created will provide the insights necessary to improve overall business performance. This role requires a problem solver capable of working with diverse systems and data.\n\n Periodically, the Associate Data Analyst will be asked to work with various business groups testing, and implementing functional business models. The role requires the ability to analyze large data sets and to carefully review outputs for quality with the Director of Customer Insights.\n\nSummary Of Key Responsibilities\n\nDefine, prepare, and analyze business models for various business functions. This will require gathering information from a variety of source systems and applications. Data volume can be substantial, so the ability to detect errors/outliers important.\n\n Knowledge, familiarity, with systems used in the development of business analytics: Business Intelligence; CRMs; Statistical software (SAS, R, Python, etc.); Visualization (Tableau).\n\n Familiarity with programming languages used in statistical learning: R, SQL, Python, etc. Experience with open-source technologies - (R) preferred.\n\n Familiarity with a variety of statistical methods: Factor Analysis, Cluster Analysis, Survival Analysis, Logistic & Linear Regression, Hypothesis Testing, Segmentation, etc.\n\nArea Of Impact\n\nFinance\nSales\nProduct Management\nMarketing\nRevenue Management\nOperations\nBachelor’s Degree in statistics, analytics or computer science (or equivalent work experience). This role is an entry-level role and will work under the supervision and guidance of the Director of Customer Insights.\nMust be able to communicate model performance effectively with users, team members and management. Flexibility and willingness to take on varied tasks as assigned is essential.\nThis role assists in evaluating and reporting business performance. Based on the findings, the data is then screened for quality before business action taken.\nKnowledge, or education, in the field of statistics, analytics, or computer science\nCapable of formulating basic business models\nUnderstanding of data structures\nKnowledge of the systems necessary to run statistical models\nCapable of preparing visualization according to end user need"},{"jobtitle":"Lead Data Analyst","companyname":"Hallmark","companyid":"","address":"","geo":"Kansas City, MO, US","postDate":"Oct 29 2018","views":"6","applicants":"0","employees":"","jobDetails":[{"level":"Associate","industry":["Marketing & Advertising","Consumer Goods","Retail"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nreqid: 23262\n\nWHEN YOU CARE ENOUGH YOU CAN CHANGE THE WORLD.\n\nYou need a job. You want a career. Working someplace you can be yourself and belong while creating something that makes a difference. Something that makes the world a better place. Perfect timing. Hallmark is looking for someone like you.\n\n People rely on us to help them connect and express their emotions through products and services that enrich lives every day. They trust that we know their needs and that we are focused on innovations that will allow them to enhance their relationships. We have a competitive mindset and “play to win” with our retailers and consumers. We work with courage and conviction, always seeking to adapt and learn. It is an exciting time to be in the Greetings business at Hallmark!\n\nWe Are Looking For\n\nHallmark is in the midst of a data analytics revolution and we need a talented senior-level Data Analytics Lead to join our Customer Analytics team. Hallmark’s mission is to inspire people everywhere “to live a caring, connected life full of meaningful moments”. We can only do that by understanding how people connect with those who mean the most to them.\n\n We are seeking innovative individuals who are energized by solving complex business problems that leverage a myriad of data and information. People who are passionate about driving analytical thought within our customer teams and throughout the Hallmark Analytics community. We’re looking for people who bring an inquisitive mind to solve complex business, analytics and statistical issues and have the necessary tools to take it to the next level.\n\nWho We Are\n\nThe Customer Analytics team under Category Solutions provides powerful consulting along with key reporting and insightful analyses to the Greetings business. We focus on using data to understand our category and customers, leveraging a vast amount of sources to our advantage. We focus on complete storytelling, from understanding what has happened in the past to conducting predictive analysis to understand the future. We are looking for motivated individuals who love exploring data to uncover hidden trends and developing new experiments and models to help drive the business.\n\nIn This Role You Will\n\nServe as the key analytics consultant for the CVS customer team and serve in an integral role by leveraging data and analytical thought leadership to develop solutions and tactics for the customer team\nBe the expert of the CVS business and data sources, including how to best leverage advanced analytics, reporting, experimentation, predictive analytics and more to create data-driven solutions and strategies aimed to grow the business\nSummarize and monitor performance, uncover hidden trends, assess opportunities for growth and provide robust solutions leveraging data-driven insights and business acumen\nRegularly present findings to CVS customer team leadership and business customers, both internal and external, who have varying expertise in analytics and statistics\nIndependently strive to make the business better every day by exploring the data and find new opportunities to drive growth in CVS\nHelp train both analytics and non-analytics staff in new skills and techniques.\n\n\nApplication Instructions\n\nYou must show how you meet the basic qualifications (listed below) in a resume or document you upload, or by completing the work experience and education application fields. Accepted file types are Microsoft Word (DOC or DOCX), PDF, HTML, or TXT.\n\n In compliance with the Immigration Reform and Control Act of 1986, Hallmark Cards, Inc. and its subsidiary companies will hire only individuals lawfully authorized to work in the United States. Hallmark does not generally provide sponsorship for employment. Employment by Hallmark is contingent upon the signing of the Employment Agreement, signing of an agreement to arbitrate in connection with the Hallmark Dispute Resolution Program, completing Form I-9 Employment Eligibility Verification, passing the urinalysis drug screen, education verification and satisfactory reference and background checks.\n\nBasic Qualifications\n\nThe following is required to be considered for this role:\n\nBachelor’s degree in Business or quantitative field (Data Science, Statistics, Analytics, Economics, Mathematics, Computer Science).\n2+ years’ experience in an advanced analytics or strategy role.\n1+ years of professional using statistical programming languages (SAS, R, Python, etc), SQL and/or data visualization tools (Tableau, etc)\n\n\nPreferred Qualifications\n\nYour resume will stand out if you have:\n\nAdvanced Degree in one of the above fields\nExpertise in at least one (1) statistical programming language (Python, R, Scala, Octave, SAS, MATLAB, etc.)\nExpertise in basic to intermediate statistical methods and experimentation, including ANOVA, predictive analysis, regression, data mining, etc.\nProven track record of simplifying large and complex problems, working with a multiple of data sources and techniques to uncover data-driven solutions and actionable insights that drive business results\nExpertise in presenting to both internal and external business customers with varying experience in advanced analytics and data science.\nExperience with CPG and/or Retail data, including transactions, assortment planning, supply chain, financial data, etc.\nExperience with data visualization tools including Tableau, Dash, RShiny, D3.js, Microstrategy, etc.\nStrong desire to combine rich business acumen and explore various data sources to uncover hidden trends and opportunities for the organization\nAble to provide a GitHub or coding portfolio of prior advanced analytics, data science, computer programming and statistical work and projects\nSelf-directed, detail & team oriented with highly developed problem solving and analytical skills\nExcellent communication skills, both written and verbal, coupled with strong organizational, planning and interpersonal skills\n\nHallmark believes in enriching the lives of our employees by offering benefit programs to help you:\n\nTake care of you and yours: We offer comprehensive medical, dental and vision benefits, as well as discounts on elder care, child care, education assistance and adoption assistance.\nSave for your future: Through profit sharing, you share in the success of Hallmark. We also offer a 4% match on 401(k) contributions.\nEnjoy your time: Maximize your work-life balance through Paid Time Off (PTO), paid holidays, community volunteer opportunities and discounts on product, entertainment venues, amusement parks and sporting events.\nAnd More! (Like an on-site cafeteria, free parking, access to Crown Center and a fitness center.)\n\nHallmark is an equal opportunity employer. All qualified applicants will be considered for employment without regard to race, color, religion, sex, age, pregnancy, national origin, physical or mental disability, genetics, sexual orientation, gender identity, veteran status, or any other legally-protected status. Principals only please."},{"jobtitle":"Associate Data Analyst","companyname":"Iron Mountain","companyid":"3780","address":"","geo":"Tampa, Florida","postDate":"Oct 29 2018","views":"1,020","applicants":"487","employees":"10001","jobDetails":[{"level":"Associate","industry":["Information Technology & Services"],"jobtype":"Full-time","function":["Information Technology","Administrative"]}],"description":"Job description\nOverview\n\n\n\n\nResponsible for analyzing large, real-time and historical data sets, data mining, statistical analysis, and data visualization. Models created will provide the insights necessary to improve overall business performance. This role requires a problem solver capable of working with diverse systems and data.\n\n\n\n\nThe Associate Data Analyst position is responsible developing analytics using established technology resources. The Associate Data Analyst works under the instruction and supervision of the Director of Customer Insights. Periodically, the Associate Data Analyst will be asked to work with various business groups testing, and implementing functional business models. The role requires the ability to analyze large data sets and to carefully review outputs for quality with the Director of Customer Insights.\n\n \n\n\n\n\n\n\n\nSummary of key responsibilities:\n\n \n\nDefine, prepare, and analyze business models for various business functions. This will require gathering information from a variety of source systems and applications. Data volume can be substantial, so the ability to detect errors/outliers important.\n\n \n\nKnowledge, familiarity, with systems used in the development of business analytics: Business Intelligence; CRMs; Statistical software (SAS, R, Python, etc.); Visualization (Tableau).\n\n \n\nFamiliarity with programming languages used in statistical learning: R, SQL, Python, etc. Experience with open-source technologies - (R) preferred.\n\n \n\nFamiliarity with a variety of statistical methods: Factor Analysis, Cluster Analysis, Survival Analysis, Logistic & Linear Regression, Hypothesis Testing, Segmentation, etc.\n\n\n\n\nSummary of key responsibilities:\n\n \n\n·       Knowledge, or education, in the field of statistics, analytics, or computer science\n\n·       Capable of formulating basic business models\n\n·       Understanding of data structures\n\n·       Knowledge of the systems necessary to run statistical models\n\n·       Capable of preparing visualization according to end user need\n\n \n\n Area of Impact:\n\nFinance\nSales\nProduct Management\nMarketing\nRevenue Management\nOperations\n\n\n\n\nExperience, Skills and Attributes: \n\n\n\n\nBachelor’s Degree in statistics, analytics or computer science (or equivalent work experience). This role is an entry-level role and will work under the supervision and guidance of the Director of Customer Insights.\n\nMust be able to communicate model performance effectively with users, team members and management. Flexibility and willingness to take on varied tasks as assigned is essential.\n\nThis role assists in evaluating and reporting business performance. Based on the findings, the data is then screened for quality before business action taken.\n\nKnowledge, or education, in the field of statistics, analytics, or computer science\nCapable of formulating basic business models\nUnderstanding of data structures\nKnowledge of the systems necessary to run statistical models\nCapable of preparing visualization according to end user need\n\n \n\n\n\n\n\nCompliance Obligations\n\nIt is the responsibility of every Iron Mountain employee:\n\nto comply with all applicable laws, rules, regulations, and company policies\nto exhibit ethical behavior in accordance with our Code of Ethics and Business Conduct\nto complete required training within the allotted time frame\n\n\nIron Mountain is an equal opportunity employer, and does not unlawfully discriminate on the basis of race, color, religion, sex, national origin, marital status, age, sexual orientation, gender identity characteristics or expression, disability, medical condition, U.S. Military or veteran status or other legally protected classifications in making employment decisions.\n\nRequisition # 2018-19301\n\nCategory : Sales\n\nType Full-Time\n\nWork From Home (Virtual) No"},{"jobtitle":"Sr. Associate, Data Engineer, Financial Services","companyname":"KPMG US","companyid":"1079","address":"","geo":"Irvine, CA, US","postDate":"Oct 29 2018","views":"16","applicants":"2","employees":"10001","jobDetails":[{"level":"Mid-Senior level","industry":["Management Consulting"],"jobtype":"Full-time","function":["General Business"]}],"description":"Job description\nRequisition Number: 37016 - 6\n\nDescription\n\nInnovate. Collaborate. Shine. Lighthouse – KPMG's Center of Excellence for Advanced Analytics – has both applied data science, AI, and big data architecture capabilities. Here, you'll work with a diverse team of sophisticated data and analytics professionals to explore the solutions for clients in a platform-diverse environment. This means your ability to find answers is limited only by your creativity in leveraging a vast array of techniques and tools. Be a part of a high-energy, diverse, fast-paced, and innovative culture that delivers with the agility of a tech startup and the backing of a leading global consulting firm. For you, that translates into the chance to work on a wide range of projects – covering technologies and solutions from AI to optimization – and the power to have a real impact in the business world. So, bring your creativity and pioneering spirit to KPMG Lighthouse.\n\n KPMG is currently seeking a Sr. Associate to join our KPMG Lighthouse - Center of Excellence for Advanced Analytics to work with our Financial Services team.\n\nResponsibilities\n\nRapidly prototype, develop, and optimize D&A implementations to tackle the BI/EDW/Big Data and Data Science needs for a variety of Fortune 1000 corporations and other major organizations\nDesign, develop and maintain D&A solutions on premise/cloud/KPMG-hosted/hybrid infrastructure; Be the team champion of some mainstream BI/EDW/Big Data toolsets like Tableau, Alteryx, Informatica, Pentaho, Er-Win, and Power Designer\nPlay the role of data owner in cross-disciplinary teams; Build logical/physical data models; Discover, profile, acquire, process, model and own data for the solutions\nImplement data processing pipelines, data mining/science algorithms, and visualization engineering to help clients distill insights from rich data sources, including social media, news, internal/external documents, emails, financial data, client data and operational data\nActively be involved in research and experiment of leading/emerging BI/EDW/Big Data methodologies such as serverless data lake, AWS Redshift, Athena, Glue, GCP BigQuery, and MS PowerBI and apply them to real client solutions\nBe the data engineering SME in the process for pursuing innovations, target solutions, and extendable platforms for Lighthouse, KPMG and client\n\n\nQualifications\n\nMinimum of three years of relevant data engineering experience in related industries, preferably professional services; Experience and knowledge of RDBMS design, data modeling, MPP EDW system implementation; Have completed two plus production BI/EDW/Big data projects with the ability to communicate complex technical concepts to non-technical personals at all levels\nBachelor's Degree, Master's Degree or PhD from an accredited college/ university in Computer Science, Computer Engineering or related field\nHands-on experience and knowledge in: BI/EDW/Big Data toolsets (Tableau, Alteryx, Informatica, Pentaho, Er-Win, Power Designer); Mainstream cloud infrastructures (AWS, MS Azure and GCP; their D&A-related Microservices); Implementing data lake and serverless data lake; Proficient-level fluency of SQL\nHands-on experience of Linux/Unix/Windows/.NET; Market-leading fluency in several programming languages: Bash/ksh/PowerShell; Python/Perl/R; Ability to pick up and learn new technologies quickly\nHands-on experience and knowledge in distributed computing architecture, massive-parallel processing big data platforms like Hadoop, MapReduce, HDFS, Spark, Hive/Impala, H-Base/MongoDB/Casandra and Teradata/Netezza/Redshift\nAbility to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future\n\nKPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package. KPMG is an affirmative action-equal opportunity employer. KPMG complies with all applicable federal, state and local laws regarding recruitment and hiring. All qualified applicants are considered for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other category protected by applicable federal, state or local laws. The attached link contains further information regarding the firm's compliance with federal, state and local recruitment and hiring laws. No phone calls or agencies please."},{"jobtitle":"Software Engineer, Data Engineering/Machine Learning","companyname":"Niantic, Inc.","companyid":"10149011","address":"","geo":"San Francisco, CA, US","postDate":"Oct 29 2018","views":"966","applicants":"222","employees":"201-500","jobDetails":[{"level":"Entry level","industry":["Computer Software","Internet","Computer Games"],"jobtype":"Full-time","function":["Engineering","Information Technology"]}],"description":"Job description\nNiantic’s Engineering Team is seeking an experienced Data Engineer to partner with our Data Scientists and Product Engineers to build machine learning systems to analyze and predict user behavior, detect fraud and cheating, understand key gameplay behaviors, and surface product features and recommendations. As a Data Engineer on our team, you will be directly contributing to creating incredible gameplay experiences and promoting Niantic’s mission of bringing gameplay into the real world. Niantic Engineering leads the advancement of Augmented Reality (AR) and other immersive technologies while creating engaging apps for a user base in the billions.\n\nResponsibilities\n\nCollaborate with data scientists and product and engineering team members to train machine learning models.\nDesign and build efficient databases to ingest and transform data and apply machine learning and data mining techniques to a variety of modeling and relevance problems involving our players.\nAggregate data across a wide variety of sources to identify patterns and features necessary to build machine learning models for prediction and forecasting.\nDevelop, scale, and maintain the necessary infrastructure to run and maintain our machine learning algorithms.\nQualifications\n\nYou have 3+ years of relevant industry experience plus a BS, MS, or PhD in Computer Science with a focus on data modeling, artificial intelligence, machine learning, high performance computing, or a related field.\nYou are fluent in one or more object oriented languages like Java, Scala, C++.\nYou have experience with a large scale or distributed programming framework (Dataflow, Spark or Hadoop) and with ML frameworks such as (sklearn, TensorFlow/Caffe/PyTorch, H2O).\nPlus If…\n\nYou have not only built and deployed machine learning models but also architected machine learning data pipelines and scoring systems.\nYou have publications in a top tier conference such as NIPS, ICLR, ICML,ECML, AAAI, AISTATS, SIGKDD, SIGMOD.\nYou have data modeling experience on anti-fraud or social engineering projects.\nJoin the Niantic team!\nNiantic is the world’s leading AR technology company, sparking creative and engaging journeys in the real world. Our products inspire outdoor exploration, exercise, and meaningful social interaction.\n\n Originally formed at Google in 2011, we became an independent company in 2015 with a strong group of investors including Nintendo, The Pokémon Company, and Alsop Louie Partners. Our current titles include pioneering global-control game Ingress, and record-breaking AR game Pokémon GO. Our third title, Harry Potter: Wizards Unite, is currently in development.\n\n Niantic is an Equal Opportunity and Affirmative Action employer. We believe that cultivating a workplace where our people are supported and included is essential to creating great products our community will love. Our mission emphasizes seeking and hiring diverse voices, including those who are traditionally underrepresented in the technology industry, and we consider this to be one of the most important values we hold close.\n\n We're a hard-working, fun, and exciting group who value intellectual curiosity and a passion for problem-solving! We have growing offices located in San Francisco, Sunnyvale, Bellevue, Los Angeles, Tokyo, and Hamburg."},{"jobtitle":"Data Analyst II CX / Text / NPS","companyname":"ADP","companyid":"1463","address":"","geo":"Florham Park, NJ, US","postDate":"Oct 29 2018","views":"116","applicants":"9","employees":"10001","jobDetails":[{"level":"","industry":["Computer Software","Financial Services","Human Resources"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nADP is hiring a Data Analyst II. Responsible for key business metrics and reporting that drives decision making and process improvement for the Business Unit and NPS Center of Excellence. A champion for standardizing and automating internal client-facing reports provided to Business Units. Be a change agent within the Business Unit's closed loop administration to ensure accurate and high quality data is collected and analyzed on a consistent basis. Leverage a variety of analytical tools to provide information that is flexible, responsive and nimble to changing business needs. The NPS Business Analyst is responsible for Analysis/ Consulting, Configuration/ Integration, Validation/ Support and Project Planning for all aspects of the NPS closed loop process with a focus on predictive Analytics, Reporting and Survey Administration.\n\n At ADP we are driven by your success. We engage your unique talents and perspectives. We welcome your ideas on how to do things differently and better. In your efforts to achieve, learn and grow, we support you all the way. If success motivates you, you belong at ADP.\n\n We strive for every interaction to be driven by our CORE values: Insightful Expertise, Integrity is Everything, Service Excellence, Inspiring Innovation, Each Person Counts, Results-Driven, & Social Responsibility.\n\nResponsibilities\n\nAnalytics/ Consulting/Communicating :\n\nConducts NPS project initiation activities.\nUncover complex client experience opportunities.\nAnalyze existing client systems, interface requirements, business process and operational needs.\nAssess client experience data including client feedback, predictive modeling, and client behaviors and profiling\nGather, assemble, analyze and deliver actionable insights and recommendations.\nProvides professional consulting in the areas of tool customizations, business processes, analytics, complex custom reports and special projects.\nResponsible for researching benchmarked and attainable validated systemic tools to evaluate HR performance, resulting in metrics that help senior leaders drive Service Excellence.\nDevelop meaningful analytic conclusions and recommends innovative solutions.\nWork with Business Unit champions and Subject Matter Experts (SMEs) to define requirement related to reporting, analytics, trending and communications.\nCreate business requirements based on detailed analysis of Business Unit needs.\nCoordinates and consults with Corporate IT for customization work.\nDevelops adhoc inquiries to assist in reporting, categorization and analysis.\nProvides demos and training for champions and SMEs, including documentation as required for reporting, analysis, trending and communication.\n\n\n\nConfiguration/ Integration\n\nWorks and counsels with business units on system and service configuration tools, tool adaptation and business best practice solutions.\nDetermines best methodology and oversees the accurate and timely conversion of survey data, reporting and analytics.\nConsults on interfaces to internal and external systems.\n\n\n\nValidation/Support\n\nBuilds survey control information and oversees the pre- and post-implementation testing of tools, processes, reports and alerts.\nEstablish predictive analytics.\nOversees formal coordination of system and operational services to other ADP business units and departments.\nPerforms testing and support during UAT, works to resolve defects/ issues.\nSupport the COE (Center of Excellence) and Business Unit during the production release of new tools, reports, alerts and analytics.\nProvide Tier I/II support for the tools, reports and system supporting the NPS initiative to the business units.\n\n\n\nProject Planning\n\nParticipates in establishing and monitoring of Business Unit implementation schedule and report status to Project Team Members.\nEnsures issues and risks are documented and work with team members to resolve.\n\n\n\nKnowledge Sharing Of Best Practices\n\nBusiness Unit and Center of Excellence teams will work collaboratively to standardize all aspects of Closed Loop process, analytics, reporting and survey administration with consideration for the unique needs of the individual businesses.\nTrain appropriate uses on analytical tools to ensure widespread adoption of best practices in collecting and analyzing data for actionable recommendations to leaders.\nPerforms other related duties as assigned.\n\n\n\nQualifications Required\n\nEducation Qualification: Bachelor's Degree with major area of concentration BS in Finance, Accounting, Statistics.\nExperience: 5-8 years of related experience in analytics, market intelligence and analytics, financial modeling or statistical analysis.\n\n\n\nPreference will be given to candidates who have the following:\n\nExcellent quantitative and analytical skills, and strong attention to detail.\nClarabridge Modeling, Tableau, SQL, SAS or other text analytics, CX Analytics, Python, R.\nExcellent project management skills.\nStrong verbal and interpersonal skills, with demonstrated ability to work with and communicate at all levels of staff and management.\nAbility to interpret data into actionable recommendations.\nStrong Excel skills required, including data modeling and ad hoc analysis.\nCan easily build relationships across multiple functions and business Units.\n\n\n\nSoftware In The Cloud. Experts On The Ground\n\nADP powers the working world with comprehensive solutions that drive business success. Consistently named one of the \"Most Admired Companies\" by FORTUNE® Magazine, and recognized by Forbes® as one of \"The World's Most Innovative Companies,\" ADP has over a half-million clients around the globe and 65 years of experience as one of the largest providers of human capital management solutions world-wide.\n\n At ADP, we believe that diversity fuels innovation. ADP is committed to equal employment opportunities regardless of race, color, genetic information, creed, religion, sex, sexual orientation, gender identity, lawful alien status, national origin, age, marital status, or protected veteran status. We support an inclusive workplace where associates excel based on personal merit, qualifications, experience, ability, and job performance.\n\n"},{"jobtitle":"Sr. Data Analyst - Moon Twp, PA -","companyname":"LoanCare","companyid":"2394540","address":"","geo":"Pittsburgh, PA, US","postDate":"Oct 29 2018","views":"18","applicants":"2","employees":"1001-5000","jobDetails":[{"level":"Associate","industry":["Banking","Financial Services","Real Estate"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nDescription\n\nA\n re youa data enthusiast with a broad understanding andexperience with real-time analytics and business intelligence platforms.Skilled in analyzing large, complex, multi-dimensional datasets with avariety of tools and statistical environments. You have experience in creating and implementing machine learningalgorithms and advanced statistics and are proficient in statistical computinglanguages for data analysis -- suchas” R and Python and are eager to workwith a diversely talented, high performance team, we encourage you to applytoday.\n A DAY IN THE LIFE In this role, you will be…\nPerforming Cloud Data warehousing design implementation using AzureCosmos DB and SQL server 2018 cloud services database;\nIntegrating new implementation of Cloud Data warehouse in MicrosoftAzure stack to an existing data warehouse on SQL Server 2012, creating databricks using trending algorithms in Python and R scripting using Data factoryand Data Lake;\nCreating jobs to extract JSON filesfrom Azure Cosmos database into Data warehousing data marts for business tobuild executive dashboards;\nAnalyzing large, complex,multi-dimensional datasets with a variety of tools and statisticalenvironments;\nValidating and ingesting Cosmos database unstructured and structureddocuments in Azure data warehouse using R, Python scripting and SSIS runtimeIntegration services;\nConducting researchleveraging big data technologies that surface actionable insight that influenceanalytical solutions roadmap;\nPerforming ad hoc T SQL queries;\nApplying quantitativeanalysis and data mining expertise in presenting data to visualize beyond thenumbers and the underlying trends and use that analysis in process automation;\nCreating and implementingmachine learning algorithms and advanced statistics such as regression,clustering, decision trees, exploratory data analysis methodology, simulation,scenario analysis, modeling, and neural networks;\nGathering and processingraw data at scale by using statistical packages like R, and programminglanguages like Python, Java, Scale;\nAnalyzing data in the warehouse with application of R script in Tableauand Azure Data warehousing systems and providing predictive trending model /algorithms towards data analysis and validation using Python programmingscripts;\nProcessing unstructureddata into a form suitable for analysis;\nUtilizing image processingand computer vision; and\nBuilding deep learningmodels in production for predicting vendor capacity and order volume.\n\n\n\nQualifications\n\n WHO YOU ARE\n\n You possess the skills and experience to meet the jobrequirements…\n\nBachelor’s Degreein Computer Science or a related field and 5 years of progressive experience,or a Master’s Degree in Computer Science or a related field and 3 years ofexperience, in the job offered or a related role using R, Python, MicrosoftAzure Cloud Services, Azure Cloud Data Warehouse, Azure Cloud SQL Server, AzureCloud SSIS integration services, Azure Cloud SSRS reporting Services, SQLServer, ETL, Tableau, Power BI, COSMOS DB, TFS, Microsoft Test Manager andVisual Studio.\nWHO WE ARE About us …\nServiceLink is a mortgage services company headquarteredin Pittsburgh, PA that helps clients in the lending industry and beyond achievetheir strategic goals, realize greater efficiencies and better serve theircustomers by delivering best-in-class technology, services and insight with arelentless commitment to upholding the highest standards of quality, complianceand service.\n\n ServiceLink, its affiliates andsubsidiaries, is an Equal Opportunity employer. All qualified applicants willreceive consideration for employment without regard to race, color, religion,sex, age, disability, protected veteran status, national origin, or any othercharacteristic protected by applicable law.\n\n ServiceLink is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, or protected veteran status."},{"jobtitle":"Software Engineer, Data Engineering/Machine Learning","companyname":"Niantic, Inc.","companyid":"10149011","address":"","geo":"Sunnyvale, CA, US","postDate":"Oct 29 2018","views":"471","applicants":"87","employees":"201-500","jobDetails":[{"level":"Entry level","industry":["Computer Software","Internet","Computer Games"],"jobtype":"Full-time","function":["Engineering","Information Technology"]}],"description":"Job description\nNiantic’s Engineering Team is seeking an experienced Data Engineer to partner with our Data Scientists and Product Engineers to build machine learning systems to analyze and predict user behavior, detect fraud and cheating, understand key gameplay behaviors, and surface product features and recommendations. As a Data Engineer on our team, you will be directly contributing to creating incredible gameplay experiences and promoting Niantic’s mission of bringing gameplay into the real world. Niantic Engineering leads the advancement of Augmented Reality (AR) and other immersive technologies while creating engaging apps for a user base in the billions.\n\nResponsibilities\n\nCollaborate with data scientists and product and engineering team members to train machine learning models.\nDesign and build efficient databases to ingest and transform data and apply machine learning and data mining techniques to a variety of modeling and relevance problems involving our players.\nAggregate data across a wide variety of sources to identify patterns and features necessary to build machine learning models for prediction and forecasting.\nDevelop, scale, and maintain the necessary infrastructure to run and maintain our machine learning algorithms.\nQualifications\n\nYou have 3+ years of relevant industry experience plus a BS, MS, or PhD in Computer Science with a focus on data modeling, artificial intelligence, machine learning, high performance computing, or a related field.\nYou are fluent in one or more object oriented languages like Java, Scala, C++.\nYou have experience with a large scale or distributed programming framework (Dataflow, Spark or Hadoop) and with ML frameworks such as (sklearn, TensorFlow/Caffe/PyTorch, H2O).\nPlus If…\n\nYou have not only built and deployed machine learning models but also architected machine learning data pipelines and scoring systems.\nYou have publications in a top tier conference such as NIPS, ICLR, ICML,ECML, AAAI, AISTATS, SIGKDD, SIGMOD.\nYou have data modeling experience on anti-fraud or social engineering projects.\nJoin the Niantic team!\nNiantic is the world’s leading AR technology company, sparking creative and engaging journeys in the real world. Our products inspire outdoor exploration, exercise, and meaningful social interaction.\n\n Originally formed at Google in 2011, we became an independent company in 2015 with a strong group of investors including Nintendo, The Pokémon Company, and Alsop Louie Partners. Our current titles include pioneering global-control game Ingress, and record-breaking AR game Pokémon GO. Our third title, Harry Potter: Wizards Unite, is currently in development.\n\n Niantic is an Equal Opportunity and Affirmative Action employer. We believe that cultivating a workplace where our people are supported and included is essential to creating great products our community will love. Our mission emphasizes seeking and hiring diverse voices, including those who are traditionally underrepresented in the technology industry, and we consider this to be one of the most important values we hold close.\n\n We're a hard-working, fun, and exciting group who value intellectual curiosity and a passion for problem-solving! We have growing offices located in San Francisco, Sunnyvale, Bellevue, Los Angeles, Tokyo, and Hamburg."},{"jobtitle":"Lead Data Analyst","companyname":"Hallmark Cards","companyid":"4798","address":"","geo":"Kansas City, MO, US","postDate":"Oct 29 2018","views":"53","applicants":"4","employees":"10001","jobDetails":[{"level":"Associate","industry":["Marketing & Advertising","Consumer Goods","Retail"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nreqid: 23262\n\nWHEN YOU CARE ENOUGH YOU CAN CHANGE THE WORLD.\n\nYou need a job. You want a career. Working someplace you can be yourself and belong while creating something that makes a difference. Something that makes the world a better place. Perfect timing. Hallmark is looking for someone like you.\n\n People rely on us to help them connect and express their emotions through products and services that enrich lives every day. They trust that we know their needs and that we are focused on innovations that will allow them to enhance their relationships. We have a competitive mindset and “play to win” with our retailers and consumers. We work with courage and conviction, always seeking to adapt and learn. It is an exciting time to be in the Greetings business at Hallmark!\n\nWe Are Looking For\n\nHallmark is in the midst of a data analytics revolution and we need a talented senior-level Data Analytics Lead to join our Customer Analytics team. Hallmark’s mission is to inspire people everywhere “to live a caring, connected life full of meaningful moments”. We can only do that by understanding how people connect with those who mean the most to them.\n\n We are seeking innovative individuals who are energized by solving complex business problems that leverage a myriad of data and information. People who are passionate about driving analytical thought within our customer teams and throughout the Hallmark Analytics community. We’re looking for people who bring an inquisitive mind to solve complex business, analytics and statistical issues and have the necessary tools to take it to the next level.\n\nWho We Are\n\nThe Customer Analytics team under Category Solutions provides powerful consulting along with key reporting and insightful analyses to the Greetings business. We focus on using data to understand our category and customers, leveraging a vast amount of sources to our advantage. We focus on complete storytelling, from understanding what has happened in the past to conducting predictive analysis to understand the future. We are looking for motivated individuals who love exploring data to uncover hidden trends and developing new experiments and models to help drive the business.\n\nIn This Role You Will\n\nServe as the key analytics consultant for the CVS customer team and serve in an integral role by leveraging data and analytical thought leadership to develop solutions and tactics for the customer team\nBe the expert of the CVS business and data sources, including how to best leverage advanced analytics, reporting, experimentation, predictive analytics and more to create data-driven solutions and strategies aimed to grow the business\nSummarize and monitor performance, uncover hidden trends, assess opportunities for growth and provide robust solutions leveraging data-driven insights and business acumen\nRegularly present findings to CVS customer team leadership and business customers, both internal and external, who have varying expertise in analytics and statistics\nIndependently strive to make the business better every day by exploring the data and find new opportunities to drive growth in CVS\nHelp train both analytics and non-analytics staff in new skills and techniques.\n\n\n\nApplication Instructions\n\nYou must show how you meet the basic qualifications (listed below) in a resume or document you upload, or by completing the work experience and education application fields. Accepted file types are Microsoft Word (DOC or DOCX), PDF, HTML, or TXT.\n\n In compliance with the Immigration Reform and Control Act of 1986, Hallmark Cards, Inc. and its subsidiary companies will hire only individuals lawfully authorized to work in the United States. Hallmark does not generally provide sponsorship for employment. Employment by Hallmark is contingent upon the signing of the Employment Agreement, signing of an agreement to arbitrate in connection with the Hallmark Dispute Resolution Program, completing Form I-9 Employment Eligibility Verification, passing the urinalysis drug screen, education verification and satisfactory reference and background checks.\n\nBasic Qualifications\n\nThe following is required to be considered for this role:\n\nBachelor’s degree in Business or quantitative field (Data Science, Statistics, Analytics, Economics, Mathematics, Computer Science).\n2+ years’ experience in an advanced analytics or strategy role.\n1+ years of professional using statistical programming languages (SAS, R, Python, etc), SQL and/or data visualization tools (Tableau, etc)\n\n\n\nYour Resume Will Stand Out If You Have\n\nPREFERRED QUALIFICATIONS\n\nAdvanced Degree in one of the above fields\nExpertise in at least one (1) statistical programming language (Python, R, Scala, Octave, SAS, MATLAB, etc.)\nExpertise in basic to intermediate statistical methods and experimentation, including ANOVA, predictive analysis, regression, data mining, etc.\nProven track record of simplifying large and complex problems, working with a multiple of data sources and techniques to uncover data-driven solutions and actionable insights that drive business results\nExpertise in presenting to both internal and external business customers with varying experience in advanced analytics and data science.\nExperience with CPG and/or Retail data, including transactions, assortment planning, supply chain, financial data, etc.\nExperience with data visualization tools including Tableau, Dash, RShiny, D3.js, Microstrategy, etc.\nStrong desire to combine rich business acumen and explore various data sources to uncover hidden trends and opportunities for the organization\nAble to provide a GitHub or coding portfolio of prior advanced analytics, data science, computer programming and statistical work and projects\nSelf-directed, detail & team oriented with highly developed problem solving and analytical skills\nExcellent communication skills, both written and verbal, coupled with strong organizational, planning and interpersonal skills\n\n\nHallmark believes in enriching the lives of our employees by offering benefit programs to help you:\n\nTake care of you and yours: We offer comprehensive medical, dental and vision benefits, as well as discounts on elder care, child care, education assistance and adoption assistance.\nSave for your future: Through profit sharing, you share in the success of Hallmark. We also offer a 4% match on 401(k) contributions.\nEnjoy your time: Maximize your work-life balance through Paid Time Off (PTO), paid holidays, community volunteer opportunities and discounts on product, entertainment venues, amusement parks and sporting events.\nAnd More! (Like an on-site cafeteria, free parking, access to Crown Center and a fitness center.)\n\n\nHallmark is an equal opportunity employer. All qualified applicants will be considered for employment without regard to race, color, religion, sex, age, pregnancy, national origin, physical or mental disability, genetics, sexual orientation, gender identity, veteran status, or any other legally-protected status. Principals only please."},{"jobtitle":"Sr. Associate, Data Engineer - Alteryx","companyname":"KPMG US","companyid":"1079","address":"","geo":"Atlanta, GA, US","postDate":"Oct 29 2018","views":"25","applicants":"1","employees":"10001","jobDetails":[{"level":"Mid-Senior level","industry":["Management Consulting"],"jobtype":"Full-time","function":["General Business"]}],"description":"Job description\nRequisition Number: 35846 - 26\n\nDescription\n\nInnovate. Collaborate. Shine. Lighthouse – KPMG's Center of Excellence for Advanced Analytics – has both applied data science, AI, and big data architecture capabilities. Here, you'll work with a diverse team of sophisticated data and analytics professionals to explore the solutions for clients in a platform-diverse environment. This means your ability to find answers is limited only by your creativity in leveraging a vast array of techniques and tools. Be a part of a high-energy, diverse, fast-paced, and innovative culture that delivers with the agility of a tech startup and the backing of a leading global consulting firm. For you, that translates into the chance to work on a wide range of projects – covering technologies and solutions from AI to optimization – and the power to have a real impact in the business world. So, bring your creativity and pioneering spirit to KPMG Lighthouse.\n\n KPMG is currently seeking a Sr. Associate Data & Analytics Alteryx Engineer to join our KPMG Lighthouse - Center of Excellence for Advanced Analytics.\n\nResponsibilities\n\nLead the data engineering team or a work stream in a cross-functional engagement leveraging your Alteryx expertise; Provide infrastructure recommendation, roadmap, solution architecture; rapidly prototype, develop and optimize D&A implementations to tackle the BI/EDW/Big Data and Data Science needs for a variety of Fortune 1000 corporations and other major organizations\nLead/mentor the practice to design, develop and maintain D&A solutions on premise, cloud, KPMG-hosted or hybrid infrastructure; Be the team championing Alteryx as key tool.\nTranslate advanced business analytics problems into technical approaches that yield actionable recommendations across multiple and diverse domains; communicate results and educate others through design and build of insightful visualizations, reports, and presentations\nActively pursue and play data owner role in cross-disciplinary teams; Build solution architecture, logical/physical data models; Discover, profile, acquire, process, model and own data for the solutions; Implement data processing pipelines, data mining/science algorithms, and visualization engineering to help clients distill insights from rich data sources including social media, news, internal/external documents, emails, financial data, client data, and operational data\nSuggest, lead and involve in research and experiment of leading and emerging BI/EDW/Big Data methodologies such as serverless data lake, AWS Redshift, Athena, Glue, GCP Bigquery, and MS PowerBI and apply them in solving real world client problems\nLead the process for pursuing innovations, target solutions, and extendable platforms for Lighthouse, KPMG, and client; Participate in developing and presenting thought leadership, and assist in ensuring that the Lighthouse technology stack incorporates and is optimized for using specific technologies\n\n\nQualifications\n\nMinimum of four years of professional experience around big data systems with a professional services firm, an internal big data group or similar environment\nBachelor's degree or Master's Degree from an accredited college in Computer Science, Computer Engineering, or related field\nDemonstrated ability to communicate complex technical concepts succinctly to non-technical colleagues, understand & manage interdependencies between all facets of a project; Demonstrated ability to lead client presentations; Familiarity with the end-to-end sales process; Demonstrated ability to manage the team to drive engagements to successful closure and also the ability to mentor others\nExpertise with programming methodologies such as version control, testing, QA, and development methodologies such as Waterfall and Agile; Ability to work efficiently under Unix/Linux environment or .NET, with experience with source code management systems like GIT and SVN; Experience with object-oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large-scale data infrastructures\nStrong experience and knowledge in BI/EDW/Big Data tool sets with a particular focus on Alteryx. Knowledge in distributed computing architecture, massive-parallel processing big data platforms, like Hadoop, MapReduce, HDFS, Spark, Hive/Impala, H-Base/MongoDB/Casandra, Teradata/Netezza/Redshift; Skilled-level fluency of SQL; Strong experience and knowledge of Linux/Unix/Windows/.NET; Market-leading fluency in several programming languages: Bash/ksh/Powershell; Python/Perl/R, Java/C/C++/Scala\nAbility to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future\n\nKPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package. KPMG is an affirmative action-equal opportunity employer. KPMG complies with all applicable federal, state and local laws regarding recruitment and hiring. All qualified applicants are considered for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other category protected by applicable federal, state or local laws. The attached link contains further information regarding the firm's compliance with federal, state and local recruitment and hiring laws. No phone calls or agencies please."},{"jobtitle":"AI & Analytics Senior Associate","companyname":"Cognizant","companyid":"1680","address":"","geo":"Teaneck, NJ, US","postDate":"Oct 29 2018","views":"163","applicants":"15","employees":"10001","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Management Consulting"],"jobtype":"Full-time","function":["Other"]}],"description":"Job description\nToday, increasing globalization, rapidly evolving technology and a changing generation of workers and customers are challenging business assumptions. These are the forces that are transforming the way organizations compete and innovate. We call this the Future of Work - and it is no longer in the Future.\n\nWe are currently hiring master’s degree graduates into the following three role opportunities. In your cover letter, you must indicate your role preference: AI & Analytics Data Engineer, Data Scientist, or Visualization Engineer.\n\nAI & Analytics Data Engineer\n\n\n\n\nResponsibilities\n\nIntegrate high volume, high variation and/or high velocity data to produce answers and enable clients to ask an entirely new class of questions\nDeliver data pipelines to store data in the way that is accessible, performant, secure, and sustainable\nPrototype solutions, prepare test scripts, and conduct tests for data replication, extraction, loading, cleansing, and data modeling for data warehouses\nReview and validate data loaded into data lakes/warehouses for accuracy\nDevelop proofs of concept and evaluate design options to deliver ingestion, search, meta data cataloging and scheduling of data pipelines\nData engineering in line with best practices and Cognizant’s reference architecture\nUnderstand and document technical use case requirements to deliver data movement and transformation solutions\n\n\nBasic Qualifications\n\nMaster’s Degree in IT-related field and 0-3 years of IT experience\nStrong business communication skills (incl. written and oral)\nExperience with Java development for modern data engineering\nStrong background in relational data models\nExposure in ETL tools & RDBMS\nStrong problem solving and analytical thinking skills\n\n\nDistinguishing Qualifications\n\nFull lifecycle development experience\nImplementation experience within the Hadoop ecosystem\nIndustry experience (financial services, insurance, retail, healthcare, life sciences, communications)\nExperience leading teams\nExperience in developing and deploying distributed computing Big Data applications using Open Source frameworks such as Apache Spark\nWorking knowledge of application development using Hadoop components (HDFS, Hbase, Hive, Sqoop, Flume, etc.)\nExposure to data analytics and data mining tools/applications such as Tableau, QlikSense /QlikView, R or SAS\nExposure to working with SQL, Relational Database Management Systems (e.g., SQL Server, Oracle)\nDevelopment workflows (e.g., Microsoft VSTS)\n\n\nAI & Analytics Visualization Engineer\n\nResponsibilities\n\nProvide direct and interactive storytelling to clients through the use of information systems that transform data complexity into digitally informed and intelligent data visualizations.\nWork with customers for addressing their visualization & narratives opportunities\nFrame and define strategic solution options to various stakeholders\nPerform analytical storytelling backed by self-developed visualizations, and the articulation of IT-centric proposals to business communities\nWork with and analyze large data sets in multiple formats\nEmbed AI within Visualization meaningfully to deliver customer outcomes\nR & D on new technologies and create shareable assets in the form of decks or whitepapers\n\n\nBasic Qualifications\n\nMaster’s Degree in IT-related field and 0-3 years of IT experience\nPortfolio of exceptional visualizations including data contextualization\nExperience using Tableau or a comparable BI tool such as Qlikview, Spotfire, D3, Looker, Jaspersoft, ThoughtSpot, Open Source Visualization tools\nExposure to Data Engineering Fundamentals to deliver Visualization engagements successfull\nStrong problem solving and analytical thinking skills\n\n\nDistinguishing Qualifications\n\nTarget to contribute on winning Pubic Hackathons\nKeep up to date on new analytics trends in the Market and identify where they can be implemented\nFocus on RPA, automation, innovations & tools and track their benefit on RFP, project delivery\nAwareness of Narrative Science/ YSEOP/Automated Insights and concept of NLG/NLP etc.\nBig data monetization technologies including AtScale/Jethro/Arcadia data etc.\nData Wrangling Technologies including Paxata/Trifacta/etc.\n\n\nAI & Analytics Data Scientist\n\nResponsibilities\n\nProvide context for data, business, and IT across the data management, business intelligence, and descriptive analytics domains to deliver better, faster, and smarter analytical insights to some of the world’s most successful businesses – our clients\nBuild an in-depth understanding of the opportunity, challenge or issue domain, and its associated data\nInteract with large and impactful data sets across business functions\nResearch, design, implement and evaluate machine learning approaches and models\nTake the initiative in evaluating and adapting new approaches from data science research\nInvestigate data visualization and summarization techniques for conveying key findings\nCommunicate findings and obstacles to stakeholders to help drive the delivery to market\n\n\nBasic Qualifications\n\nMaster's Degree in IT-related or Engineering field and 0-3 years of IT experience\nStrong business communication skills (including written and oral)\nHands on experience in identifying and testing hypotheses, establishing correlations, selecting the right algorithms, building a predictive model using traditional as well as machine learning algorithms, data quality assessment, imputing and transformation as well as familiarity with typical data distributions such as normal, binomials, chi-square, Poisson, etc.\nHands on experience with traditional modeling algorithms (e.g., regression, log-regression, clustering, Bayesian, etc.)\nHands on experience with the modeling platform like Python, R/R Studio\nStrong problem solving and analytical thinking skills\n\n\nDistinguishing Qualifications\n\nPh.D. in IT-related or Engineering field and 0-3 years of IT experience\nFamiliarity with machine learning algorithms, e.g., Extreme Gradient Boosting, SVM, Random Forest, Neural Networks, etc. Hence it is a very good skill set to have for this role\nFamiliarity with developing and deploying models on the Hadoop environment\nExperience with collaborative development workflows (e.g., Microsoft VSTS)\nExposure to working with SQL, Relational Database Management Systems (e.g., SQL Server, Oracle)\n\nLearning & Development\nYour on-the-job success and Cognizant career advancement is important to us. To help you construct a platform for personal and professional growth, your Cognizant journey will include a learning program catering to your skill level and role.\n\nGain niche Data Sciences skills vital to success in your new role\nCreate job maneuverability in emerging and established technologies\nOur commitment to you:\n\nYour innovative thinking and successes will be rewarded with opportunities for career advancement\nYou can make a difference working with high-profile clients and projects\nYou will be supported by a high-caliber analytics ecosystem\nNew skills, knowledge, and training through our global network of experts\nCompetitive salary including paid time off, a 401K matching program, an extensive healthcare benefits suite, and more\nApplicants must be willing to relocate to one of the major geographic areas where we have significant customer accounts and/or travel may be required.\n\nCognizant will not sponsor H-1B or other U.S. work authorization, or lawful permanent residence (otherwise known as a “Green Card”) for this role.\n\nCognizant is an equal opportunity employer provider and committed to creating a diverse environment. Cognizant considers all applicants without regard to race, creed, color, national origin, ancestry, age, marital and family status, disabilities, sexual orientation or preference, veteran status or any other classification protected by state, federal or local law.\n\nCognizant is always looking for top talent. We are searching for candidates to fill future needs within the business. This job posting represents potential future employment opportunities with Cognizant. Although the position is not currently available, we want to provide you with the opportunity to express your interest in future employment opportunities with Cognizant. If a job opportunity that you may be qualified for becomes available in the future, we will notify you. At that time you can determine whether you would like to apply for the specific open position. Thank you for your interest in Cognizant career opportunities.\n\nEmployee Status : Full Time Employee\n\n Shift : Day Job\n\n Job Posting : Sep 28 2018\n\n Cognizant US Corporation is an Equal Opportunity Employer Minority/Female/Disability/Veteran. If you require accessibility assistance applying for open positions in the US, please send an email with your request to CareersNA2@cognizant.com\n\nAbout Cognizant\n\nCognizant is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant, a member of the NASDAQ-100, is ranked 195 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us on Twitter: USJobsCognizant.\n\n Cognizant is recognized as a Military Friendly Employer and is a coalition member of the Veteran Jobs Mission. Our Cognizant Veterans Network assists Veterans in building and growing a career at Cognizant that allows them to leverage the leadership, loyalty, integrity, and commitment to excellence instilled in them through participation in military service."},{"jobtitle":"Sr. Associate, Data Engineer - Alteryx","companyname":"KPMG US","companyid":"1079","address":"","geo":"Denver, CO, US","postDate":"Oct 29 2018","views":"48","applicants":"4","employees":"10001","jobDetails":[{"level":"Mid-Senior level","industry":["Management Consulting"],"jobtype":"Full-time","function":["General Business"]}],"description":"Job description\nRequisition Number: 36991 - 16\n\nDescription\n\nInnovate. Collaborate. Shine. Lighthouse – KPMG's Center of Excellence for Advanced Analytics – has both applied data science, AI, and big data architecture capabilities. Here, you'll work with a diverse team of sophisticated data and analytics professionals to explore the solutions for clients in a platform-diverse environment. This means your ability to find answers is limited only by your creativity in leveraging a vast array of techniques and tools. Be a part of a high-energy, diverse, fast-paced, and innovative culture that delivers with the agility of a tech startup and the backing of a leading global consulting firm. For you, that translates into the chance to work on a wide range of projects – covering technologies and solutions from AI to optimization – and the power to have a real impact in the business world. So, bring your creativity and pioneering spirit to KPMG Lighthouse.\n\n KPMG is currently seeking a Sr. Associate Data & Analytics Engineer - Alteryx to join our KPMG Lighthouse - Center of Excellence for Advanced Analytics.\n\nResponsibilities\n\nRapidly prototype, develop, and optimize D&A implementations to tackle the BI/EDW/Big Data and Data Science needs for a variety of Fortune 1000 corporations and other major organizations\nDesign, develop and maintain D&A solutions on premise/cloud/KPMG-hosted/hybrid infrastructure; Be the team champion of some mainstream BI/EDW/Big Data toolsets like Tableau, Alteryx, Informatica, Pentaho, Er-Win, and Power Designer\nPlay the role of data owner in cross-disciplinary teams; Build logical/physical data models; Discover, profile, acquire, process, model and own data for the solutions\nImplement data processing pipelines, data mining/science algorithms, and visualization engineering to help clients distill insights from rich data sources, including social media, news, internal/external documents, emails, financial data, client data and operational data\nActively be involved in research and experiment of leading/emerging BI/EDW/Big Data methodologies such as serverless data lake, AWS Redshift, Athena, Glue, GCP BigQuery, and MS PowerBI and apply them to real client solutions\nBe the data engineering SME in the process for pursuing innovations, target solutions, and extendable platforms for Lighthouse, KPMG and client\n\n\nQualifications\n\nMinimum of three years of relevant data engineering experience in related industries, preferably professional services; Experience and knowledge of RDBMS design, data modeling, MPP EDW system implementation; Have completed two plus production BI/EDW/Big data projects with the ability to communicate complex technical concepts to non-technical personals at all levels\nBachelor's Degree, Master's Degree or PhD from an accredited college/ university in Computer Science, Computer Engineering or related field\nHands-on experience and knowledge in: BI/EDW/Big Data toolsets (Tableau, Alteryx, Informatica, Pentaho, Er-Win, Power Designer); Mainstream cloud infrastructures (AWS, MS Azure and GCP; their D&A-related Microservices); Implementing data lake and serverless data lake; Proficient-level fluency of SQL\nHands-on experience of Linux/Unix/Windows/.NET; Market-leading fluency in several programming languages: Bash/ksh/PowerShell; Python/Perl/R; Ability to pick up and learn new technologies quickly\nHands-on experience and knowledge in distributed computing architecture, massive-parallel processing big data platforms like Hadoop, MapReduce, HDFS, Spark, Hive/Impala, H-Base/MongoDB/Casandra and Teradata/Netezza/Redshift\nAbility to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future\n\nKPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package. KPMG is an affirmative action-equal opportunity employer. KPMG complies with all applicable federal, state and local laws regarding recruitment and hiring. All qualified applicants are considered for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other category protected by applicable federal, state or local laws. The attached link contains further information regarding the firm's compliance with federal, state and local recruitment and hiring laws. No phone calls or agencies please."},{"jobtitle":"Data Analyst - Strategic Finance","companyname":"Uber","companyid":"1815218","address":"","geo":"San Francisco, CA, US","postDate":"Oct 29 2018","views":"284","applicants":"52","employees":"10001","jobDetails":[{"level":"","industry":["Computer Software","Consumer Services","Information Technology & Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nAt Uber, we ignite opportunity by setting the world in motion. We take on big problems to help drivers, riders, delivery partners, and eaters get moving in more than 600 cities around the world.\n\n We welcome people from all backgrounds who seek the opportunity to help build a future where everyone and everything can move independently. If you have the curiosity, passion, and collaborative spirit, work with us, and let’s move the world forward, together.\n\nAbout The Role\n\nIn this position, you will get an amazing opportunity to play a critical role in influencing decisions with data. You will work extensively with Strategic Finance (Eats) team and other stakeholders across the finance team. Your performance is measured by the insights you give, effectiveness of communication, and the initiative to drive ideas and implement them into action.\n\nWhat You’ll Do\n\nWork with strategic finance, accounting, engineering, data science, product management teams and other business stakeholders in mining and analyzing financial data to extract key trends and insights\nBuild scalable queries powering our Eats financial decisions, including but not limited to planning, marketing, product initiatives and sales\nBuild analysis to quantify the financial impact of new product or pricing strategy, informing ROI assessments\nCollaborate with finance stakeholders to troubleshoot/analyze complex calculations and resolve financial imbalances\nGet a deep understanding about the process and data flows involved; document and train internal personnel to institutionalize the learnings of the data analytics practice\nBuild end to end data pipelines and self serving dashboards. Automate whatever you can!\nDesign and create visualizations to present actionable insights related to data sets and business questions at hand\n\n\nWhat You’ll Need\n\nBachelor’s degree with 2 yrs experience or Master Degree with 1 yr experience in Economics, Statistics, Management Science, Computer Science, Engineering or other quantitative field.\nProficient SQL skills with strong analytical mindset\nGood understanding of basic statistical concepts\nExperience with at least one scripting language such as R or Python\nExperience telling stories with data to both technical and non-technical audiences and creating clear and compelling visualizations to convey complex data\nExperience managing projects and stakeholders with strong communication and presentation skills\n\n\nBonus Points if\n\nExperience with Hive & Presto is a plus.\nExperience with data pipeline management\nExperience in building predictive modeling\nStrong coding skills (e.g., R, Python)\nProfessional experience in business intelligence / strategy / consulting / operations or related field\n\n\nAbout The Team\n\nThis role is a part of the quantitative strategy team within Strategic finance, which builds scientific models using time series analysis & machine learning to forecast metrics, understand supply-demand relationships, users’ elasticity and quantify impact of various metrics on eaters / couriers/ restaurants in order to provide actionable insights to the finance leadership for making financial decisions. Specifically, you will be part of the Global team that supports the Eats business. You will partner with operations and product teams to drive growth, new product launches, and find operating efficiencies in Uber's fastest growing business.\n\n"},{"jobtitle":"Data Analyst Intern","companyname":"Sony Playstation Network","companyid":"","address":"","geo":"San Diego, CA, US","postDate":"Oct 29 2018","views":"190","applicants":"49","employees":"","jobDetails":[{"level":"Internship","industry":["Information Technology & Services","Computer Software","Computer & Network Security"],"jobtype":"Internship","function":["Information Technology"]}],"description":"Job description\nPlayStation isn't just the Best Place to Play -it's also the Best Place to Work. We've thrilled gamers since 1994, when we launched the original PlayStation. Today, we're recognized as a global leader in interactive and digital entertainment. The PlayStation brand falls under Sony Interactive Entertainment, a wholly-owned subsidiary of Sony Corporation.\n\n This internship is for Summer 2019.\n\n Sony Interactive Entertainment is looking for a Data Analyst Intern to become part of IT Applications team who manages the SIE Intranet, develops custom applications and workflows for revenue-generating business units, and trains SIE staff on the use of our IT applications such as Confluence, JIRA, Slack, Box & Google Apps for Work. Ideal candidates will have a strong desire to build both in-depth technical skills and an ability to develop exemplary client-facing skills. Candidate will implement, and maintain leading-edge analytic systems, taking complicated problems and building simple frameworks. Identify trends and opportunities for growth through analysis of complex data sets and generate forward looking insights for the business.\n\nResponsibilities\n\nEvaluate organizational methods and provide source-to-target mappings and information-model specification documents for data sets.\nWork closely with IT teams and maintain focus on their analytical needs, including identifying critical metrics and KPIs, and deliver actionable insights to relevant decision-makers.\nCreate best-practice reports based on data mining, analysis, and visualization.\nCreate and maintain rich interactive visualizations through data interpretation and analysis integrating reporting components from multiple data sources.\nEvaluate internal systems for efficiency, problems, and inaccuracies, developing and maintaining protocols for handling, processing, and cleaning data.\nDevelop and maintain databases by acquiring data from primary and secondary sources, and build scripts that will make our data evaluation process more flexible or scalable across data sets.\nRespond to requests for ad hoc analysis and investigate data inconsistencies.\n\nQualifications\n\nBachelor's degree in Computer Science, Engineering, Mathematics or related\n1+ year experience mining data as a data analyst and visualizing using Tableau\nAt least 1 year of full-time professional experience working extensively with databases such as RedShift, and/or MySQL\nProficient with Python or R as well as Excel\nProven analytic skills, including mining, evaluation, analysis, and visualization\nTechnical writing experience in relevant areas, including queries, reports, and presentations\nStrong SQL or Excel skills with the ability to learn other analytic tools\nStrong written and verbal communication skills\n\nSony is an Equal Opportunity Employer. All persons will receive consideration for employment without regard to race, color, religion, gender, pregnancy, national origin, ancestry, citizenship, age, legally protected physical or mental disability, covered veteran status, status in the U.S. uniformed services, sexual orientation, gender identity, marital status, genetic information or membership in any other legally protected category.\n\n We strive to create an inclusive environment, empower employees and embrace diversity. We encourage everyone to respond.\n\n We sincerely appreciate the time and effort you spent in contacting us and we thank you for your interest in PlayStation."},{"jobtitle":"Senior Data & Applied Scientist","companyname":"Microsoft","companyid":"1035","address":"","geo":"Redmond, WA, US","postDate":"Oct 29 2018","views":"85","applicants":"8","employees":"10001","jobDetails":[{"level":"","industry":["Computer Hardware","Computer Software","Information Technology & Services"],"jobtype":"Full-time","function":["Other"]}],"description":"Job description\nThe Capacity, Supply Chain & Provisioning (CSCP) group within Azure engineering is an exciting and fast evolving engineering group within Microsoft and powering Microsoft’s Cloud First mission. CSCP is responsible for designing, building and operating Microsoft unified global datacenters; managing demand planning and capacity utilization of the unified infrastructure; and for all the operations needed to run the physical infrastructure. The organization is responsible for strategy and delivery of the foundational platform for all Microsoft Online Services including demand and capacity forecasting, supply chain, data centers, networking, bandwidth, operations, and incident management. CSCP supports over 200 online businesses including Bing, O365, OneDrive, Xbox and Windows Azure branded services. The Cloud Supply Chain & Provisioning Engineering (CSCP-E) team is responsible for building a world class agile supply chain management and execution platform for increased predictability and efficiency to deliver superior customer experience at optimal cost.\n\n Are you interested in guiding key business decisions around Microsoft Cloud (Azure) customer bases? Are you interested in honing your data engineering & analytics skills? Do you want to build a cutting-edge highly scalable analytics platform using latest technologies such as Azure Data Lake, Kusto, SQL Server, Power BI, Cosmos?\n\n Cloud Supply Chain & Provisioning Engineering (CSCP-E) Analytics team is looking for an experienced, self-driven, analytical Senior Business Intelligence professional. In this role, you will be working in creating Single Authoritative Data platform, enabling analytics to measure pulse of Microsoft Cloud Provisioning business.\n\nResponsibilities\n\nThe right candidate will possess excellent business and communication skills, be able to work with business owners to develop and define key business questions, work with the team to create analytics platform that will help in analyzing data to answer those questions. Your responsibility will include the following:\n\n\nDesign, implement and support Supply Chain & Deployment Analytical platform that will enable insights to analyze and measure the rhythm of business\nDeveloping ETL platform to acquire and integrate data from diverse sources like Azure Data Lake, Kusto, SQL Server, Cosmos, flat files etc.\nCreate Near Real Time Data Mart to support business operational requirement\nRecognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation\nCreate reports / dashboards using Microsoft technologies like Power BI\nContinually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers\nCreate analytical model, performing analyses on data to identify trends, patterns, correlations, and providing insights from data. You will partner and collaborate with engineering groups, business stakeholders to predict Supply Chain & Deployment Milestones and identify risks that will help in proactive mitigation and smooth deployment\n\n\nQualifications\n\nSkills & Qualifications:\n\nBachelor’s degree in Computer Science, MIS, related technical field, or equivalent work experience.\nAt least 5 years of relevant work experience in analytics, data engineering, business intelligence or related field\nBoth technically deep and business savvy enough to interface with all levels and disciplines within the organization\nDemonstrable ability in data modeling, ETL development, and Data warehousing, or similar skills\nDemonstrable skills and experience using SQL with large data sets (e.g. Oracle, SQL Server, Redshift)\nProven track record of successful communication of analytical outcomes through written communication, including an ability to effectively communicate with both business and technical teams\n\n\nPreferred Experience/skills\n\nGraduate degree in computer science, business, mathematics, statistics, economics, or other quantitative field\n7+ years prior experience in a Data Engineer role with a technology company or financial institution.\nKnowledge of Advanced SQL and scripting for automation (e.g. Python, Perl or R)\nExperience with Azure Data Lake, Kusto, Tabular Cube (Analysis Services)\nFamiliarity with statistical models and data mining algorithms\nExperience with Hadoop or other map/reduce \"big data\" systems and services.\nExperience in Data Center Supply Chain business\nExceptional interpersonal and communications (verbal and written) skills\n\nAbility to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud Background Check upon hire/transfer and every two years thereafter.\n\n Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.\n\n Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work."},{"jobtitle":"Sr. Data Analyst - Moon Twp, PA","companyname":"ServiceLink, a Black Knight Company","companyid":"","address":"","geo":"Pittsburgh, PA, US","postDate":"Oct 29 2018","views":"4","applicants":"0","employees":"","jobDetails":[{"level":"Associate","industry":["Banking","Financial Services","Real Estate"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nA\n\n re youa data enthusiast with a broad understanding andexperience with real-time analytics and business intelligence platforms.Skilled in analyzing large, complex, multi-dimensional datasets with avariety of tools and statistical environments. You have experience in creating and implementing machine learningalgorithms and advanced statistics and are proficient in statistical computinglanguages for data analysis -- suchas\" R and Python and are eager to workwith a diversely talented, high performance team, we encourage you to applytoday.\n\n A DAY IN THE LIFE\n\n In this role, you will beâ¦\n\nPerforming Cloud Data warehousing design implementation using AzureCosmos DB and SQL server 2018 cloud services database;\nIntegrating new implementation of Cloud Data warehouse in MicrosoftAzure stack to an existing data warehouse on SQL Server 2012, creating databricks using trending algorithms in Python and R scripting using Data factoryand Data Lake;\nCreating jobs to extract JSON filesfrom Azure Cosmos database into Data warehousing data marts for business tobuild executive dashboards;\nAnalyzing large, complex,multi-dimensional datasets with a variety of tools and statisticalenvironments;\nValidating and ingesting Cosmos database unstructured and structureddocuments in Azure data warehouse using R, Python scripting and SSIS runtimeIntegration services;\nConducting researchleveraging big data technologies that surface actionable insight that influenceanalytical solutions roadmap;\nPerforming ad hoc T SQL queries;\nApplying quantitativeanalysis and data mining expertise in presenting data to visualize beyond thenumbers and the underlying trends and use that analysis in process automation;\nCreating and implementingmachine learning algorithms and advanced statistics such as regression,clustering, decision trees, exploratory data analysis methodology, simulation,scenario analysis, modeling, and neural networks;\nGathering and processingraw data at scale by using statistical packages like R, and programminglanguages like Python, Java, Scale;\nAnalyzing data in the warehouse with application of R script in Tableauand Azure Data warehousing systems and providing predictive trending model /algorithms towards data analysis and validation using Python programmingscripts;\nProcessing unstructureddata into a form suitable for analysis;\nUtilizing image processingand computer vision; and\nBuilding deep learningmodels in production for predicting vendor capacity and order volume.\n\nWho You Are\n\nYou possess the skills and experience to meet the jobrequirementsâ¦\n\nBachelor's Degreein Computer Science or a related field and 5 years of progressive experience,or a Master's Degree in Computer Science or a related field and 3 years ofexperience, in the job offered or a related role using R, Python, MicrosoftAzure Cloud Services, Azure Cloud Data Warehouse, Azure Cloud SQL Server, AzureCloud SSIS integration services, Azure Cloud SSRS reporting Services, SQLServer, ETL, Tableau, Power BI, COSMOS DB, TFS, Microsoft Test Manager andVisual Studio.\n\nWho We Are\n\nAbout us â¦\n\n ServiceLink is a mortgage services company headquarteredin Pittsburgh, PA that helps clients in the lending industry and beyond achievetheir strategic goals, realize greater efficiencies and better serve theircustomers by delivering best-in-class technology, services and insight with arelentless commitment to upholding the highest standards of quality, complianceand service.\n\n ServiceLink, its affiliates andsubsidiaries, is an Equal Opportunity employer. All qualified applicants willreceive consideration for employment without regard to race, color, religion,sex, age, disability, protected veteran status, national origin, or any othercharacteristic protected by applicable law."},{"jobtitle":"Data Analyst Intern","companyname":"PlayStation","companyid":"1254","address":"","geo":"San Diego, CA, US","postDate":"Oct 29 2018","views":"696","applicants":"175","employees":"5001-10000","jobDetails":[{"level":"Internship","industry":["Computer Software","Consumer Services","Entertainment"],"jobtype":"Temporary","function":["Information Technology"]}],"description":"Job description\nPlayStation isn’t just the Best Place to Play —it’s also the Best Place to Work. We’ve thrilled gamers since 1994, when we launched the original PlayStation. Today, we’re recognized as a global leader in interactive and digital entertainment. The PlayStation brand falls under Sony Interactive Entertainment, a wholly-owned subsidiary of Sony Corporation.\n\n This internship is for Summer 2019.\n\n Sony Interactive Entertainment is looking for a Data Analyst Intern to become part of IT Applications team who manages the SIE Intranet, develops custom applications and workflows for revenue-generating business units, and trains SIE staff on the use of our IT applications such as Confluence, JIRA, Slack, Box & Google Apps for Work. Ideal candidates will have a strong desire to build both in-depth technical skills and an ability to develop exemplary client-facing skills. Candidate will implement, and maintain leading-edge analytic systems, taking complicated problems and building simple frameworks. Identify trends and opportunities for growth through analysis of complex data sets and generate forward looking insights for the business.\n\nResponsibilities\n\nEvaluate organizational methods and provide source-to-target mappings and information-model specification documents for data sets.\nWork closely with IT teams and maintain focus on their analytical needs, including identifying critical metrics and KPIs, and deliver actionable insights to relevant decision-makers.\nCreate best-practice reports based on data mining, analysis, and visualization.\nCreate and maintain rich interactive visualizations through data interpretation and analysis integrating reporting components from multiple data sources.\nEvaluate internal systems for efficiency, problems, and inaccuracies, developing and maintaining protocols for handling, processing, and cleaning data.\nDevelop and maintain databases by acquiring data from primary and secondary sources, and build scripts that will make our data evaluation process more flexible or scalable across data sets.\nRespond to requests for ad hoc analysis and investigate data inconsistencies.\n\n\n\nQualifications\n\nBachelor’s degree in Computer Science, Engineering, Mathematics or related\n1+ year experience mining data as a data analyst and visualizing using Tableau\nAt least 1 year of full-time professional experience working extensively with databases such as RedShift, and/or MySQL\nProficient with Python or R as well as Excel\nProven analytic skills, including mining, evaluation, analysis, and visualization\nTechnical writing experience in relevant areas, including queries, reports, and presentations\nStrong SQL or Excel skills with the ability to learn other analytic tools\nStrong written and verbal communication skills\n\n\nSony is an Equal Opportunity Employer. All persons will receive consideration for employment without regard to race, color, religion, gender, pregnancy, national origin, ancestry, citizenship, age, legally protected physical or mental disability, covered veteran status, status in the U.S. uniformed services, sexual orientation, gender identity, marital status, genetic information or membership in any other legally protected category.\n\n We strive to create an inclusive environment, empower employees and embrace diversity. We encourage everyone to respond.\n\n We sincerely appreciate the time and effort you spent in contacting us and we thank you for your interest in PlayStation."},{"jobtitle":"Data Analyst - USA","companyname":"Ingram Micro.","companyid":"","address":"","geo":"Williamsville, NY, US","postDate":"Oct 29 2018","views":"16","applicants":"4","employees":"","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Computer Software","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nMarketing Data Analyst and Customer Insights Role\n\n Ingram Micro helps businesses fully realize the promise of technology.TM No other company delivers the full spectrum of global technology and supply chain services to businesses around the world. Ingram Micro's global infrastructure and deep expertise in technology solutions, supply chain, cloud and mobility enable its business partners to operate efficiently and successfully in the markets they serve. Combined with distinct market insights and the trust and dependability generated from decades of strong partner relationships, Ingram Micro stands apart as the global technology services provider for the future.\n\nAs a Marketing Data Analyst, you will analyze and synthesize partner, market and competitive data to translate findings into business insights and action plans to support improved performance.\nYou will provide financial and business information, analysis, and insight to the company's leadership team around Marketing initiatives. You will be a member of a high-impact, fast paced, Account team driven to show marketing results.\nDevelop and present insightful presentations across departments that outline significant changes in customer behavior and the marketplace with recommendations for actions. You will Communicate insights across relevant forums in order to broadly inform key decision makers.\nThe Marketing Analyst is responsible for developing and analyzing data models that generate knowledge into the project owner's business objectives and show how marketing activities tie to revenue growth.\nHe or she will utilize reports of findings and create appropriate materials to communicate the findings across multiple departments.\nThey will maintain a broad understanding of Ingram Micro's business model along with becoming educated on vendors, partners, end users and internal division's business models and needs.\nThey must understand client's objectives and translate business needs into the appropriate technical data models.\nExpertise to prepare data models and review output to ensure model accuracy, along with translating the trends and applying to business demands.\nThey must have the ability to data-mine and aggregate data from multiple sources and provide a cohesive report back to associates and people managers.\nHe or she must have strong business acumen and be able to work on most projects independently and lead projects with guidance from management.\nEffectively listen, communicate, recommend, and present data analytic solutions to internal and external clients, including over the phone meetings, in person presentations with PowerPoint, and other media sources.\nWe're looking for an ambitious, focused professional who is comfortable with change and can provide great story-telling through data.\n\nRequirements\n\nMaster's degree in quantitative discipline (Statistics, Applied Mathematics, Operations Research, Computer Science, or Econometrics) and 2 years of experience OR Bachelor's degree in quantitative field with 5-10 years relevant experience.\nExperience working on research and analytics initiatives in the areas of digital marketing, customer experience, branding, advertising, marketing communications and customer segmentation.\nExperience in analysis of large data sets, identifying trends and patterns.\nExperience with Modeling Techniques (linear regression, logistic regression, decision tree), Query Languages (SQL, Python), Automation (SQL Stored Procedures, SSIS, APIs), Reporting (Excel, .Net, MicroStrategy), prior management of a project in which a relational database was built and utilized for analysis, Google Analytics, and Data Mining experience\n\nIngram Micro Inc. is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, veteran status, or any other protected category under applicable law.\n\n SDL2017"},{"jobtitle":"Data Engineer","companyname":"American Financial Group","companyid":"","address":"","geo":"Cincinnati, OH, US","postDate":"Oct 29 2018","views":"","applicants":"0","employees":"","jobDetails":[{"level":"Entry level","industry":["Information Technology & Services","Insurance","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nLocation US-OH-Cincinnati\n Posted Date 27 minutes ago(10/16/2018 10:41 AM)\n\n Job ID 24225\n # Positions 1\n Category Technology\n Position Type Full Time\n\nOverview\n\nBe Here. Be Great. Working for a leader in the insurance industry means opportunity for you. Great American Insurance Group, a member of American Financial Group, is a Fortune 500 company consistently recognized as a top place to work. We combine a 'small company' culture where your ideas will be heard with 'big company' expertise to help you succeed. With over 30 specialty property and casualty operations and a variety of financial services, there are always opportunities here to learn and grow.\n\n Great American's Predictive Analytics division is looking for a Data Engineer to join their growing and dynamic team.\n\nResponsibilities\n\nWork with project team and business stakeholders to determine data requirements for analysis\nAcquire and manipulate internal and external data to create clean reproducible data sets to facilitate predictive modeling\nBuild comprehensive data sets from various source systems including Hadoop, Oracle warehouses/marts, SQL Server, API's, XLS, etc.\nWork with Information Technology to develop production solutions to bring predictive analytics to the enterprise\nResearch and evaluate new methods and tools to improve data gathering processes\nDesign and implement database structures for modeling solutions\nComplete descriptive analyses on various data sets\nResearch business unit queries regarding model outputs; this includes score shifts, missing items, reason messages, etc.\n\nQualifications\n\nSuperior organizational leadership skills.\nIntegrates multiple concepts across job functions with a goal of overall benefit to the organization.\nAbility to communicate, develop and leverage strategic business relationships across the organization and externally.\nRequires advanced technical and business knowledge.\nSelf-motivated team player who excels in a collaborative environment.\nContributes beyond job role and responsibilities.\nExcellent problem solving skills.\n\nRequired\n\nStrong SQL and database knowledge (Oracle preferred)\nUnderstanding of ETL techniques and processes\nStrong Excel knowledge/experience including Macros and VB development\nSOAP and REST web service experience testing and development\n\nPreferred\n\nPrevious experience in the P & C insurance industry\nReport development/design experience (Tableau / Cognos preferred)\nStrong Software Engineering practices developing enterprise applications - Java, Spring, XML, JDBC/JPA/Hibernate\nFamiliar with approximate string matching techniques (fuzzy matching)\nHadoop Development - interfacing with data stored in Hadoop environment (Familiar with technologies including: Hive, Pig, Spark, HDFS, Sqoop, Flume, HAWQ, Zeppelin)\nExperience with Informatica Data Quality Suite & Infomatica Data Integration Suite (PowerCenter)\nExperience in Linux\nExperience with R/R-Studio\nText Mining experience utilizing Python or R a plus\n\nEducation: Bachelor's degree or higher in Information Technology, Informatics, Computer Science, Information Systems, or equivalent experience\n Experience: 0-6 years of relevant experience\n\n Options"},{"jobtitle":"Data Engineer, Alexa Smart Home/IOT","companyname":"Amazoncom Services Inc","companyid":"","address":"","geo":"Bellevue, WA, US","postDate":"Oct 29 2018","views":"","applicants":"0","employees":"","jobDetails":[{"level":"Entry level","industry":["Information Technology & Services","Computer Software","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nJob Description\n\nData Engineer, Alexa Smart Home/IOT\n\n Location: US-WA-Bellevue\n\n Job ID: ******\n\n Company: : ********** Services, Inc.\n\n Position Category: Business Intelligence\n\n Company/Location (search) : Country (Full Name): : United States\n\nJob Description\n\nAlexa is the cloud service that powers Amazon Echo, the groundbreaking device designed around your voice. This is an opportunity to join a growing team that is working to build an exciting new Amazon business in voice.\n\n We are looking for candidates who want to help shape the future of human-computer interactions. Specifically, we are looking for an outstanding Data Engineer who is looking to work in a new space to help define how we use multi-modal data (voice, mobile, desktop) to understand customer behavior and satisfaction. In this role, you will develop and support the data pipelines that give our teams flexible and structured access to their data.\n\n The successful candidate will be an expert with coding and scripting languages to build and deploy complex data pipelines. The candidate will need to be a self-starter, comfortable with ambiguity in a fast-paced and ever-changing environment, and able to think big while paying careful attention to detail.\n\nResponsibilities\n\nYou know and love working with data engineering tools, can model multidimensional datasets, and can partner with other technical teams and end-users to gather data sets needed to answer key business questions. You will also have the opportunity to display your skills in the following areas:\n\nDesign, implement, and support a platform providing ad-hoc access to large data sets\nInterface with other technology teams to extract, transform, and load data from a wide variety of data sources\nImplement data structures using best practices in data modeling, ETL/ELT processes, and SQL, Redshift, and OLAP technologies\nModel data and metadata for ad-hoc and pre-built reporting\nInterface with business customers, gathering requirements and delivering complete reporting solutions\nBuild robust and scalable data integration (ETL) pipelines using SQL, Python and Spark.\nBuild and deliver high quality data sets to support business analyst, data scientists, and customer reporting needs.\nContinually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers\nParticipate in strategic & tactical planning discussions, including annual budget processes\n\nBasic Qualifications\n\nBachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering).\n5+ years of relevant experience in one of the following areas: Data engineering, database engineering, business intelligence or business analytics.\n5+ years of hands-on experience in writing complex, highly-optimized SQL queries across large data sets.\n2+ years of experience in scripting languages like Python etc..\n2+ years of experience in coding languages: Java/Scala\nDemonstrated strength in data modeling, ETL development, and Data warehousing. Data Warehousing * Experience with Redshift, Oracle, etc.\nExperience with AWS services including S3, Redshift, EMR and RDS.\nExperience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.)\nExperience in working and delivering end-to-end projects independently.\nKnowledge of distributed systems as it pertains to data storage and computing\n\nPreferred Qualifications\n\nProven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy\nExperience providing technical leadership and mentoring other engineers for best practices on data engineering\nKnowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations\nMasters in computer science, mathematics, statistics, economics, or other quantitative field\n\nAmazon is an Equal Opportunity-Affirmative Action Employer - Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation"},{"jobtitle":"DATA SCIENTIST/ANALYST","companyname":"Honda R&D Americas, Inc.","companyid":"164214","address":"","geo":"Raymond, OH, US","postDate":"Oct 29 2018","views":"185","applicants":"32","employees":"10001","jobDetails":[{"level":"","industry":["Electrical & Electronic Manufacturing","Automotive","Mechanical Or Industrial Engineering"],"jobtype":"Full-time","function":["Engineering","Information Technology"]}],"description":"Job description\nHonda R&D Americas, Inc. is an innovative and dynamic company responsible for the complete product creation of Honda & Acura products, including automobiles, power sports and power equipment. As a member of the Enterprise Applications team in the Information Systems Division, you will be at the forefront of implementing systems, services and software/data products that will focus on ensuring the efficient operations of the R&D business.\n\n We are seeking a data analyst engineer who will use insights gained from analyzing company data to support our development, administrative, and leadership teams. The candidate must be proficient at using large data sets to find opportunities for process optimization across multiple business divisions. They must be comfortable working and communicating with a diverse group of stakeholders and functional teams. The ideal candidate is expected to have a high level of knowledge and experience in data mining and analytic methods, and creating/running simulations. We are looking for someone to bring passion for solving complex problems with data sets and working with stakeholders to positively influence our business outcomes.\n\n Each day will bring new and exciting challenges on the job while you:\n\n\nLearn and use groundbreaking technologies\nInteract with leading Engineers & Management from across the organization globally\nExperience world class products & services built in front of you and by you\n\n\nEssential Job Requirements\n\n\nBusiness Analysis – Capture and interpret the business needs/requirements through appropriate means (interviews, document analysis, workshops, etc) and identify opportunities to leverage data to drive the business solution.\nProcess Improvement – Actively participate and assist in the projects, mine and analyze data from company databases to drive optimization and improvement of product development and business strategies. Ability to assess productivity and accuracy of new data sets, develop data models and algorithms to apply to the data sets.\nAdvanced Thinking – Use predictive modeling and what-if analysis to increase and optimize stakeholder/customer experiences and influence business outcomes. Develop processes and tools to monitor and analyze model performance and data accuracy.\nCritical Thinking & Problem Solving - Recognizes problems and/or opportunities that are new or without clear precedent. Evaluates alternatives and finds solutions using a systematic, multi-step approach with the goal of providing improvements or innovations to enhance the business.\nData Visualization – Organize and develop easy to use and interpret reports/dashboards for use by all levels of the organization. Employing basic user experience methods and delivery techniques to enable quick understanding, what-if analysis and decision-making.\nBA or BS or equivalent experience in Statistics, Mathematics, Computer Science or another quantitative field is required.\nMinimum 5 years of experience manipulating data sets and building statistical models desired\nAbility to interpret data and trends, and present recommendations\nExperience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.\nFamiliar with relational databases / Hadoop-based data mining frameworks, SQL, Java and C/C++\nKnowledge of different data mining techniques and advance machine learning algorithms such as regression, simulation, scenario analysis, modeling, clustering, decision trees, text mining, etc.\nExperience visualizing/presenting data for stakeholders\nStrong analytical, planning, and organizational skills with an ability to manage competing demands\nUnderstanding of data analytic concepts and best practices, with a drive to learn and master new technologies and techniques.\nExcellent oral and written communications skills and experience interacting with both business and IT individuals at all levels including the executive level\nCreative approach to problem-solving with the ability to focus on details while maintaining the “big picture” view.\n\n\nHonda R&D Americas, Inc."},{"jobtitle":"Analytics Coordinator, Creative Testing (Jr. Analyst)","companyname":"Essence Digital Ltd","companyid":"","address":"","geo":"New York City, NY, US","postDate":"Oct 29 2018","views":"1","applicants":"1","employees":"","jobDetails":[{"level":"Entry level","industry":["Marketing & Advertising","Online Media","Internet"],"jobtype":"Full-time","function":["Other"]}],"description":"Job description\nAbout Essence\n\nEssence, part of GroupM, is a global data and measurement-driven agency that blends data science, objective media and captivating experiences to build valuable connections between brands and consumers. Clients include Google, FrieslandCampina, and the Financial Times. The agency is more than 1,100 people strong, manages over $3.2B in media spend and deploys campaigns in 71 markets via its global offices throughout North America, EMEA and APAC.\n Visit ***************** for more information and follow us on Twitter at @essenceglobal\n\nAbout The Role\n\nWe rely on Analytics professionals who are well-rounded: individuals with a strong academic background, skills and interest in data science, creative thinking about our analytics offering and ability to translate their analysis into compelling insights for our clients.\n The individual will be part of the Essence digital marketing creative testing team and work closely for a well-established but extremely dynamic client that does not require introduction. Google is looking to partner with Essence and utilize our skills, methods and expertise in digital marketing to further strengthen branding and promote the ecosystem.\n\n You will help the Analytics team in designing the analysis plan, formulating research hypothesis, conducting deep dive analysis and delivering insights on each of the business problem.\n\nResponsibilities\n\n\n\nImplement a variety of analytical techniques, ranging from data mining, to statistical modeling and numerical optimizations on a wide range of data sources (brand equity, engagement and diagnostic metrics, website visits etc)\n\n\n\nProvide intellectual leadership and analytic creativity\n\n\n\nAnalyze and synthesize marketing research data to draw key insights and communicate them to clients and senior leaders\n\n\n\nParticipate in brainstorming sessions with media planners, creative teams, clients and other partner agencies to develop robust research methodologies\n\n\n\nApply independent critical thinking in day-to-day work to uncover research insights\n\n\n\nUtilize analysis to uncover business opportunities and improvement areas\n\n Please note: this is data analyst entry level role within our digital marketing research team not an account management, media planning position.\n\n Education\n\n\n\nBachelor's degree from a top-tier college or university\n\n\n\nConcentration in statistics, mathematics, economics, quantitative finance, actuarial science, engineering or other fields of study where math, statistics and research design are important components of the curriculum.\n\n\n\nMaster's degree preferred\n\n Work Experience\n\n\n\nMinimum 1-2 years of experience in an analytics function is highly preferred. Internship experience will also be considered.\n\n\n\nMedia or marketing experience is a plus\n\nSkills\n\nProficiency with data-management and statistical languages: R / Python / SAS\n\n\nBackground in marketing analytics, statistical analysis or model development\n\n\n\nAbility to work in a deadline-oriented environment\n\n\n\nData visualization and presentation\n\n\n\nAbility to scope a solution out of noisy data\n\n\n\nStrong organizational and time management skills\n\n\n\nHigh level attention to details\n\n\n\nExcellent verbal,written communication skills with ability to tell a story behind the data\n What you can expect from Essence\n Essence's mission is to make advertising more valuable to the world. We do this by employing the world's very best talent to solve some of the toughest challenges of today's digital marketing landscape. It's important that we hire people whose values reflect those of our own: genuine, results-focused, daring and insightful. As an Essence employee, we promise you a workplace that invests in your career, cares for you and is fun and engaging. We believe these factors create a workplace where you can be yourself and do amazing work."},{"jobtitle":"Senior Data Engineer","companyname":"Course Hero","companyid":"309629","address":"","geo":"2000 Seaport Blvd, Redwood City, CA 94063, US","postDate":"Oct 29 2018","views":"38","applicants":"5","employees":"51-200","jobDetails":[{"level":"Director","industry":["E-learning","Internet"],"jobtype":"Full-time","function":["Education","Engineering"]}],"description":"Job description\n\nThe Role:\n\n\n\n\nCourse Hero is looking to hire a Senior Data Engineer to play a critical role in building the next generation Data Analytics platform. The Data Team’s mission is to build and maintain the data platforms that support all teams in engineering ranging from machine learning, analytics to research engineering and product design.\n\n\n\n\nAs a Senior Data Engineer you will have deep hands-on experience working with Data Scientists, Machine Learning experts, and search engineers. The scalable systems you build will enable our teams of machine learning experts and product designers to bring powerful recommendation and personalization models to the Course Hero platform.\n\n\n\n\nHere are some ways you’ll make an impact:\n\n\n\n\nYou’ll work with a team of passionate data engineers to enable data mining, deep learning applications for revenue optimization, statistical modeling, predictive analytics, machine learning, and NLP.\nYou’ll empower data scientists, machine learning experts, and analysts to innovate and discover insights by removing the technical barriers that come with processing big data.\nYou’ll ensure compliance with the organization's high bar for data quality and modeling standards, across the product vertical and related business areas; including high standards for automation and self-service for all products created.\nYou’ll provide tools to empower internal teams across the organization (sales, operations, finance, engineering, etc.) to make data-driven decisions.\nYou’ll institute development best practices to ensure the team produces high quality, well architected and supportable code through a continuous delivery model.\nYou’ll participate in document administration and response procedures through runbooks & playbooks.\n\n\n\nAre you our Star Senior Data Engineer?\n\n\n\n\nYou have worked with Machine Learning experts and Data Scientists to enable self-service data ingestion, transformation, visualization, reporting, and advanced analytics (machine learning, AI).\nYou are a strategic thinker and thrive operating in a broad scope, from conception through continuous operation.\nYou have a robust Ops foundation - you’re always thinking “What happens if this fails” when you build things.\nYou have a Bachelor’s or Master’s degree in computer science, mathematics, economics, engineering, or other related fields.\nYou have hands-on experience working with large scale data ingestion, ETL processing, storage, Hadoop ecosystems, Spark, non-relational databases (NoSQL, MongoDB, Cassandra), and messaging systems (Kafka, Kinesis, RabbitMQ).\nYou have written scripts in one or more languages such as Python or Go.\n\n\n\nBonus Points:\n\n\n\n\nYou understand open source software like Kafka, Arvo, ElasticSearch, NGINX, Kubernetes, and Docker.\nYou are familiar with Python analytics libraries or use of R language.\nYou have experience with standard IT security practices such as Access, Authorization, and Key Management.\nYou have performed hands on work using AWS stack (i.e. S3, Redshift, EC2, SNS, SQS, SES, Dynamo DB).\n\n\n\nWhat We Offer You:\n\nIndustry competitive salary and stock options\nFull coverage (medical, dental, vision, and life)\n401(k) program to help you save for the future\nEducational assistance program to support lifelong learning\nFree weekly lunches, plus an endless snack and drink supply\nRegularly planned team outings and company events\nCommuter benefits, cell-phone allowance, and a free gym membership\nOpportunity to make a meaningful impact in a revolutionary space"},{"jobtitle":"Data Analyst III","companyname":"ADP","companyid":"1463","address":"","geo":"Alpharetta, GA, US","postDate":"Oct 29 2018","views":"9","applicants":"0","employees":"10001","jobDetails":[{"level":"","industry":["Computer Software","Financial Services","Human Resources"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nADP is hiring a Data Analyst III. We're looking for a Business Systems Analyst (NLP Natural Language Processing)/ Text Analytics Analyst that will be responsible for key business metrics and reporting that drives decision making and process improvement for the Business Unit. A champion for standardizing and automating internal client-facing reports provided to Business Units. Be a change agent within the Business Unit's closed loop administration to ensure accurate and high quality data is collected and analyzed on a consistent basis. Leverage a variety of analytical tools to provide information that is flexible, responsive and nimble to changing business needs. The Data Analyst is responsible for Client Experience Analysis/Providing Actionable Insight to the front line leaders.\n\nAt ADP we are driven by your success. We engage your unique talents and perspectives. We welcome your ideas on how to do things differently and better. In your efforts to achieve, learn and grow, we support you all the way. If success motivates you, you belong at ADP.\n\n We strive for every interaction to be driven by our CORE values: Insightful Expertise, Integrity is Everything, Service Excellence, Inspiring Innovation, Each Person Counts, Results-Driven, & Social Responsibility.\n\nResponsibilities\n\nAnalytics/ Consulting/Communicating\nConducts NPS project initiation activities\nUncover complex client experience opportunities, through the use of data insights\nAnalyze existing client systems, interface requirements, business process and operational needs.\nAssess client experience data including client feedback (qualitative & quantitative), predictive modeling, and client behaviors and profiling\nGather, assemble, analyze and deliver actionable insights and recommendations.\nProvides professional consulting in the areas of tool customizations, business processes, analytics, complex custom reports and special projects\nResponsible for researching benchmarked and attainable validated systemic tools to evaluate HR performance, resulting in metrics that help senior leaders drive Service Excellence.\nDevelop meaningful analytic conclusions and recommends innovative and actionable solutions\nWork with Business Unit champions and Subject Matter Experts (SMEs) to define requirement related to reporting, analytics, trending and communications.\nCoordinates and consults with Corporate IT for customization work\nDevelops adhoc inquiries to assist in reporting, categorization and analysis\nProvides demos and training for champions and SMEs, including documentation as required for reporting, analysis, trending and communication.\nWorks and counsels with business units on system and service configuration tools, tool adaptation and business best practice solutions.\nDetermines best methodology and oversees the accurate and timely conversion of survey data, reporting and analytics.\nBusiness Unit and Center of Excellence teams will work collaboratively to standardize all aspects of analytics and reporting.\nTrain appropriate uses on analytical tools to ensure widespread adoption of best practices in collecting and analyzing data for actionable recommendations to leaders.\nPerforms other related duties as assigned.\n\n\n\nQualifications Required\n\n8 to 12 Years of Directly Related Experience\nBachelor's Degree or its equivalent in education and experience with a Major Area of Concentration in BS in Finance, Accounting, Statistics\n\n\n\nPreference will be given to candidates who have the following:\n\nExcellent quantitative and analytical skills, and strong attention to detail.\nTableau, SQL, CX Analytics, Python, R.\nExcellent project management skills.\nStrong verbal and interpersonal skills, with demonstrated ability to work with and communicate at all levels of staff and management.\nAbility to interpret data into actionable recommendations.\nStrong Excel skills required, including data modeling and ad hoc analysis.\nKnowledge of text mining tools/techniques.\nCan easily build relationships across multiple functions and business Units.\n\n\n\nSoftware In The Cloud. Experts On The Ground\n\nADP powers the working world with comprehensive solutions that drive business success. Consistently named one of the \"Most Admired Companies\" by FORTUNE® Magazine, and recognized by Forbes® as one of \"The World's Most Innovative Companies,\" ADP has over a half-million clients around the globe and 65 years of experience as one of the largest providers of human capital management solutions world-wide.\n\n At ADP, we believe that diversity fuels innovation. ADP is committed to equal employment opportunities regardless of race, color, genetic information, creed, religion, sex, sexual orientation, gender identity, lawful alien status, national origin, age, marital status, or protected veteran status. We support an inclusive workplace where associates excel based on personal merit, qualifications, experience, ability, and job performance."},{"jobtitle":"Data Analyst","companyname":"Credit Sesame","companyid":"1098518","address":"","geo":"Mountain View, California","postDate":"Oct 22 2018","views":"1,412","applicants":"572","employees":"51-200","jobDetails":[{"level":"Associate","industry":["Financial Services"],"jobtype":"Full-time","function":["Engineering","Other","Analyst"]}],"description":"Job description\n\nWe are looking for an Data Analyst who can help support product development. If you are curious and creative with the grit to take on and solve tough analytical problems, this role is for you. This is a unique opportunity to be part of a data science team supporting the creation of innovative products that help millions.\n\n\n\n\nYou’ll be…\n\nmining data from large SQL databases;\nbuilding models that lead to better insights and business understanding;\ndesigning and maintaining reports and dashboards to track and communicate Credit Sesame’s key performance indicators;\nassuring quality and data integrity for revenue and business development;\ninteracting with data source owners and participating in developing project plans;\nproviding creative insights beyond the scope of supporting reactive requests.\n\n\n\n\nYou’ll make an impact because...\n\nyou have 2+ years of experience in data analytics;\nyou have an expertise in statistics, econometrics, and data science—shown through experience or education;\nyou have a command of machine learning concepts and tools, including improving model performance;\nyou have deep experience analyzing large data sets, along with experience in creating data flow graphs;\nyou know how to use Python and R to analyze and solve highly complex business problems;\nyou have a deep understanding of SQL;\nyou have the adaptability and agility needed in a high-growth, startup environment;\nyou have an eCommerce background (preferred but not required);\nyou have past experience in financial services or technology, and a passion for FinTech;\nideally, you have a Master’s degree in a quantitative field of study.\n\n\n\n\nYou’ll love working with us because...\n\nwe pioneered the Personal Credit Management space;\nyou will have huge potential to grow with a dynamic startup that’s a category leader;\nwe have an amazing company culture with the best coworkers in the Bay Area;\nyou will get equity in a leading startup that is backed by top VCs, along with comprehensive medical, dental, vision insurance;\nwe have meals catered twice a week;\nwe offer both free on-site fitness centers and a monthly fitness reimbursement; we have fully-stocked kitchens with tasty snacks and drinks;\nwe have open paid time off—take the time off you need so you’re happy and healthy;\nwe are only a block from the Montgomery Street BART;\nyou can work in either our San Francisco or our Mountain View office;\nwe are an equal opportunity employer."},{"jobtitle":"Data Engineer","companyname":"Tokio Marine Technologies, LLC","companyid":"","address":"","geo":"Duluth, GA, US","postDate":"Oct 22 2018","views":"2","applicants":"0","employees":"","jobDetails":[{"level":"Entry level","industry":["Information Technology & Services","Computer Software","Insurance"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nPosition Summary And Responsibilities\n\nAs a Data Engineer, you will be developing strategies, standards and best practices in the areas of data wrangling, data visualization and data integration and lead adoption throughout analytical platforms. The Data Engineer is essential to understanding the analytical need and use big data technologies to analyze data and develop analytical data sets used for research, development and deployment of insights. The Data Engineer will have an eye for building and optimizing data systems and will work closely with various stakeholders such as actuaries and underwriters, IT and data analysts to develop data pipelines and ensure consistency and compatibility of data development across multiple projects.\n\n The Data Engineer will support our group companies in developing new insights that leverage data assets.\n\nAdditional Responsibilities Of The Data Engineer Include\n\nCollaborate with a group company(GC) to create pilot cases in regard to actual usage of big data, and share it with other GCs. Followings are some examples of actual usage;\nText mining to utilize unstructured data in predictive models\nProvide expert advice in cutting edge modeling techniques\nA common mapping/geocoding solution\nCollect big data which is useful in pricing/underwriting/reserving etc. from external data sources (such as websites), and establish data hub on group wide basis.\nCollaborate with/Support Silicon Valley team as well as Digital Strategy Group in TMHD from technical point of view in regard to data science.\n\n\nRequired Skills\n\n3-5 years real project experience as a data engineer to handle unstructured data\n3+ years experience in Big Data technology including: HIVE, Impala, Python, and Scala\nStrong data analysis skills including skills to rapidly learn new data assets\nRegular and reliable attendance\n\n\nPreferred/Other Skills\n\nExperience working in insurance industry\nStrong interpersonal skills and ability to project manage and work with cross-functional teams\nAbility to overcome obstacles to solve the hardest problems\nFlexible and responsive with ability to adapt to rapid change in direction or business priority\nFrequent domestic and international travel is possible (Especially Houston, San Fransisco, London and Asia)\nAbility to work independently with limited supervision as well as contribute to team efforts is required\nAbility and desire to communicate technical matters in order to train others and lead adoption of new tools and technologies.\nExcellent oral and written communication skills\nAbility to innovate and apply new ideas\nKnowledge and ability to share big data to only necessary stakeholders in legitimate manner\n\n\nEducation\n\n\nBachelor's Degree (Computer Science/Engineering or equivalent work experience)\nMaster's degree (preferred)\nprovided by Dice HIVE, Impala, Python, Scala"},{"jobtitle":"Senior Data Engineer","companyname":"Fanatics, Inc.","companyid":"68543","address":"","geo":"San Mateo, CA, US","postDate":"Oct 22 2018","views":"707","applicants":"145","employees":"1001-5000","jobDetails":[{"level":"Associate","industry":["Marketing & Advertising","Consumer Goods","Retail"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nFanatics is the global leader in licensed sports merchandise that changes the way fans purchase their favorite team apparel and jerseys through an innovative and tech-infused approach to making and selling fan gear in today’s on-demand culture. We have the world’s largest collection of officially licensed fan gear from all the leagues, teams and players our fans love. We operate more than 300 online and offline stores including e-commerce business with all major professional sports leagues (NFL, MLB, NBA, NHL, NASCAR, MLS, PGA), major media brands (NBC Sports, CBS Sports, FOX Sports) and over 150 collegiate and professional team properties. We partner with over 1000 vendors including Adidas, Nike, Reebok and Under Armor.\n\n Our inventory intelligence team in close collaboration with data science team has a charter to build data-driven applications & services to develop supply chain & inventory management excellence at Fanatics. The team plays a key role in building data pipelines that extract and process raw data into useful data analytics and aid data scientists to develop predictive models to meet our business’s growing activities and potential. The pipelines are core to inventory replenishment algorithms, pricing optimization, assortment optimization, and deriving key business insights for our merchandising and fulfillment operations. We also build automation tools and monitoring systems to improve our development cycle.\n\n We are seeking for a Senior Data Engineer who has strong architectural skills and upkeeps scalability, availability and excellence when building the next generation of our data pipelines and platform. You are an expert in various data processing technologies and data stores, appreciate the value of clear communication and collaboration, and devote to continual capacity planning and performance fine-tuning for emerging business growth. As the Senior Data Engineer, you will be designing and building inventory intelligence data pipelines and application platform services that power business decisions.\n\nWhat Will You Do?\n\n\nArchitect and build inventory intelligence data pipelines and platform that can parse raw data algorithmically from different data sources, and deliver quality real-time analytical reports for all our replenishment team and our business analytics\nDevelop clean, safe, testable and cost-efficient solutions; Build fast and reliable pipeline, platform with underlying data model that can scale according to business needs and growth\nWork with backend engineers to create services that can ingest and supply data to and from external sources, provide data streaming solutions and ensure data quality and timeliness\nWork with product manager to translate business requirements into scalable solutions, prioritize workload and deliver quality and functional products on a timely manner that can grow over time\nMake well-informed decisions with deep knowledge of both the internal and external impacts to teams and projects\nUnderstand the system you are building, foresee shortcomings ahead of time and be able to resolve or compromise appropriately\n\n\nWhat Are We Looking For?\n\n\nExcellent understanding of data structures algorithms and at least 4 years of experience in distributed systems\nKnowledge of common design patterns used in Big Data processing\nStrong development experience using programming languages: Scala, Java, C++, Python\nProficiency in big data technologies: Spark, Hadoop, Flink, Hive\nExperience with and deep understanding of traditional, NoSQL and columnar databases such as Oracle, MySQL, PostgreSQL, DynamoDB, Redshift, Vertica\nKnowledge and experience in designing and developing data modeling & mining, ETL, data warehouse, deployment and infrastructure management, and performance tuning\nExperience in partnering with architects, engineers in data environments that are complex, enterprise wide, multi-tenant, and host large scale of data\nAbility to build systems that balance scalability, availability and latency while solving different problems\nAdvocator of continual deployment and automation tools that can help improve the lives of our engineers\nA good communicator and team player who has a proven track record of building strong relationships with management, co-workers and customers.\nA desire to learn and grow, push yourself and your team, share lessons with others and provide constructive and continuous feedbacks, and receptive to feedback from others"},{"jobtitle":"Sr. Associate, Data Engineer, Financial Services","companyname":"KPMG US","companyid":"1079","address":"","geo":"New York City, NY, US","postDate":"Oct 22 2018","views":"31","applicants":"4","employees":"10001","jobDetails":[{"level":"Mid-Senior level","industry":["Management Consulting"],"jobtype":"Full-time","function":["General Business"]}],"description":"Job description\nRequisition Number: 36702 - 64\n\nDescription\n\nInnovate. Collaborate. Shine. Lighthouse – KPMG's Center of Excellence for Advanced Analytics – has both applied data science, AI, and big data architecture capabilities. Here, you'll work with a diverse team of sophisticated data and analytics professionals to explore the solutions for clients in a platform-diverse environment. This means your ability to find answers is limited only by your creativity in leveraging a vast array of techniques and tools. Be a part of a high-energy, diverse, fast-paced, and innovative culture that delivers with the agility of a tech startup and the backing of a leading global consulting firm. For you, that translates into the chance to work on a wide range of projects – covering technologies and solutions from AI to optimization – and the power to have a real impact in the business world. So, bring your creativity and pioneering spirit to KPMG Lighthouse.\n\n KPMG is currently seeking a Sr. Associate, Data Engineer to join our KPMG Lighthouse - Center of Excellence for Advanced Analytics to work with our Financial Services team.\n\nResponsibilities\n\nRapidly prototype, develop, and optimize D&A implementations to tackle the BI/EDW/Big Data and Data Science needs for a variety of Fortune 1000 corporations and other major organizations\nDesign, develop and maintain D&A solutions on premise/cloud/KPMG-hosted/hybrid infrastructure; Be the team champion of some mainstream BI/EDW/Big Data toolsets like Tableau, Alteryx, Informatica, Pentaho, Er-Win, and Power Designer\nPlay the role of data owner in cross-disciplinary teams; Build logical/physical data models; Discover, profile, acquire, process, model and own data for the solutions\nImplement data processing pipelines, data mining/science algorithms, and visualization engineering to help clients distill insights from rich data sources, including social media, news, internal/external documents, emails, financial data, client data and operational data\nActively be involved in research and experiment of leading/emerging BI/EDW/Big Data methodologies such as serverless data lake, AWS Redshift, Athena, Glue, GCP BigQuery, and MS PowerBI and apply them to real client solutions\nBe the data engineering SME in the process for pursuing innovations, target solutions, and extendable platforms for Lighthouse, KPMG and client\n\n\nQualifications\n\nMinimum of three years of relevant data engineering experience in related industries, preferably professional services; Experience and knowledge of RDBMS design, data modeling, MPP EDW system implementation; Have completed two plus production BI/EDW/Big data projects with the ability to communicate complex technical concepts to non-technical personals at all levels\nBachelor's Degree, Master's Degree or PhD from an accredited college/ university in Computer Science, Computer Engineering or related field\nHands-on experience and knowledge in: BI/EDW/Big Data toolsets (Tableau, Alteryx, Informatica, Pentaho, Er-Win, Power Designer); Mainstream cloud infrastructures (AWS, MS Azure and GCP; their D&A-related Microservices); Implementing data lake and serverless data lake; Proficient-level fluency of SQL\nHands-on experience of Linux/Unix/Windows/.NET; Market-leading fluency in several programming languages: Bash/ksh/PowerShell; Python/Perl/R; Ability to pick up and learn new technologies quickly\nHands-on experience and knowledge in distributed computing architecture, massive-parallel processing big data platforms like Hadoop, MapReduce, HDFS, Spark, Hive/Impala, H-Base/MongoDB/Casandra and Teradata/Netezza/Redshift\nAbility to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future\n\nKPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package. KPMG is an affirmative action-equal opportunity employer. KPMG complies with all applicable federal, state and local laws regarding recruitment and hiring. All qualified applicants are considered for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other category protected by applicable federal, state or local laws. The attached link contains further information regarding the firm's compliance with federal, state and local recruitment and hiring laws. No phone calls or agencies please."},{"jobtitle":"Manager, Data Engineer, Financial Services","companyname":"KPMG US","companyid":"1079","address":"","geo":"Philadelphia, PA, US","postDate":"Oct 22 2018","views":"24","applicants":"0","employees":"10001","jobDetails":[{"level":"Mid-Senior level","industry":["Management Consulting"],"jobtype":"Full-time","function":["General Business"]}],"description":"Job description\nRequisition Number: 36703 - 73\n\nDescription\n\nInnovate. Collaborate. Shine. Lighthouse – KPMG's Center of Excellence for Advanced Analytics – has both applied data science, AI, and big data architecture capabilities. Here, you'll work with a diverse team of sophisticated data and analytics professionals to explore the solutions for clients in a platform-diverse environment. This means your ability to find answers is limited only by your creativity in leveraging a vast array of techniques and tools. Be a part of a high-energy, diverse, fast-paced, and innovative culture that delivers with the agility of a tech startup and the backing of a leading global consulting firm. For you, that translates into the chance to work on a wide range of projects – covering technologies and solutions from AI to optimization – and the power to have a real impact in the business world. So, bring your creativity and pioneering spirit to KPMG Lighthouse.\n\n KPMG is currently seeking a Manager, Data Engineer to join our KPMG Lighthouse - Center of Excellence for Advanced Analytics to work with our Financial Services team.\n\nResponsibilities\n\nLead the data engineering team or a work stream in a cross-functional engagement; Provide infrastructure recommendation, roadmap, solution architecture; Rapidly prototype, develop and optimize D&A implementations to tackle the BI/EDW/Big Data and Data Science needs for a variety of Fortune 1000 corporations and other major organizations\nLead/mentor the practice to design, develop and maintain D&A solutions on premise/cloud/KPMG-hosted/hybrid infrastructure; Act as the team champion of some mainstream BI/EDW/Big Data toolsets like Tableau, Alteryx, Informatica, Pentaho, Er-Win and Power Designer\nActively pursue and play data owner role in cross-disciplinary teams; Build solution architecture, logical/physical data models; Discover, profile, acquire, process, model and own data for the solutions; Implement data processing pipelines, data mining/science algorithms, and visualization engineering to help clients distill insights from rich data sources, including social media, news, internal/external documents, emails, financial data, client data and operational data\nSuggest, lead and involve in Research and experiment of leading/emerging BI/EDW/Big Data methodologies, such as serverless data lake, AWS Redshift, Athena, Glue, GCP BigQuery, and MS PowerBI and apply them to real client solutions\nLead/play the data engineering SME in the process for pursuing innovations, target solutions, and extendable platforms for Lighthouse, KPMG and client\n\n\nQualifications\n\nMinimum of seven years of relevant data engineering experience in related industries, preferably professional services (minimum of two years as lead; minimum of one year in the management level)\nBachelor's degree or Master's degree from an accredited college/university in Computer Science, Computer Engineering, or related fields or a PhD with three plus years of relevant experience\nPrevious experience leading/completed a few production data engineering projects, including PoC (proof-of-concept), pilot and full production; Led projects of EDW to Hadoop/Data Lake migration, and/or on premise to cloud migration, involving raw data volume of 100+ TB\nStrong experience and knowledge in: BI/EDW/Big Data toolsets (Tableau, Alteryx, Informatica, Pentaho, Er-Win, Power Designer); Linux/Unix/Windows/.NET; Market-leading fluency of: SQL; and several programming languages (Bash/ksh/PowerShell; Python/Perl/R; Java/C/C++/Scala)\nStrong knowledge in distributed computing architecture, massive-parallel processing big data platforms (such as Hadoop, MapReduce, HDFS, Spark, Hive/Impala, H-Base/MongoDB/Casandra, Teradata/Netezza/Redshift)\nProficiency in: mainstream cloud infrastructures (AWS, MS Azure and GCP; their D&A-related Microservices); and implementing data lake and serverless data lake. Solution certificates of AWS, MS Azure, or GCP is preferred\nAbility to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future\n\nKPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package. KPMG is an affirmative action-equal opportunity employer. KPMG complies with all applicable federal, state and local laws regarding recruitment and hiring. All qualified applicants are considered for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other category protected by applicable federal, state or local laws. The attached link contains further information regarding the firm's compliance with federal, state and local recruitment and hiring laws. No phone calls or agencies please."},{"jobtitle":"Data Application Developer","companyname":"Barrick Gold Corporation","companyid":"","address":"","geo":"Elko, NV, US","postDate":"Oct 22 2018","views":"6","applicants":"0","employees":"","jobDetails":[{"level":"Entry level","industry":["Human Resources","Financial Services","Hospital & Health Care"],"jobtype":"Full-time","function":["Engineering","Information Technology"]}],"description":"Job description\nAbout Barrick & Barrick Nevada\n\nBarrick is the gold industry leader with a vision of wealth generation through responsible mining; wealth for our owners, our people, and the countries and communities with which we partner. Our objective is to maintain and grow industry-leading margins, driven by innovation and our digital transformation; managing our portfolio and allocating capital with discipline and rigor; and leveraging our distinctive partnership culture as a competitive advantage. We aim to cultivate a high-performance culture defined by the following principles: a deep commitment to partnership, consistent execution, operational excellence, disciplined capital allocation, and continual self-improvement. We are obsessed with talent, and seek out fresh perspectives and challenging ourselves to think differently as we transform Barrick into a leading 21st century company.\n\nPosition Description\n\nBarrick is looking for a Data Analyst to join the Analytics and Unified Operations Center (AU Operations Center) team. The Application Developer will be responsible for supporting all Operations personnel by developing application standard reporting and visualization tools that enable leaders and technical specialists to make sound decisions based on data. The reports will be made available to all required personnel as per current standards; daily, weekly, monthly, annually, or as requested by leadership. The Au Operations Center team provides 24 hours a day, 7 days a week support for Barrick Nevada mine sites. They will also support the Au Operations Center leadership and technical team by developing and sustaining internal performance reports, SOPs and other relevant documents. This role will also develop and maintain the performance dashboards that will be displayed in the Au Operations Center and also made available to Barrick Nevada personnel on site with the capacity of testing/utilizing advanced analytics tools, providing capacity to customize reports and completing analysis to gain non- intuitive insights in to production trends.\n\nResponsibilities\n\nApply In-depth knowledge/experience related to mining and mineral processing to support Au Operations Specialists\nSolve complex problems, with new perspective leveraging data, technology and people\nProvide support to integration, implementation and adoption of Digital Portfolio in to Barrick Nevada Au Operations Center\nSupport Au Operations Center main function (Get Data, Develop Tools, Analyze Data, Liberate Data and Act on Data) are occurring within Operating Model and specifically Situational Awareness throughout the process\nWork closely with Au-Operations Center Superintendent and staff to deliver results according to plan and conduct root cause analysis and apply lessons learned\nDevelop, maintain, improve and automate standard reports to increase intuitiveness and ability to act rapidly on information and escalate issues and findings per escalation matrix\nWork with data custodians & operational leadership to ensure data collection source systems provide the most accurate possible\nDeliver high levels of transparency to allow for rapid response to deviation and escalate variance to plan, thereby allowing leadership to respond in a timely manner\nDevelop trust with operational leaders and technical specialists to ensure that they are receiving the required support for day-to-day operations and the implementation of improvement opportunities in a timely manner\nOffer 24-7 support as an escalation point for operational support issues\nCreate ad-hoc analysis & reporting based on disparate information sources and be able to present to senior management your findings\nSuggest metrics and strategies to improve target productions\nDevelop applications to support the preparation and monitor analytics reports on a daily, weekly, monthly and annual basis and ensure insights to performance vs plan\nDevelop tools and applications (multi-languages) that provide insight to data through visual analytics and machine learning (modeling)\nReview, design, and create SOPs and best practices within the Au-Ops Center\nEnsure data accuracy & integrity\nProduce timeliness of data, reports & adherence to escalation matrix\nCapture and enable improvements for Au-Ops Center\nEnsure Au-Ops Center and systems are supporting the business as required\nIntegrate a process of plan, do, check and act for the business to identify and capture new Au-Operations Center opportunities at Barrick Nevada\nPerform other duties as assigned.\n\nQualifications\n\nBachelor's degree in Computer Science, Data Analytics, or related field\nMinimum of two (2) years' experience in application development and data science/analytics\nExperience in mining related functions is preferred\nExcellent verbal and written communication skills\nStrong ability in operational execution and project management\nAbility to meet tight deadlines\nInnovative/creative thinking capabilities\nExperience in C#, .NET, ASP.NET, .Net Web Services (WCF, and ASMX), Java, or Go\nProficiency in Ajax, JavaScript, HTML, DHTML, XML, SQL, CSS\nExperience with Python, R, and/or other statistical programs\nUnderstanding of data structures\nUnderstanding cloud services, such as AWS\nExcellent understanding and experience in Object-oriented design (OOD)\nExperience with designing, maintaining and deploying relational database systems (MSSQL)\nFamiliarity with design patterns\nExperience with creating and consuming web services\nWorking knowledge in an agile development environment\nOSI-Soft PI tools and PI Asset Analytics experience\nExperience with Power BI\nDemonstrated ability to perform essential functions of the position\n\nWhat we can Offer You\n\nA comprehensive compensation package including bonuses benefits, and stock purchase plans where applicable\nAbility to make a difference and lasting impact\nWork in a dynamic, collaborative, progressive, and high-performing team\nAn Opportunity to transform Traditional Mining into the future of Digital Mining\nOpportunities to grow and learn with the industry colleagues are endless\nAccess to a variety of career opportunities across Barrick locations\n\nBarrick is committed to creating a diverse environment and is proud to be an equal opportunity employer.\n\n Thank you for your application, however, only those selected for an interview will be contacted."},{"jobtitle":"Senior Data Analyst","companyname":"Zebra Technologies","companyid":"167024","address":"","geo":"Lincolnshire, US-IL","postDate":"Oct 22 2018","views":"132","applicants":"24","employees":"5001-10000","jobDetails":[{"level":"Mid-Senior level","industry":["Computer Hardware","Computer Software","Information Technology & Services"],"jobtype":"Full-time","function":["Analyst","Information Technology","Research"]}],"description":"Job description\n\nThe Data Scientist manages, architects and analyzes data to build data driven forecasts and business insights. It will require development of predictive models and processes to gather and aggregate data from multiple sources, training and validating data, and visualizing results. It will require working with the business stakeholders and Sales leadership. It requires a deep understanding of statistics/statistical testing, machine learning, data mining, database structures and management.\n\n\nResponsibilities\n\nThe Data Scientist is responsible for developing predictive models to forecast revenue and provide actionable insights in the global Sales organization. It will require development of predictive models and processes to gather and aggregate data from multiple sources, training and validating data, and visualizing results. It will require working with the business stakeholders and Sales leadership. It requires a deep understanding of statistics/statistical testing, machine learning, data mining, database structures and management.\n\nEssential Duties and Responsibilities:\n\nDevelop predictive models and generate data driven forecast and impactful business insights.\nDeep knowledge in Machine Learning methodology.\nDeep knowledge in forecasting revenue using opportunity pipeline data as a variable\nMachine Learning Experience – Experience on Azure Machine Learning (AML) platform and tools are preferred, including deep learning and neural networks, genetics algorithm, etc.\nDevelop processes to manage and enrich large data sets from multiple sources\nManage and manipulate data sets, including: defining variables, performing calculations and summarizations.\nExperience working with relational databases and intermediate level knowledge of SQL.\nData Mining; evaluate and make recommendations to evolve data collected to improve analytics.\nIdentifies meaningful insights from large data sources; interprets and communicates insights and findings from analysis and experiments.\nEvaluate and make recommendations to evolve data collected to improve analytics.\nCreate data visualization in Microsoft Power BI to adequately analyze historical data and display trending.\nMentor and train junior developers and modelers.\nAbility to work in a global collaborative team environment.\nPerforms other duties as assigned.\n\n\nQualifications\nBachelor’s degree. Advanced degree – masters or PhD - strongly preferred in Statistics, Mathematics, Data / Computer Science or related discipline.\nStrong analytical, communication scheduling and organizational skills.\nStrong background in statistical modeling and algorithms.\nData engineering experience, including Bigdata – SQL, NoSQL, Hadoop, Map Reduce, Hive, Pig, Spark, etc. Hands-on experience preferred\nMachine Learning experience – including deep learning and neural networks, genetics algorithm etc\nStatistical and data science programming languages R, PYTHON (required), MATLAB, C++, SAS are a plus.\nComfortable working with and presenting to senior management and CxO level executives\nSelf-motivated and self-starter with high degree of work ethic\nMust be very skilled and knowledgeable in MS Excel. Must have experience creating complex reports, pivot tables, VLOOKUP’s, and macros within Excel.\nMust know how to link data between Microsoft Access, Excel, PowerPoint, SharePoint, Word, and Outlook.\nInnovative/self-thinker/self-motivated ability to comprehend business requirements and translate into final work product. Proactive- Must want to seek out information and solutions that are pertinent to their responsibilities and key to their delivery\nAttention to detail with the highest level of quality and integrity required.\nEnthusiasm and tenacity to carry out difficult tasks through to the end with guidance from Manager.\nTeam player attitude with a focus on the success of the team is a MUST.\n< li>Ability to collaborate with teams across global time zones.\nExcellent oral and written communication skills with ability to present technical and business solution concepts to all levels across functional domains.\nStrong desire to keep current on new technologies that push the limits of what we can do creatively."},{"jobtitle":"Data Scientist - Guaynabo, Puerto Rico","companyname":"UnitedHealth Group","companyid":"1720","address":"","geo":"Rico, CO, US","postDate":"Oct 22 2018","views":"8","applicants":"1","employees":"10001","jobDetails":[{"level":"Entry level","industry":["Internet","Human Resources","Outsourcing/Offshoring"],"jobtype":"Full-time","function":["Engineering","Information Technology"]}],"description":"Job description\nIn this role, Individual will provide recommendations and actionable insights through analysis of data. Individual will need to effectively communicate results of data analysis and reporting to internal stakeholders including, but not limited to, marketing, member engagement, and leadership. Exhibits a strong curiosity about data and excels at harvesting insights from highly complex data across multiple data sources using advanced analytic approaches. Excels at telling a story with data and influencing others to adopt new ideas, products, and/or approaches. Assists in predicting emerging customer needs and develops innovative solutions to meet them. Primary Responsibilities: Develop and implement effective/strategic business solutions through research and analysis of data Harvest insights from data and present findings that will impact business objectives Facilitate effectiveness measurement through test design, implementation support, and post-analysis for new and existing programs and initiatives Assist in managing day-to-day results reporting and visualization for major corporate initiatives Analyze, review, forecast, and trend complex data Develop statistical models, forecasts and conduct statistical analysis to better understand trends, population segments and predict behaviors/outcomes *** ENGLISH PROFICIENT ASSESSMENT WILL BE REQUIRED AFTER APPLICATION ***\n\n Required Qualifications: Bachelor degree Minimum of 1 year of experience in predictive/statistical modeling using SAS or R or Python Proficient in MS Office applications Excel proficiency (Pivots, V-Lookups, Formulas) Bilingual (Spanish / English) Preferred Qualifications: Master’s Degree Experience performing data analysis Experience extracting data using SQL and/or data exploration tools (such as SAS or R) Experience with data analytics design Experience working with large databases Health care industry experience Demonstrated ability to effectively gather requirements, probe for deeper understanding, and translate deep technical concepts to non-technical as well as technical senior stakeholders, marketing customers, and data scientists Demonstrated ability to manage people and prioritize deliverables Proven organizational skills with ability to be flexible and work with ambiguity Careers with Optum. Here's the idea. We built an entire organization around one giant objective; make the health system work better for everyone. So when it comes to how we use the world's large accumulation of health-related information, or guide health and lifestyle choices or manage pharmacy benefits for millions, our first goal is to leap beyond the status quo and uncover new ways to serve. Optum, part of the UnitedHealth Group family of businesses, brings together some of the greatest minds and most advanced ideas on where health care has to go in order to reach its fullest potential. For you, that means working on high performance teams against sophisticated challenges that matter. Optum, incredible ideas in one incredible company and a singular opportunity to do your life's best work.(sm) Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.UnitedHealth Group is a drug-free workplace. Candidates are required to pass a drug test before beginning employment. Job Keywords: Data Scientist, Technology, Data Analysis, Data Analyst, Statistical Models, SQL, Python, SAS, RStudio, R-Studio, Predictive Model, Data Exploration, Data Extraction, Data/Hadoop, San Juan, PR, Puerto Rico"},{"jobtitle":"Senior Technical/Data Analyst","companyname":"Enterra Solutions, LLC","companyid":"42280","address":"","geo":"New York, New York, United States","postDate":"Oct 22 2018","views":"425","applicants":"190","employees":"11-50","jobDetails":[{"level":"Mid-Senior level","industry":["Computer Software","Information Technology & Services"],"jobtype":"Full-time","function":["Analyst","Information Technology"]}],"description":"Job description\n\n \n\nPOSITION: Senior Technical/Data Analyst-Category Management\n\n \n\nAbout Enterra Solutions®\n\nEnterra Solutions has combined artificial intelligence and advanced mathematics to pioneer the Enterra Enterprise Cognitive System™. By reasoning the way humans do and performing sophisticated mathematical analysis, Enterra automates a new way of problem-solving and decision-making; thus, going beyond advanced analytics to answer queries and generate insights instantly. Enterra helps transform market-leading companies into true digital enterprises.\n\n \n\nLOCATION:\n\nEnterra is located in Newtown, PA (Bucks County) --Approximately 30 miles north of Philadelphia/ 20 miles south of Princeton NJ.  Local candidates in a reasonable commutable distance to Newtown, PA are generally preferred; however, this is a client-facing position and requires up to 50% travel to client sites. Travel demands will vary depending on location of candidate in relation to client sites. Enterra will consider candidates willing/able to work from their home residing in the Northeast and Mid-Atlantic regions (preferably Pennsylvania, New Jersey or Northern Virginia/Washington, DC area).\n\n \n\nPOSITION DESCRIPTION:\n\nEnterra has distinguished itself as an early thought leader within the Cognitive Computing space and has built an impressive client list of top companies implementing innovative solutions. Our environment is both exciting and challenging as we continue to build our core platform, further productize our offerings and deliver quality solutions to our rapidly growing client base.\n\n\n\n\nWork with Enterra Business Analysts and client personnel to:\n\n-Understand and document the technical and data infrastructure that supports business functions and processes to be impacted by the engagement. \n\n \n\nWork with client personnel to:\n\n-Derive, specify and document the data requirements for the engagement from the process knowledge. In some cases, this involves identifying and understanding data that is not currently available to client users but could be used to improve the business functions and processes.\n\n-Establish the data acquisition/transfer/integration process for the engagement from primary and/or secondary data sources.\n\n-Understand and document the existing (and planned) system architectures and architecture requirements.  Specific focus is on installation and integration of Enterra offerings within the client architecture. Note that Enterra offerings are generally deployed within the cloud.\n\n\n\n\nObtain a full understanding of the data set(s) to:\n\n-Perform data quality assurance (DQA), validation and verification to ensure accuracy and completeness of data sets against the requirements.\n\n-Perform data munging/wrangling to connect and map data sets such that they can be used by the Enterra engines.\n\n-Resolve data quality problems. Activities include: Identify, assess, fix, document, and communicate potential quality issues. This may involve interacting with business users to resolve data quality problems using techniques such as root cause analysis. It may also include data cleansing and operations like removing duplicate records or determining appropriate proxies for any missing data.\n\n-Note: Candidate should be able to perform the above on sample/initial data submissions from the client in an offline environment AND specify the requirements for Engineering personnel to develop the appropriate production code for use within the systems.\n\n\n\n\nWork with Enterra Business Analysts and the Data Science team to:\n\n-Specify the key insights and recommendations to be generated as output from the system.\n\n-Review the analytics approach.\n\n-Perform initial statistical analysis, as needed.\n\n-Perform initial feature engineering to enrich the data, as needed. Detail the requirements for Engineering to develop the appropriate production code.\n\n-Create technical and business level presentations of analytical results/insights for review with clients.\n\n\n\n\nWork with Enterra Engineering team to:\n\n-Describe the client business operational processes and system requirements.\n\n-Detail the data management requirements to implement the on-going validation, verification, cleansing, harmonization and feature engineering.\n\n-Answer questions from the team – this may require obtaining more information from the client.\n\n-Provide quality assurance oversight of data flows and stores. Review quality of data, loads, transformations, extractions, merges, or other production jobs. This may also include the establishment and monitoring of service level agreements, communication protocols with data suppliers, and data quality assurance policies.\n\n-Debug SQL, stored procedures, NoSQL, Python, and related data issues.\n\n-Manage data quality documentation. Define and maintain data standards, definitions, and models (e.g. data dictionary, organizational data model. This may also include any DQA documents such as checklists, guidelines, manuals, templates, forms, etc.).\n\n-Identify, analyze, and interpret trends or patterns in complex data sets\n\n\n\n\nWork with all project participants to:\n\n-Test the solution and assist in debugging issues.\n\n \n\n \n\nREQUIREMENTS: Must have the following:\n\n-Hands on work experience as a technical/data analyst (5 years minimum).\n\n-Hands on work experience in an external client-facing role (3 years minimum).\n\n-Strong documentation skills especially in documenting requirements using different approaches such as use cases, activity diagrams, sequence diagrams and state charts, data dictionaries, class or entity relationship diagrams.\n\n-Strong communication skills. Ability to clearly articulate and communicate with business and technical personnel. This includes documentation, presentations and individual analysis sessions.\n\n-Experience with databases including SQL skills, stored procedure programming and Python for data manipulation.\n\n-High comfort level with relational databases, data mining and data warehousing.\n\n-Able to make (and defend) informed decisions on a wide range of complex technical issues.\n\n-Distinctive problem-solving and analytical skills, combined with strong business sense.\n\n-Minimum of BS Degree in Computer Science or related field.\n\n\n\n\nHIGHLY DESIRED SKILLS:\n\nExperience in Category Management functions such as Trade Promotion, Assortment and Pricing – along with related data sets and technologies (e.g., Nielsen, IRI, JDA etc.)     \n\n-Experience with automated data profiling tools.\n\n-Experience with BI, Data Mining, and Data Visualization tools.\n\n-Knowledge of statistics and experience using statistical packages for analyzing large datasets (Excel, R, Python, etc.).\n\n-Knowledge of data encryption techniques and algorithms such as PGP, Triple DES, RSA.\n\n-Working knowledge of the cloud environments (Azure, Google, AWS).\n\n\n\n\nBefore applying, please read below:\n\nCandidates must be willing to travel as required.\n\nCandidates must currently reside in the northeast or mid-atlantic region\n\nEnterra does NOT sponsor - Candidates must be eligible to work in the US without sponsorship\n\nNo Corp to Corp --this is a full time position\n\nIf interested, please submit your resume with your full name and contact info, including phone number and location (city/state is acceptable)."},{"jobtitle":"Data Analyst, Analytics and Research","companyname":"Conference of State Bank Supervisors (CSBS)","companyid":"99902","address":"","geo":"Washington D.C. Metro Area","postDate":"Oct 22 2018","views":"813","applicants":"185","employees":"51-200","jobDetails":[{"level":"Entry level","industry":["Banking","Financial Services"],"jobtype":"Full-time","function":["Other","Research"]}],"description":"Job description\n\nThe Policy & Supervision Data Analyst will provide support for the implementation of the data analytics strategy for CSBS' public policy and supervision departments. The analyst will be responsible for primary data analytics and for reporting tool development support utilizing in-house and external data sources as well as a variety of Business Intelligence tools. The analyst will perform various data and economic analysis functions in support of the policy and supervisory committees, work groups, and task forces. The individual will also assist in the deployment of data gathering tools and surveys, and assist in developing an analytics framework for making such data accessible to CSBS’s members and leadership in a useful way. The analyst will participate in working groups comprised of representatives from the State and federal banking agencies.\n\n \n\nEssential Functions\n\nTo perform this job successfully, an individual must be able to perform each essential duty and responsibility satisfactorily. Reasonable accommodations may be made to enable individual with disabilities to perform the essential functions. Other duties may be assigned to meet business needs.\n\n \n\nDevelops and maintains a range of reports, advanced analytics and dashboards in business intelligence platforms and/or data science tools to support the data analysis needs of state regulators and the CSBS public policy development process;\n\nHelps create and maintain survey tools required for policy, supervision and accreditation;\n\nCreates and maintains documentation related to technical processes using code repository and other documentation tools\n\nProvide economic and econometrics analysis to support the public policy development process;\n\nCreates analytics that summarize state responses on a national level with tables and charts;\n\nMaintains and contributes codes to survey/profile reporting tool that generates the HTML report.\n\nDevelops analytics to inform end users on risk assessment and hypothesis, develop user friendly reports including formatting to ensure a smooth presentation and a professional experience for the end users.  \n\nResponds to specific data inquires and requests from state banking departments, federal banking agencies, bankers, and other parties, and drafts and coordinates responses needed throughout the year.\n\nHandles requests from state banking departments for geographic data to be represented on a map.\n\nDevelops processes and solutions that focus on automation and efficiency\n\n \n\n Additional Responsibilities\n\n \n\nProvides economic analysis to support the public policy development process.\n\nParticipates and assists in special projects, e.g., CSBS Profile of State Charter Banks, CSBS hosted meetings, and various state banking department initiatives.\n\nCoordinates with state regulators, federal regulatory agencies, trade groups on multiple projects;\n\nServes as a facilitator and staff support for multiple committees and taskforces of the Policy and Supervision Department;\n\n \n\nMinimum Qualifications\n\nTo perform this job successfully, an individual should possess the knowledge, skills, and abilities listed and meet the amount of education, training and/or work experience required.\n\n \n\nEducation and Experience\n\nA Bachelor’s degree or higher in computer science, statistics, finance, operations research, economics, or another business, quantitative, or government related field.\n\nExperience using and developing reports in any Business Intelligence or Business Discovery tool, such as MicroStrategy, Qlikview, Tableau, Business Objects, Cognos or PowerBI is highly desirable;\n\nExperience with statistical, data mining and data science tools such as R, SAS, SPSS, Python, is highly desirable\n\nAdvanced Excel skills in a business finance or economics environment.\n\nExperience with a Bloomberg terminal is desirable but not required.\n\nExperience with open source tools for data analysis, data mining, data visualization and BI.\n\nSome experience with data warehousing including relational and dimensional data modeling, ETL, source to dimension mapping, is desired but not required.\n\nExperience with object oriented programming such as Java is desired.\n\nExperience with scripting languages such as JavaScript and Python\n\nExperience with ad-hoc choropleth maps with JavaScript graphing libraries.\n\nAn interest in banking and financial services.\n\nWork in a bank regulatory agency (national or state), trade association, or financial institution in interpreting, analyzing and assessing federal/state bank procedures, regulations, and statutes, a plus but not required.\n\n \n\n \n\nKnowledge, Skills, and Abilities\n\nKnowledge of MicroStrategy Analytics Engine, a business intelligence tool for banking data analysis and reporting for exploratory analysis.\n\nKnowledge of ESRI Maps plugin for MicroStrategy for location analysis of geo-enabled banking data with institution headquarter and branch information.\n\nAbility to program in Java/Python to customize user interface of data analysis tool; consolidate and manipulate data; support data validation and maintain data integrity.\n\nAbility to create new visualization tools for cartogram using Visualization SDK and customize web interface with MicroStrategy Web SDK.\n\nExposure to Plot.ly API for Python, creates Python web dashboards.\n\nAbility to leverage python scripting for data acquiring, validating and cleaning.\n\nAbility to conduct regression analysis, which includes time series analysis, generalized linear regression model and other statistical learning model to data.\n\nAbility to learn new technology, processes and applications quickly.\n\nData Science – Ability to synthesize the essential and relevant elements out of large sets of data, and display them in a user-friendly manner.\n\nOrganization and planning—able to balance organizational needs of multiple projects with different timeframes. Able to meet deadlines and timeframes. Able to keep processes moving at the appropriate pace. Ability to manage and prioritize multiple, complex projects accurately and timely.\n\nWritten communication – able to write clearly and effectively present ideas and to document activities; to communicate information in a succinct and organized manner; produce written information, which may include technical material, that is appropriate for the intended audience; to read and interpret written information; e.g., ability to both respond to inquiries from regulatory agencies and members of the business community on complex regulatory matters. Able to recount discussions of various meetings and events.\n\nResults orientation - ability to work at a fast pace and meet critical deadlines.\n\nPosition requires completion of a nondisclosure agreement and annual financial disclosure.\n\n \n\nWorking Conditions\n\n \n\nGeneral office. Travel required approximately 10% of the time.\n\n        \n\n\n To apply, please visit https://www.csbs.org/careers "},{"jobtitle":"Data Engineer","companyname":"GHG Systems","companyid":"","address":"","geo":"Los Angeles, CA, US","postDate":"Oct 22 2018","views":"","applicants":"0","employees":"","jobDetails":[{"level":"Entry level","industry":["Information Technology & Services","Computer Software","Information Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nSummary As a Lead Data Engineer, you have a solid understanding of both the business and the technical aspects of BI in relation to digital media business. You will drive the completion of projects within the established scope, while simultaneously planning for and managing unknown future BI requirements in a dynamic environment. Responsibilities Include Design, model and develop data sets to support reporting and analytics in a cloud environment. ETL development: perform all aspects of programming assignments and assist with systems design. Develop and maintain a technical metadata framework and repository of data events and ETL operations. Manage and administer Analytics tools and tag management systems. Help plan and maintain the technical infrastructure, its configuration, performance, and storage requirements, with consideration of tiered data and data archiving. Generate ad-hoc queries and reports based on business requirements. Provide ongoing evaluations of technology solutions and capabilities to ensure alignment with business objectives, identify areas of risk, while monitoring the current environment and potential improvement areas. Work with business stakeholders to gather, analyze, and translate requirements in BI reporting area - either recommending an existing solution, developing a solution, or synthesizing delivery requirements to engineering teams for development. Actively question and challenge customers to understand their requirements and reach the best solutions, near and long term. Understand and adhere to development and documentation standards, database design and storage. Successfully implement process improvements impacting own work and work of others. On-call application support is required. Qualities / Experience We're Seeking 5+ years of top-tier Data engineering experience; at least 2 years on cloud Infrastructure. Working knowledge of digital media ecosystem, including how digital video streaming, ad servers, DSPs, SSPs work. Experience working in a mix of Cloud and Enterprise data environments with real world implementation of data collection and processing on AWS environment. Knowledge of web technologies and online advertising systems. Experience with real-time Big Data analytics. Experience with Hadoop, MapReduce, Spark, Flink and/or other Big Data processing platforms. Excellent knowledge of OLAP concepts. Familiarity with columnar databases like Redshift, Vertica etc. Programming language such as Java, and scripting languages like python, ruby and Unix shell scripts. Experienced working in a fast-paced, high-tech environment (preferably software development) and comfortable navigating conflicting priorities and ambiguous problems. Experience with data visualization tools such as Looker, Tableau. Great communication and collaboration skills across technical and non-technical stakeholders. A Bachelor’s degree in Computer Science or equivalent preferred. - provided by Dice\n ETL, Big Data Analytics"},{"jobtitle":"Senior Technical/Data Analyst","companyname":"Enterra Solutions, LLC","companyid":"42280","address":"","geo":"Washington, D.C., District of Columbia, United States","postDate":"Oct 22 2018","views":"361","applicants":"150","employees":"11-50","jobDetails":[{"level":"Mid-Senior level","industry":["Computer Software","Information Technology & Services"],"jobtype":"Full-time","function":["Analyst","Information Technology"]}],"description":"Job description\n\n \n\nPOSITION: Senior Technical/Data Analyst-Category Management\n\n \n\nAbout Enterra Solutions®\n\nEnterra Solutions has combined artificial intelligence and advanced mathematics to pioneer the Enterra Enterprise Cognitive System™. By reasoning the way humans do and performing sophisticated mathematical analysis, Enterra automates a new way of problem-solving and decision-making; thus, going beyond advanced analytics to answer queries and generate insights instantly. Enterra helps transform market-leading companies into true digital enterprises.\n\n \n\nLOCATION:\n\nEnterra is located in Newtown, PA (Bucks County) --Approximately 30 miles north of Philadelphia/ 20 miles south of Princeton NJ.  Local candidates in a reasonable commutable distance to Newtown, PA are generally preferred; however, this is a client-facing position and requires up to 50% travel to client sites. Travel demands will vary depending on location of candidate in relation to client sites. Enterra will consider candidates willing/able to work from their home residing in the Northeast and Mid-Atlantic regions (preferably Pennsylvania, New Jersey or Northern Virginia/Washington, DC area).\n\n \n\nPOSITION DESCRIPTION:\n\nEnterra has distinguished itself as an early thought leader within the Cognitive Computing space and has built an impressive client list of top companies implementing innovative solutions. Our environment is both exciting and challenging as we continue to build our core platform, further productize our offerings and deliver quality solutions to our rapidly growing client base.\n\n\n\n\nWork with Enterra Business Analysts and client personnel to:\n\n-Understand and document the technical and data infrastructure that supports business functions and processes to be impacted by the engagement. \n\n \n\nWork with client personnel to:\n\n-Derive, specify and document the data requirements for the engagement from the process knowledge. In some cases, this involves identifying and understanding data that is not currently available to client users but could be used to improve the business functions and processes.\n\n-Establish the data acquisition/transfer/integration process for the engagement from primary and/or secondary data sources.\n\n-Understand and document the existing (and planned) system architectures and architecture requirements.  Specific focus is on installation and integration of Enterra offerings within the client architecture. Note that Enterra offerings are generally deployed within the cloud.\n\n\n\n\nObtain a full understanding of the data set(s) to:\n\n-Perform data quality assurance (DQA), validation and verification to ensure accuracy and completeness of data sets against the requirements.\n\n-Perform data munging/wrangling to connect and map data sets such that they can be used by the Enterra engines.\n\n-Resolve data quality problems. Activities include: Identify, assess, fix, document, and communicate potential quality issues. This may involve interacting with business users to resolve data quality problems using techniques such as root cause analysis. It may also include data cleansing and operations like removing duplicate records or determining appropriate proxies for any missing data.\n\n-Note: Candidate should be able to perform the above on sample/initial data submissions from the client in an offline environment AND specify the requirements for Engineering personnel to develop the appropriate production code for use within the systems.\n\n\n\n\nWork with Enterra Business Analysts and the Data Science team to:\n\n-Specify the key insights and recommendations to be generated as output from the system.\n\n-Review the analytics approach.\n\n-Perform initial statistical analysis, as needed.\n\n-Perform initial feature engineering to enrich the data, as needed. Detail the requirements for Engineering to develop the appropriate production code.\n\n-Create technical and business level presentations of analytical results/insights for review with clients.\n\n\n\n\nWork with Enterra Engineering team to:\n\n-Describe the client business operational processes and system requirements.\n\n-Detail the data management requirements to implement the on-going validation, verification, cleansing, harmonization and feature engineering.\n\n-Answer questions from the team – this may require obtaining more information from the client.\n\n-Provide quality assurance oversight of data flows and stores. Review quality of data, loads, transformations, extractions, merges, or other production jobs. This may also include the establishment and monitoring of service level agreements, communication protocols with data suppliers, and data quality assurance policies.\n\n-Debug SQL, stored procedures, NoSQL, Python, and related data issues.\n\n-Manage data quality documentation. Define and maintain data standards, definitions, and models (e.g. data dictionary, organizational data model. This may also include any DQA documents such as checklists, guidelines, manuals, templates, forms, etc.).\n\n-Identify, analyze, and interpret trends or patterns in complex data sets\n\n\n\n\nWork with all project participants to:\n\n-Test the solution and assist in debugging issues.\n\n \n\n \n\nREQUIREMENTS: Must have the following:\n\n-Hands on work experience as a technical/data analyst (5 years minimum).\n\n-Hands on work experience in an external client-facing role (3 years minimum).\n\n-Strong documentation skills especially in documenting requirements using different approaches such as use cases, activity diagrams, sequence diagrams and state charts, data dictionaries, class or entity relationship diagrams.\n\n-Strong communication skills. Ability to clearly articulate and communicate with business and technical personnel. This includes documentation, presentations and individual analysis sessions.\n\n-Experience with databases including SQL skills, stored procedure programming and Python for data manipulation.\n\n-High comfort level with relational databases, data mining and data warehousing.\n\n-Able to make (and defend) informed decisions on a wide range of complex technical issues.\n\n-Distinctive problem-solving and analytical skills, combined with strong business sense.\n\n-Minimum of BS Degree in Computer Science or related field.\n\n\n\n\nHIGHLY DESIRED SKILLS:\n\nExperience in Category Management functions such as Trade Promotion, Assortment and Pricing – along with related data sets and technologies (e.g., Nielsen, IRI, JDA etc.)     \n\n-Experience with automated data profiling tools.\n\n-Experience with BI, Data Mining, and Data Visualization tools.\n\n-Knowledge of statistics and experience using statistical packages for analyzing large datasets (Excel, R, Python, etc.).\n\n-Knowledge of data encryption techniques and algorithms such as PGP, Triple DES, RSA.\n\n-Working knowledge of the cloud environments (Azure, Google, AWS).\n\n\n\n\nBefore applying, please read below:\n\nCandidates must be willing to travel as required.\n\nCandidates must currently reside in the northeast or mid-atlantic region\n\nEnterra does NOT sponsor - Candidates must be eligible to work in the US without sponsorship\n\nNo Corp to Corp --this is a full time position\n\nIf interested, please submit your resume with your full name and contact info, including phone number and location (city/state is acceptable)."},{"jobtitle":"Data Engineer","companyname":"MSX International","companyid":"165062","address":"","geo":"Southfield, Michigan","postDate":"Oct 22 2018","views":"266","applicants":"70","employees":"5001-10000","jobDetails":[{"level":"Mid-Senior level","industry":["Automotive","Information Technology & Services"],"jobtype":"Full-time","function":["Information Technology","Customer Service"]}],"description":"Job description\n\nMSX International is currently seeking a Data Engineer. The successful candidate must have the following skills and experience:\n\n\n\n\n****Short term 6 month position****\n  \n SUMMARY\n\n As a Data Engineer you will support GRI's Global Data & Analytics team and will be responsible for creation and maintenance of databases, tables, data flows, and reporting dashboards covering every aspect of the company's activities. You will understand the nuances of the data and ensure that each field in each table is properly named, populated, documented, and used. You will maintain high data quality and integrity by identifying and eliminating ambiguity, duplication, data errors, and inefficient data flows. The data that you maintain is a key strategic and competitive advantage for GRI, and will form the backbone of analysis that drives the company's business decisions.\n\n ESSENTIAL DUTIES AND RESPONSIBILITIES\n\n Design, develop, document, and test advanced data systems that bring together data from disparate sources, making it available to data scientists, analysts, and other users using scripting and/or programming languages (Python, Java, C, etc.)\n Evaluate structured and unstructured datasets utilizing statistics, data mining, and predictive analytics to gain additional business insights\n Design, develop, and implement data processing pipelines at scale\n Present programming documentation and design to team members and convey complex information in a clear and concise manner\n Extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes\n Write and refine code to ensure performance and reliability of data extraction and processing.\n Communicate with all levels of stakeholders as appropriate, including executives, data modelers, application developers, business users, and customers\n Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests\n Partner with clients to fully understand business philosophy and IT Strategy; recommend process improvements to increase efficiency and reliability in ETL development\n Collaborate with Quality Assurance resources to debug code and ensure the timely delivery of products.\n Some of our technologies might include: HDFS, Cassandra, Spark, Java, Scala, Informatica, SQL Server, Oracle, Ab Initio, Kafka\n\n KNOWLEDGE, SKILLS, AND ABILITIES\n\n A successful candidate will have hands-on experience in a multitude of domains; including, but not limited to database design, data warehousing, business intelligence, big data, database tuning, application optimization, security, virtual computing and storage, incident tracking, and general database administration\n Three or more years' experience including enterprise data warehouses, business intelligence, and MDM\n Knowledge and familiarity with concepts in predictive analytics\n Experience building and optimizing 'big data' data pipelines, architectures and data sets.\n Expert level knowledge of Microsoft SQL Server\n Expert level knowledge of SQL administration, engineering, and monitoring tools\n Expert level knowledge of designing, constructing, administering, and maintaining data warehouses\n Solid experience working with SSIS and SSRS or similar tools\n Solid experience with change control and agile methodologies\n Experience with Performance Tuning\n Passion for using data to effectively support business needs.\n Excellent written and verbal communication skills\n Ability to juggle and prioritize multiple projects simultaneously\n Must be a motivated self-starter who can work independently, but also seeks out opportunities to work collaboratively with others\n Must have experience working directly with senior business leaders to understand objectives and articulate the value of business intelligence solutions\n Must be comfortable dealing with changing priorities and timelines\n Experience with the following tools and technologies preferred:\n Cloudera Hadoop, Spark, Kafka, NiFi, Elastic Search, Hive, Solr\n Relational SQL and NoSQL databases\n Data visualization tools such as Tableau, Power BI or similar self-service BI products\n AWS cloud services such as EC2, EMR, RDS and Redshift\n Stream-processing systems such as Storm and Spark-Streaming\n Programming languages and related web technologies such as Python, Java, JavaScript, C++, JSON, R, etc.\n\n SUPERVISION\n No management responsibilities\n\n EDUCATION and TRAINING\n\n Bachelor's degree in Business Management, Computer Information Systems/Data Management, or other related fields is strongly preferred\n\n WORKING ENVIRONMENT\n 40 hours / week\n Limited travel is required\n\n Nothing in this job description restricts management's right to assign or reassign duties and responsibilities to this job at any time, and this job description is subject to change at any time"},{"jobtitle":"Data Engineer","companyname":"Another Source","companyid":"45975","address":"","geo":"San Francisco Bay Area","postDate":"Oct 22 2018","views":"102","applicants":"19","employees":"11-50","jobDetails":[{"level":"Mid-Senior level","industry":["Higher Education","Information Technology & Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\n\nAnother Source’s client, Stanford University, is recruiting a Data Engineer to join their team.\n\n\n\nHere’s a little about Stanford University and the position they are recruiting for:\n\n\n\nImprovement, Analytics, and Innovation Services\n\n\n\nWe are a newly formed department within Stanford tasked with providing management consulting services to a highly complex university administration with hundreds of business processes and dozens of major systems. Our team of internal consultants strives to create, instill, and sustain a business improvement discipline that delivers transformed and efficient processes through a data science approach with both structured and unstructured data.\n\n \n\nThe Business Analytics team is instrumental in executing our vision by providing essential data services both internally within our department as well as to our various clients. This team is composed of data professionals that cover a broad spectrum of skills such as data visualization, data engineering, statistics, machine learning, optimization, and general problems solving. We are in search of a seasoned data engineer, who will utilize a wide variety of data extraction and preparation techniques in order to build and maintain data sets to be analyzed or reported on for business decision-making. In addition to your extensive technical background, we also value your creativity and innovation in finding the right tools and techniques to solve a diverse problem set that will challenge you to employ a vast range of data skills.\n\n \n\nAdditional perks of working in our team:\n\nExciting and diverse set of projects in a broad data science spectrum with varied data sets that are not limited by and specific to any industry\n\nMany opportunities to make a huge impact with this small newly formed team to support all other groups campus-wide at Stanford\n\nAttend a work-related conference of your choice every year\n\nFlexibility to take one of Stanford’s many exercise classes during lunch or play in a variety of group-organized sports such as basketball\n\nGood work from home policy\n\n \n\nYour responsibilities include:\n\nExtract, transform, and load data to and from various data sources including relational databases, NoSQL databases, web services, and flat files\n\nDesign and implement scalable and high performance data and project repositories\n\nDevelop, optimize, and maintain code used in ETL and data analysis\n\nImplement NLP techniques to parse, clean, and normalize text data for the purpose of topic modeling, document clustering, and classification.\n\nSetup and maintain scheduled data loads to ensure up-to-date information and data consistency\n\nProfile and validate sources of data where very little metadata is provided\n\nProduce various technical documents such as entity relationship diagrams, table schemas, data lineage, API docs, etc.\n\nImplement guidelines or standard methodologies on source code tracking preferably with git\n\nDevelop reports or data visualizations in an iterative process\n\nPerform business analysis and capture requirements from clients regarding their various data needs\n\n \n\nKnowledge, skills, and abilities you bring:\n\nSolid grasp of complex data concepts as well as the ability to effectively communicate those concepts to team members, senior leaders, and clients\nStrong programming skills including the ability to build highly flexible and performance-tuned user-defined functions and classes with both object oriented and functional programming approaches. For example, build a call center simulation from scratch or implement a custom machine model evaluation script with multiple metrics.\nIn-depth understanding of Python including data packages such as pandas, scikit-learn, numpy, etc.\nDeep understanding of querying languages for both SQL and NoSQL databases\nExpertise in maintaining and administering NoSQL databases such as MongoDB and neo4j, as well as relational databases like Oracle, MySQL, PostgreSQL, and Microsoft SQL\nExpertise in administering Linux (Oracle, Red Hat, etc.) and Windows servers\nExperience extracting data from web services working with JSON and XML output and from web scraping parsing through HTML\nExperience using open source technologies to set up an ETL architecture capable of job scheduling, logging, and generating error notifications\nExperience using git to track source code\nExperience working closely with data scientists and report developers\nExperience eliciting, interpreting, and documenting user requirements in the context of data analysis\nAbility to lead multiple activities in a diverse environment\nHighly organized, flexible, and demonstrates rigorous attention to detail\nExperience with data visualization tools such as Tableau, D3\nBachelor’s degree and seven years of relevant experience in computer science, or engineering, or a combination of education and relevant experience.\n\n\n\n\n\nWorking at Stanford:\n\nImagine a world without search engines or social platforms. Consider lives saved through first-ever organ transplants and research to cure illnesses. Stanford University has revolutionized the way we live and enrich the world. Supporting this mission is our diverse and dedicated 17,000 staff. We seek talent driven to impact the future of our legacy. Our culture and unique perks empower you with:\n\n \n\nFreedom to grow. We offer career development programs, tuition reimbursement, audit a course. Join a TedTalk, film screening, or listen to a renowned author or global leader speak.\n\nA caring culture. We provide superb retirement plans, generous time-off, and family care resources.\nA healthier you. Climb our rock wall or choose from hundreds of health or fitness classes at our world-class exercise facilities. We also provide excellent health care benefits.\nDiscovery and fun. Stroll through historic sculptures, trails, and museums.\nEnviable resources. Enjoy free commuter programs, ridesharing incentives, discounts, and more!\n\n\n\n\n\nThis position will be located at Stanford’s Redwood City campus, scheduled to open in 2019, which brings together 2,700 staff in a collaborative environment that reflects Stanford’s culture and mission. In addition to all amenities offered by the Palo Alto campus, this site will offer amenities such as onsite cafes and a dining pavilion, a high-end fitness facility with an outdoor pool, and a childcare center for Stanford families.\n\n \n\nStanford is an equal opportunity employer and all qualified applicants will receive consideration without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, or any other characteristic protected by law.\n\nConsistent with its obligations under the law, the University will provide reasonable accommodation to any employee with a disability who requires accommodation to perform the essential functions of the job.\n\n \n\nAnother Source works with their clients, on a retained project basis, to maximize the recruiting process. \n\n "},{"jobtitle":"Senior Data Engineer","companyname":"ForgeRock","companyid":"784549","address":"","geo":"Remote, OR, US","postDate":"Oct 22 2018","views":"123","applicants":"21","employees":"201-500","jobDetails":[{"level":"","industry":["Information Technology & Services","Computer Software","Internet"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nSenior Data Engineer\n Cloud Solutions | San Francisco, CA or Remote\n\nAbout The Company\n\nForgeRock® rocks when others are rolling. We aren’t your typical high-tech company and aren’t looking for typical people. We look for real people. Whoever you are. Whatever you are. While you play well with others you aren’t afraid to be you and let others be themselves. Someone has called you wicked smart before, but you would never refer to yourself that way.\n\n ForgeRock pioneered open source identity and access management, went on to invent identity relationship management for customer identities, and is now busy playing with the identity of things. Yes, we’re growing fast, but we remain true to our start up culture. We’re decidedly creative, we’re always learning, no one hesitates to ask questions, and we’re on a never-ending search for new ideas.\n\n Our customers are some of the biggest companies, organizations, and even countries in the world. On any given day, it’s likely that the ForgeRock Identity Platform helped keep your data safe, gave you access to stuff, and supported trusted relationships between you, companies and the devices you were using. Please read more about us at forgerock.com or follow ForgeRock on Twitter at http://www.twitter.com/forgerock.\n\nWhat We Want\n\nA passionate, driven engineer who is comfortable working with the principles of agile software development and getting products into customers hands, collecting feedback, and iterating to deliver an outstanding solution. You are highly adaptable and work efficiently in self-driven environments.\n\n This role will be heavily involved in expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. The individual will be very experienced with data pipelines and will have been involved in building production-grade systems from the ground up. They will be extremely well versed in engineering and maintaining data infrastructure that focuses on solving difficult data science problems. The role will support software developers and data scientists on critical product initiatives that will deploy intelligence into the core product line.\n\nWhat This Role Looks Like To Us\n\nAttend the daily team stand up, collaborate with fellow engineers solving challenging problems, and perform code reviews. Depending on the tasks, you might need to engage with the product, one of the other engineering teams or executive management to provide guidance and help steer them. You will have the flexibility to work on tasks that you or the team has assigned to you or to pair up to collaborate on a complex issue. Other times, you and some of the team will need to spike to look into the incorporation of some innovative functionality, either as a public or internal feature.\n\nResponsibilities\n\nBuilding and scaling features to be used by machine learning algorithms, work closely with supervised and unsupervised learning tools\nEnhancing data collection to improve existing pipeline\nBuild and manage entire data pipelines for data processing and machine learning applications\nWork closely with stakeholders throughout the entire organization to identify opportunities for leveraging company data to drive business solutions\nDevelop processes and tools to monitor and analyze model performance and data accuracy\nDevelop A/B testing framework and test model quality\nMine and analyze data using state-of-the-art methods, use this data to drive optimization and improvement of product development\n\n\n\nRequired Skills & Qualifications\n\nExperience working with cloud infrastructures (AWS, Google Cloud, Azure) for data processing, storage, and analysis in highly scalable production systems\nExperience with Hadoop, Spark, Kafka, Dataflow or comparable tools\nExperience with building and deploying entire features to production end-to-end, using tools like Airflow, Docker, Kubernetes, github, SQL\nExperience with CI/CD pipelines, working with tools like Codefresh, Jenkins, Travis, GitLab, Codeship, etc.\nExperience building features from raw data, and pushing those features into data science models\nExperience working in statistical computer languages (Python, R, SQL) to manipulate data and draw insights from large data sets\nExperience working with and creating data architectures\nExperience building analytics tools and API's that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.\n\n\n\nPreferred Skills & Qualifications\n\nExperience working with deep learning models and frameworks like Tensorflow, Theano, Keras, Torch\nExperience working with machine learning models in production\nExperience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modelling, clustering, decision trees, neural networks, etc\nKnowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.\nKnowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\n\n\n\nLife At ForgeRock\n\nWe believe in and facilitate a flexible, collaborative work environment. We’ve grown enormously, but remain true to the innovative, can-do startup values that got us here. Most important of all, we keep hiring talented, smart, fun, and genuinely nice people because that’s who we want to succeed with every day. Below are just a few of the great things we have to offer at ForgeRock:\n\nA great team of smart, fun and genuinely nice individuals.\nAwesome company culture focused around providing a flexible and collaborative work environment\nRegular office bonding events, from lunches and happy hours to group offsites and hack-days\nWell-stocked fridges, whether you’re hungry or thirsty\nCompetitive benefits and perks\nWe’re Mac-friendly!\nGenerous employee referral bonus program\nAmazing offices across the globe – San Francisco HQ; Vancouver, WA; Austin, TX; Munich, Germany; London & Bristol, UK; Grenoble & Paris, FR; Oslo, NO; Singapore, Australia & counting!\n\n\nForgeRock is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex including sexual orientation and gender identity, national origin, disability, protected Veteran Status, or any other characteristic protected by applicable federal, state, or local law."},{"jobtitle":"IT Intern (Summer 2019)","companyname":"Continental Resources","companyid":"","address":"","geo":"Oklahoma City, OK, US","postDate":"Oct 22 2018","views":"15","applicants":"5","employees":"","jobDetails":[{"level":"Internship","industry":["Information Technology & Services","Oil & Energy","Financial Services"],"jobtype":"Internship","function":["Education","Training"]}],"description":"Job description\nJob Summary\n\nThe Information Technology Intern will work with the Information Management team as a Jr. Data Engineer and will have exposure to Continental's next generation Advanced Analytics solution. As an Information Technology Intern, this position will be expected to work with internal customers to (1) gather business and data requirements for a pre-determine advanced analytics use case, (2) design and model the analytical solution that meets the pre-defined needs of the customer, and (3) deliver a working prototype of their proposed design.\n\nBusiness/Technology Exposure\n\nThe Information Technology Intern will have exposure to the following IT technologies processes:\n\n Technologies\n\nInfrastructure: Amazon Web Services\nAdministration: Hadoop (Cloudera)\nIntegration: Sqoop, Oozi, Mulesoft, Kafka\nData Storage: HDFS/S3, Hive, Kudu, Impala, NoSQL\nReporting: Spotfire, Excel\nDevelopment: R, Python\nBusiness Tools: Microsoft Office, Excel, PowerPoint, Project, and Visio\n\nProcesses\n\nSoftware Development Lifecycle\nProject Management\nBusiness Requirements\nData Integration (streaming and batch)\nData Quality Management\nData Mining\nData Governance and Control\nChange Management\n\nDuties/Responsibilities\n\n The Information Technology Intern will have the following duties and responsibilities:\n\nMeeting with internal CLR customers to document specific business and technical requirements.\nDesign and model a solution that meets the needs of the documented requirements.\nDevelop a task plan that shows both individual and external tasks to develop a solution to meet the needs of the customer.\nCreate a prototype of the proposed solution.\nPresent solution to both the internal business customer and IT Leadership.\n\nSkills/Qualifications\n\nThe successful candidate should obtain most, if not all, of the following skills or qualifications:\n\nComputer Science, Management Information Systems, or Mathematics Degree Family\nCurrent enrollment in 4-year college or university\nMinimum 3.0 GPA for consideration (transcripts required)\nStrong interest in building upon current skillsets that center around all things data (Data Administration, Data Governance, Data Migration, Data Integration, Data Quality Management, Data Mining, Data Engineering, and Data Science)\nHas a desire to learn, build upon, development skills (such as R and Python)\nStrong communication skills (both written and oral)\nAnalytical thinking/problem solving\nStrong customer focus and a team player\nPossess good time management skills\nProfessional appearance and demeanor\nEligible to work permanently in the United States upon graduation\nAn acceptable pre-employment background and drug test\n"},{"jobtitle":"Data Analyst","companyname":"UFG Insurance","companyid":"","address":"","geo":"Cedar Rapids, IA, US","postDate":"Oct 22 2018","views":"8","applicants":"2","employees":"","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Insurance","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nOverview\n\nUFG offers you an award-winning workplace and a trustworthy, financially stable company. While we've always known our commitment to employees and financial stewardship, it is good to have others recognize our dedicated efforts. We've been named an Iowa Top Workplace by the Des Moines Register for four consecutive years, and included on Forbes' \"America's Most Trustworthy Financial Companies\" every year since 2014. Additionally, UFG is a super-regional property and casualty insurer rated \"A\" (Excellent) by A.M. Best Company.\n\n The UFG Enterprise Analytics Department is focused on delivering strategically-impactful results by building analytically based solutions that integrate a wide range of internal and external data assets. The ultimate objective of the Enterprise Analytics organization is to help UFG gain and maintain a competitive advantage in how it prices risk and identifies potential loss.\n\n We are seeking a Data Analyst to facilitate the development of Analytics solutions in support of UFG's strategic plan. This individual will work closely with business units throughout the organization to develop and implement strategies that leverage data to enable enhanced decision making. The ideal candidate will possess strong technical and communication skills, as well as proven experience in analytics, and information management, and the insurance industry in general.\n\nResponsibilities\n\nInterpret data, analyze results using statistical techniques and provide ongoing reports\nIdentify, analyze, and interpret trends or patterns in complex data sets\nPrototyping the development of databases, data collection systems, data analytics, and other strategies that optimize statistical efficiency and quality\nWork with management to prioritize business and information needs\nDesign and build comprehensive reports/dashboards and other tools to assist business managers in making business decisions\nSupport the enterprise data warehouse in identifying and revising reporting requirements\nTrain end users on new reports and dashboards\nResearch opportunities for data acquisition and new uses for existing data\nRecommend ways to improve data reliability, efficiency and quality\nCollaborate with data architects, modelers and IT team members on project goals\n\nQualifications\n\nBS in Mathematics, Economics, Finance, Computer Science, Information Management or Statistics\nMaster's Degree in a quantitative field preferred\nProven working experience as a data analyst\nTechnical expertise regarding data models, data mining and segmentation techniques\nStrong knowledge of and experience with reporting packages (Tableau, etc.) and databases (SQL, etc.)\nKnowledge of statistics and experience using statistical packages for analyzing datasets (SAS, R, Python, etc.)\nStrong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy\nAdept at queries, report writing and presenting findings\nAbility to translate business requirements into non-technical, lay terms\nAbility to create content rich and concise data visualization outputs for easy consumption by business users\nExperience in methodologies and processes for managing large scale databases\nDemonstrated experience in handling large datasets, structured and semi-structured data formats\nUnderstanding of star/snowflake schemas as general data warehousing methodologies (i.e. Kimball)\nStrong analytical thinking and verbal communication skills\nAbility to deliver incremental value via an Agile Development Methodology\nP&C Insurance and Consulting experience preferred\n"},{"jobtitle":"Principal Data Engineer, BI","companyname":"Rally Health","companyid":"5313796","address":"","geo":"Chicago, IL, US","postDate":"Oct 22 2018","views":"4","applicants":"0","employees":"501-1000","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Computer Software","Internet"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nRally Health is all about putting health in the hands of the individual. It's our mission, and it drives everything we do, which is to empower people with easy-to-use online and mobile tools that help them take charge of their health and health care, from improving their diet and fitness to selecting health benefits, and choosing the right doctor at the right price for their needs.\n\n Our culture is built on a deep and sincere commitment to helping people live healthier lives. To do this, we are committed to innovating at every level. As our president and COO David Ko says, \"We are a company that continuously innovates. It cannot end. It has to be in everything we do, which means that some of the things we're going to do are not going to work - and that's okay. We're not trying to build something that is churn and burn. We're building something that follows consumers over their lifetime.\"\n\n Do you love data and supporting an organization that is dedicated to making it easier and more rewarding for people to handle their health and wellness? Rally's mission is to help people to become healthier every day by putting health and wellness tools and crucial information in their own hands. We are looking for expert Business Intelligence professionals to join our data team, which also includes engineers and scientists, to drive our analytics, reporting, and business intelligence.\n\nResponsibilities\n\nAnalyze data from consumers interactions with their healthcare insurers and providers, monitor trends and develop strategies and opportunities to improve their health and lower their costs.\nPartner with employers and healthcare insurers, prova phenomenal great UI for covered members and their families to manage both their health and healthcare options\nDevelop actionable insights for population health management and positive recommendations for ways individuals can improve their health and manage their costs\nResponsible for the design, development, implementation and support of critical enterprise E2E Business Intelligence ETL solutions in Hadoop, sourcing data from HDFS, Amazon Redshift, MongoDB or Postgres environments and utilizing Python, Spark and Hive.\nHandle the product's or project's conception, design initial product specifications and lead scheduling, estimating and securing of resources\nProvide technical guidance to other internal and external teams\nHelp to train new employees and stay ahead of industry trends and issues\nMaintaining business partner engagement and setting expectations\nAssessing current processes and recommending changes as needed\nDocumenting and communicating technical specifications to ensure that proper and optimized techniques, queries, data standards, and final outputs are understood and incorporated into data and analytics processes\nParticipate in business analysis activities to gather required reporting and dashboard requirements\nTranslate business requirements into specifications that will be used to implement the required user-friendly environments, reports and dashboards, built from potentially multiple data sources\n\nQualifications\n\nAdvanced working knowledge and ability to write complex SQL and HQL queries in an HDFS environment\nExtensive hands-on experience working with Python and PySpark for the purposes of data transformations and ETL\nStrong familiarity with Kimball, OLAP, and EDW data design methodologies\n8+ years experience in ETL, Data Engineering, or BI fields with concentration on data transformations\nUnderstanding of various data extraction and transformation techniques with data sourced in HDFS, MongoDB, and Postgres\nWorking familiarity with Pentaho, Airflow, or Oozie\nKnowledge of Scala is a bonus\nFamiliar with Data Visualization standard methodologies\nAbility to succeed in a dynamic, Agile environment\nStrong prioritization and time-management skills\nDedication to team goals that include support of live 24/7 production systems\nA consummate collaborator, able to establish good relationships with technical, product, and business owners\nA champion of quality, able to QA and vouch for the integrity of the report output\n\nWhy join Rally? On top of an innovative work atmosphere and a chance to help people change their lives, we offer competitive pay, daily catered lunches, and an extensive benefits package for all full-time employees (including medical, dental, vision and 401(k)). In addition, offer the ability to grow, while truly making an impact in the healthcare system.\n\n Rally Health is committed to ensuring that its workforce reflects America's diverse population. Rally Health knows that such diversity will enrich us with the talent, energy, perspective and inspiration it needs to achieve its mission. Rally Health believes in a policy of equal employment and opportunity for all people based on merit and commitment to the principles of diversity. It is our policy to recruit, hire, train, and promote individuals in all job titles, and administer all programs, without regard to race, color, religion, national origin or ancestry, citizenship, sex, age, marital status, pregnancy, childbirth or related medical conditions, personal appearance, sexual orientation, gender identity or expression, family responsibilities, genetic information, disability, matriculation, political affiliation, veteran status, union affiliation, or any other category protected by applicable federal, state or local laws.\n\n Individuals with disabilities and veterans are encouraged to apply. Applicants who require an accommodation related to the application and/or review process should notify Talent Acquisition (recruiting@rallyhealth.com).\n\n Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records."},{"jobtitle":"Data Engineer- Mount Sinai Health Partners","companyname":"Mount Sinai Medical Center","companyid":"","address":"","geo":"New York City, NY, US","postDate":"Oct 22 2018","views":"19","applicants":"1","employees":"","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Financial Services","Hospital & Health Care"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nMount Sinai is one of the largest non-profit health systems in the U.S. with a strong reputation for quality of care (18th ranked academic medical center) and research/education (22nd ranked medical school). Our health system has ~40,000 employees working together to provide billions of dollars in high-quality care for millions of patients each year.\n\n We are accelerating a transition to a business model focused on population health management - our goal is to keep entire communities healthy and out of the hospital. Mount Sinai Health Partners (MSHP) is the team driving this transformation within Mount Sinai. The team includes 400 employees with clinical, contracting, finance, IT, analytics, operations, and product development expertise.\n\n MSHP is a fast growing business unit within Mount Sinai and is looking for team members who:\n\nAre comfortable \"playing up\" and \"playing down\" as needed to accomplish business objectives\nWork productively amidst ambiguity\nThrive in fast-paced work environments\nSeek to improve the status quo\n\nMount Sinai Health Partners is realizing this new objective in two ways. First, we engage in value-based contracts with health plans. Using analytical insights, we deploy our clinical programs to improve the health of attributed populations and maximize customer value. Second, we have created a team to assemble our clinical and population health assets into product offerings (e.g., care bundles, worksite health centers, insurance products in partnership with health plans), and sell them to individuals and employers via multiple channels. Each of these new product offerings will have important population health features including: (1) value-based pricing (2) a curated network of high-value physicians (3) optimized care pathways and related programs, and (4) an enhanced patient experience. The goal of each product is to increase the value for employers and their employees, mitigating the effects of the affordability crisis.\n\n Role Summary\n\n MSHP seeks a Data Engineer.\n\n Mount Sinai Health Partners, the population health division of the Mount Sinai Health System and the Icahn School of Medicine at Mount Sinai, located in the New York Metropolitan area and ranked 5th in FastCompany's \"Top 10 Most Innovative Companies in Big Data\" is searching for a highly qualified Data Engineer. In this role, you will design, develop and provision highly curated marts of data in an Oracle data warehouse and Big Data platform. These data marts fuel analysis and create insights and BI (Business Intelligence) solutions that contribute to sound strategic planning, decision-making, goal setting, and effective performance measurement.\n\n This role would report directly to the Lead Data Engineer.\n\n In this role, you will be responsible for data management and engineering in support of the Actuarial Informatics team of data scientists who deliver reporting, statistical modeling and advanced analytics for each of the diverse MSHP business areas. The role will also be supporting, enhancing an enriching the existing claims data warehouse for supporting the data scientist team with various projects and stakeholders.\n\nResponsibilities\n\nEffectively collaborate and communicate with your stakeholders and customers to understand their needs and ensure all data management requests are properly triaged, recorded and tracked.\nWork with enrollment, eligibility, medical claims, pharmacy claims, utilization, clinical, medical management, financial, administrative and other corporate or third party data from raw, modeled and disparate internal and external sources.\nWork with departmental staff to identify business requirements for data intake, reporting and / or business intelligence tools.\nEnsure all data intake leverages approved enterprise methods for data exchange and transfer, including setup and utilization of secure FTP.\nIdentify necessary data, data sources and methodologies to meet the business need.\nWork with IT or independently to collect, organize, integrate, profile and curate data, in both our Oracle RDMS or new Big Data platform Microsoft Azure Hadoop.\nIdentify and address expected and unforeseen data complexities to mitigate their impact on the analytic outcome and associated business decisions. Clearly communicate data issues to the recipients and work to improve data quality where possible within the data marts you create.\nFeed data quality issues back to IT or identified data stewards (inside and outside the team) to assist in our quest for the highest quality data.\nAssist in building reports or dashboards that profile or express the quality of data to your stakeholders.\nDesign and build complex Extract, Transform & Load (ETL) routines to ensure that data intake is consistently processed and integrated in accordance with approved business logic.\nDesign and build data marts to specification to enhance efficiency of standard reporting and analyses being built by data science analysts.\nExecute production programs on daily, weekly, monthly and quarterly schedule for standardized reporting and other data processes that have been built by data science analysts.\nAdhere to corporate standards for performance metrics, data collection, data integrity, query design, and reporting format to ensure high quality, meaningful analytic output.\nHelp identify and understand data from internal and external sources for competitive, scenario and performance analyses, and financial modeling to gain member/provider insight into new and existing processes and business opportunities.\nWork closely with IT on the ongoing improvement of Mount Sinai's integrated data warehouse, driven by strategic and business needs, and designed to ensure data and reporting consistency throughout the organization.\nDevelop and maintain project work plans, including critical tasks, milestones, timelines, interdependencies and contingencies. Track and report progress. Keep stakeholders apprised of project status and implications for completion.\nProvide technical support to data analytics functions as they relate to varied business units, and technical expertise on the selection, development and implementation of various reporting and BI tools tied to business unit reporting requirements.\nPrepare clear, well-organized project-specific documentation, including, at a minimum, data dictionaries, analytic methods used, key decision points and caveats, with sufficient detail to support comprehension and replication.\nAbility to coordinate with offshore development resources on various requests and projects.\nAssist and teach others within the organization on how to define meaningful process and performance measures\nShare development and process knowledge with other staff to assure redundancy and continuously build a core of technical strength within the organization.\nDemonstrate proficiency with the principles and methodologies of process improvement. Apply these in the execution of responsibilities in support of a process focused approach.\nPerform other data management duties as necessary or assigned.\n\nQualifications\n\nMinimum of BA/BS degree in a relevant field of study; Master's degree preferred.\nAt least four (4) years of data mart or data warehouse development experience for a health provider, health plan or accountable care organization including either:\nBasic understanding of health care EMR or claims systems such as Epic/Clarity, eCW, Facets, Amisys, or similar systems.\nKnowledge of New York State Medicaid and CMS Medicare regulations and related reporting requirements such as STARS, QARR, MMCOR, MEDS, RAPS and HEDIS.\nExperience working in healthcare provider analytics related to revenue modeling, managed care contracting, population management, case management, clinical or financial decision support,\nPhD, MD or DO program may be substituted for 3 years of experience\nStrong technical skills working with SQL (Oracle's PL/SQL preferred) developing and trouble-shooting stored procedures and developing adhoc scripts.\nStrong data mining skills using tools like SQL, R, Python, SAS, Java/MapReduce, Aster, etc\nAbility to learn Business Intelligence products such as Tableau, Information Builders, Dimensional Insights, SAP/Business Objects, SAS, MicroStrategy, etc.\nAbility and passion to learn data acquisition, orchestration and provisioning techniques with rapidly evolving technologies like Sqoop, Flume, Impala, etc\nGeneral understanding of ETL tools like SSIS, Data Stage, PowerCenter, etc.\nAbility to exercise critical thinking and logical reasoning, and understand the conceptual framework and database relationships underlying health care data.\nAbility to think creatively; demonstrated excellent problem solving skills.\nExcellent oral and writing skills characterized by the ability to communicate effectively with varying audiences.\nDemonstrated ability to articulate goals, plan and implement processes to achieve those goals, recognize and assess the implications of confounding variables, anticipate consequences, and meet deadlines.\nAdvanced interpersonal (e.g., mediating, mentoring, teaching) skills required to service internal and external clients effectively, and manage relationships and activities that are diverse and complex.\nSelf-motivated and resourceful, with a demonstrated ability to think and work independently, and to exercise independent judgment in originating or developing complex techniques or programs in a complex and dynamic environment.\nHigh level of integrity as demonstrated by 1) appropriate treatment of confidential or protected health information, 2) adherence to policies, procedures, rules, and regulations, 3) professional conduct in dealing with persons internal and external to the organization, and 4) sensitivity to populations served by the organization.\n"},{"jobtitle":"Big Data and AI Engineer","companyname":"Pfizer","companyid":"","address":"","geo":"La Jolla, CA, US","postDate":"Oct 22 2018","views":"25","applicants":"1","employees":"","jobDetails":[{"level":"Entry level","industry":["Information Technology & Services","Biotechnology","Pharmaceuticals"],"jobtype":"Full-time","function":["Engineering","Information Technology"]}],"description":"Job description\nAs a member of the Pfizer Analytics Lab team, a component of Pfizer's Business Technology organization, the Data Engineer will join a team of highly collaborative data scientists & engineers dedicated to leveraging data and advanced analytics to create a healthier world. This team member will contribute their dynamic perspective and knowledge to data engineering and advanced analytics, inspire colleagues and peers to develop and implement critical data driven solutions within Pfizer's drug discovery efforts.\n\n Specifically, this group is focused on developing a set of capabilities designed to enable highly efficient exploration, experimentation, and rapid hypothesis generation based on internal, public, and commercially available datasets to continue supporting Pfizer's data driven, forward thinking approach to data science\n\n Day-to-day, the Data Engineer will\n\nBuild services and tooling around \"scraping\" databases, loading logs, fetching data from external stores or APIs\nAutomate data consumption from other source systems, files etc.\nCollaborate with other engineering, cloud infrastructure , security and product management teams to understand requirements and develop highly scalable system designs and architecture\nIntegrate new data management technologies and software engineering tools into existing structures\nCreate custom software components and analytics applications\nEmploy a variety of languages and tools to marry systems together\nParticipate in the assessment of new technologies as well as identifying next-generation solution architectures.\nDevelop efficient analytic pipelines that include components related to data acquisition, exploratory analysis, feature engineering, modeling, and interactive storytelling.\nShared-ownership of advancing team's data engineering capabilities through the ability to implement and execute on state-of-the-art approaches\nCo-develop re-usable components that will serve as the foundation for a scalable approach for Pfizer's analytic maturation\nPartner with other Business Technology teams to define and execute technology POCs using innovative technologies to advance Pfizer's analytic capabilities\nDirectly engage with key business stake-holders (Director level)\nInformal leadership of project teams comprised of Associate/Sr. Associate level colleagues\n\nQualifications\n\nBachelor's Degree in Computer Science, Operations Research, physics, applied mathematics, statistics required\n\n Advanced Degree in Computer Science, Operations Research, physics, applied mathematics, statistics or related field strongly preferred\n\n5 years' experience working as a Data/ML Engineer\n3 years working with semi-structured and unstructured data\n2 years working in a cloud based ecosystem, preferably Amazon Web Services.\nAbility to thrive in a fast-paced multi-disciplinary environment; with the ability to effectively communicate with a diverse audience\nAbility to create technical examples, prototypes, and demonstrations based on rapidly changing data sets\nExcellent written and verbal communication skills\n\nTechnical Qualification\n\n Proven experience in at least two of the three following categories:\n\n Data Science / Machine Learning\n\nExpertise with general-purpose statistics/machine learning algorithms and at least one of the following sub-disciplines: Natural Language Processing, Deep Learning, Network Analysis.\nExpertise with the implementation of algorithms within Python, R or Scala\nExpertise with model tuning, validation and evaluation\n\nData Engineering\n\nExpertise with SQL development, database administration and performance tuning\nExpertise with data manipulation and extraction using modern programming languages (Java, C++, C#, Python, Scala, Spark, etc.)\nExperience with Unix/Linux development - package management, knowledge of filesystems, performance monitoring/troubleshooting\nExperience with sourcing data from APIs; experience building APIs is a plus\nExperience with a variety of data stores for unstructured and columnar data as well as traditional database systems, for example, ElasticSearch, MongoDB, Cassandra, HBase, MySQL, Postgres and Vertica\n\nMachine Learning Engineering\n\nExperience building production implementations of data science and engineering pipelines\nBuilding and running high throughput real-time and batch data processing pipelines using Spark, Flink, Storm, Kafka or equivalent technologies\n\nEEO & Employment Eligibility\n\n Pfizer is committed to equal opportunity in the terms and conditions of employment for all employees and job applicants without regard to race, color, religion, sex, sexual orientation, age, gender identity or gender expression, national origin, disability or veteran status. Pfizer also complies with all applicable national, state and local laws governing nondiscrimination in employment as well as work authorization and employment eligibility verification requirements of the Immigration and Nationality Act and IRCA. Pfizer is an E-Verify employer.\n\n Sunshine Act\n\n Pfizer reports payments and other transfers of value to health care providers as required by federal and state transparency laws and implementing regulations. These laws and regulations require Pfizer to provide government agencies with information such as a health care provider's name, address and the type of payments or other value received, generally for public disclosure. Subject to further legal review and statutory or regulatory clarification, which Pfizer intends to pursue, reimbursement of recruiting expenses for licensed physicians may constitute a reportable transfer of value under the federal transparency law commonly known as the Sunshine Act. Therefore, if you are a licensed physician who incurs recruiting expenses as a result of interviewing with Pfizer that we pay or reimburse, your name, address and the amount of payments made currently will be reported to the government. If you have questions regarding this matter, please do not hesitate to contact your Talent Acquisition representative.\n\nOther Job Details\n\nEligible for Employee Referral Bonus\nThis position can sit in La Jolla, CA, New York, NY or Collegeville, PA\n\nPfizer is an equal opportunity employer and complies with all applicable equal employment opportunity legislation in each jurisdiction in which it operates."},{"jobtitle":"Senior Data Engineer","companyname":"Fanatics Inc","companyid":"","address":"","geo":"San Mateo, CA, US","postDate":"Oct 22 2018","views":"","applicants":"0","employees":"","jobDetails":[{"level":"Associate","industry":["Marketing & Advertising","Computer Software","Retail"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nFanatics is the global leader in licensed sports merchandise that changes the way fans purchase their favorite team apparel and jerseys through an innovative and tech-infused approach to making and selling fan gear in today's on-demand culture. We have the world's largest collection of officially licensed fan gear from all the leagues, teams and players our fans love. We operate more than 300 online and offline stores including e-commerce business with all major professional sports leagues (NFL, MLB, NBA, NHL, NASCAR, MLS, PGA), major media brands (NBC Sports, CBS Sports, FOX Sports) and over 150 collegiate and professional team properties. We partner with over 1000 vendors including Adidas, Nike, Reebok and Under Armor.\n\n Our inventory team is building inventory intelligence data pipelines that extract and process raw data into useful data analytics to meet our business's growing activities and potential. The pipelines are the core to our merchandising replenishment tool with forecasting statistics for our buyers to stock inventory and other business intelligence applications. We also build automation tools and monitoring systems to improve our development cycle.\n\n We are seeking for a Senior Data Engineer who has strong architectural skills and upkeeps scalability, availability and excellence when building the next generation of our data pipelines and platform. You are an expert in various data stores and data stream libraries, appreciate the value of clear communication and collaboration, and devote to continual capacity planning and performance fine-tuning for emerging business growth. As the Senior Data Engineer, you will architect and build inventory intelligence data pipelines and application platform that drive business decisions.\n\n What Will You Do?\n\nArchitect and build inventory intelligence data pipelines and platform that can parse raw data algorithmically from different data sources, and deliver quality real-time analytical reports for all our replenishment team and our business analytics\nDevelop clean, safe, testable and cost-efficient solutions; Build fast and reliable pipeline, platform with underlying data model that can scale according to business needs and growth\nWork with backend engineers to create services that can ingest and supply data to and from external sources, provide data streaming solutions and ensure data quality and timeliness\nWork with product manager to translate business requirements into scalable solutions, prioritize workload and deliver quality and functional products on a timely manner that can grow over time\nMake well-informed decisions with deep knowledge of both the internal and external impacts to teams and projects\nUnderstand the system you are building, foresee shortcomings ahead of time and be able to resolve or compromise appropriately\n\n\nWhat Are We Looking For?\n\nExcellent understanding of data structures, algorithms and distributed systems\nKnowledge of common design patterns used in Big Data processing\nStrong development experience using OO programming languages: Scala, Java, C++\nProficiency in big data technologies: AWS, Spark, Flink, Hive, Hadoop\nExperience with and deep understanding of traditional, NoSQL and columnar databases such as Oracle, MySQL, PostgreSQL, DynamoDB, Redshift, Vertica\nKnowledge and experience in designing and developing RESTful services, data modeling & mining, ETL, data warehouse, deployment and infrastructure management, and performance tuning\nExperience in partnering with architects, engineers in data environments that are complex, enterprise wide, multi-tenant, and host large scale of data\nAbility to build systems that balance scalability, availability and latency while solving different problems\nAdvocator of continual deployment and automation tools that can help improve the lives of our engineers\nA good communicator and team player who has a proven track record of building strong relationships with management, co-workers and customers.\nA desire to learn and grow, push yourself and your team, share lessons with others and provide constructive and continuous feedbacks, and receptive to feedback from others"},{"jobtitle":"Manager, Data Analysis","companyname":"Micron","companyid":"","address":"","geo":"Boise, ID, US","postDate":"Oct 22 2018","views":"1","applicants":"0","employees":"","jobDetails":[{"level":"Mid-Senior level","industry":["Computer Software","Research","Chemicals"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nReq. ID: 124279\n\nMicron Technology’s vision is to transform how the world uses information to enrich life and our commitment to people, innovation, tenacity, collaboration, and customer focus allows us to fulfill our mission to be a global leader in memory and storage solutions. This means conducting business with integrity, accountability, and professionalism while supporting our global community.\n\nHave you led a Data Analytics team in a fast-moving environment and are you comfortable driving goals while providing and receiving feedback? The Technology Development at Micron has an opportunity for a data driven leader who strives to promote leading edge capability in data analysis and visualization across a large-scale development manufacturing environment. We are looking for a dynamic leader with the ability to strategize and guide teams through goal challenges and decisions regarding technology development capabilities with focus on partner relationships and customer experience. You will manage a team of data analysts and interact with Leadership, Data Science, and Engineering teams to identify questions and issues for data analysis projects, developing new and leveraging innovation from Big Data solutions to present data stories supporting yield, quality, variation, anomaly’s, capability, correlations, SPC, and operations challenges. This position will drive operational and strategic changes in how Technology Development, Manufacturing, and Yield engineering teams do data analysis by automating basic data analysis and leveraging/promoting the implementation of advanced automated solutions. We're passionate about Data Analytics to drive innovation in our business. The foundation for our progress is our ability to work with data, to measure impact and accuracy, to respond quickly while keeping the long-term vision in mind, and to continuously develop the talent on our teams.\n\nResponsibilities Include, But Are Not Limited To\n\nOur Data Analyst Manager is responsible for mentoring and a leading diverse and talented team as we deliver on our technology development roadmap. To thrive in this role, you execute well in a fast paced and agile environment with ability to make pragmatic decisions, establish and use tight feedback loops, and take calculated risks based on your knowledge and collaborating with your peers.\n\nDrive existing and new analytics, reporting, and automation capabilities including the use of advanced data science base solutions\nProvide management updates on correlation breakthroughs, project roadmaps, wins and challenges\nEngage and mentor multi-functional team members in projects, critical metrics to increase efficiencies and consistency\nCommitment to mentor, coach, and serve a team of experienced team members\nCollaborate with partners across Technology Development to develop best-in-class interactive experiences that meet the business objectives of the organization and advance our data visualization positioning and information-based decision-making\nPartner with global peer network to identify and leverage best-known methods where appropriate\nCarry a sense of urgency in problem solving, demonstrates effective time management and organization\nMaintain a high-level strategy to drive innovation and leadership in team's solutions and contributions\nDrive team members to grow through regular review of expectations, performance, and path to progress on career goals\nPromote a safety culture in our working environment\n\n\nMinimum Qualifications\n\nBS in an engineering related field\n3 yrs Supervisory or Management experience\nYou carry a passion for leadership of a team and team member success while devoted to the work they do\nYour primary tools are mentoring, collaboration, communication, goal setting, and a positive growth mindset\nProject management across organizational boundaries and ability to execute to aggressive timelines\nSubject matter expertise in data collection/analysis, and SPC\nExperience in scripting and programming languages (i.e. Python/R)\nExperience in mining data, warehousing systems and also ETL, SQL\nExcellent verbal and written communication; deep interest and aptitude in telling stories with data\nDemonstrate problem solving, analytical skills and report results\nProven ability to drive multiple complex projects to completion\nUnderstanding of semiconductor processing\nAbility to work through ambiguous situations to drive work product delivery\n\n\nWe recruit, hire, train, promote, discipline and provide other conditions of employment without regard to a person's race, color, religion, sex, age, national origin, disability, sexual orientation, gender identity and expression, pregnancy, veteran’s status, or other classifications protected under law. This includes providing reasonable accommodation for team members' disabilities or religious beliefs and practices.\n\n Each manager, supervisor and team member is responsible for carrying out this policy. The EEO Administrator in Human Resources is responsible for administration of this policy. The administrator will monitor compliance and is available to answer any questions on EEO matters.\n\n To request assistance with the application process, please contact Micron’s Human Resources Department at 1-800-336-8918 (or 208-368-4748).\n\n Keywords: Boise || Idaho (US-ID) || United States (US) || Technology Development || Experienced || Regular || Engineering || ||\n\n"},{"jobtitle":"Data Analyst II","companyname":"TBC Corporation","companyid":"","address":"","geo":"Palm Beach Gardens, FL, US","postDate":"Oct 22 2018","views":"3","applicants":"1","employees":"","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Retail","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nDescription\n\nGeneral Summary:\n\n The Data Analyst II will perform business analysis using various techniques, e.g. statistical analysis, data mining to facilitate data profiling, data cleansing, and data defect prevention. Determines best practices and develops actionable insights and recommendations for the current and future Data Management operations. The role will assist in the implementation or development of systems to capture master data and information. Occasionally leads and/or guide less experienced Data Quality Analysts. It does requires a bachelor's degree. Directly reports to the Data Quality Manager and occasionally directed in several aspects of the work. 2 to 4 years of related experience preferred.\n\nPrimary Responsibilities\n\nInterpret data, analyze results using statistical techniques and provide ongoing reports.\nDevelop and implement dashboards, databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality of master data.\nAcquire data from primary or secondary data sources and maintain databases/data systems\nIdentify, analyze, and interpret trends or patterns in complex data sets.\nFilter and \"clean\" data by reviewing computer reports, printouts, and performance indicators to locate and correct process or systemic problems.\nWork with management to prioritize business and information needs.\nIdentify and recommend new ways to save money by streamlining business processes\nWork with departmental managers to outline the specific data needs for each business method analysis project\nLocate and define new process improvement opportunities.\n\nEducation\n\nBachelor's Degree in business, computer/data science or a related field required.\n\nExperience\n\nMinimum Requirements\n\n 2-4 years of Data mining experience preferred. (Includes time spent obtaining Bachelor's Degree)\n\n 2-4 Data Analysis experience preferred. (Includes time spent obtaining Bachelor's Degree)\n\n 2 years of technical expertise regarding data models, database design development, data mining and segmentation techniques.\n\n 2-4 years of experience with reporting packages (Cognos, Qlikview, etc), databases (SQL etc), programming (XML, Javascript, EDI and ETL frameworks)\n\n 2 years of knowledge and/or experience in statistics and the use of statistical packages for analyzing datasets (Excel, Power BI, SPSS, SAS etc)\n\n Adept at queries, report writing and presenting findings.\n\nSkills\n\nStrong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with detail and accuracy.\n\n Excellent communication skills.\n\n Advanced Microsoft Office skills; MSAccess, Excel, Word, and Visio\n\n Intranet search skills.\n\n Data Entry skills, with emphasis on accuracy and speed.\n\n Working Knowledge of data querying and analytics tools, processes and methodology.\n\n Working Knowledge of database and software tools to support data analysis and reporting.\n\n Team Oriented.\n\n Self-Starter\n\n TBC Corporation TBC continuously offers strong career opportunities to those from inside as well as outside the auto services industry. We hire those with a passion for success and we will train them with proven processes that will take them there. Our employees share a very unique and lucrative opportunity to maximize their earnings with industry leading pay, incentives, and recognition programs when they deliver and exceed expected results."},{"jobtitle":"Senior Data Engineer","companyname":"Northrop Grumman","companyid":"","address":"","geo":"Monterey, CA, US","postDate":"Oct 22 2018","views":"4","applicants":"0","employees":"","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Defense & Space","Computer Software"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nAt Northrop Grumman, innovation isn't just an idea----its a way of life. Our employees have incredible opportunities to work on revolutionary systems in air and space that impact peoples lives around the world today, and for generations to come. Our work preserves freedom and democracy, and advances human discovery and our understanding of the universe.\n\n We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future. Northrop Grumman is seeking a Senior Data Engineer to become part of Northrop Grumman's organization supporting the Army Analytics Group's Research Facilitation Laboratory located in Monterey, California.\n\nRoles And Responsibilities\n\nGather and document data, user, and system business requirements\nProduce comprehensive and usable technical and business database specifications\nLead the data analysis and development efforts for new client implementations and system enhancements\nMaintain and optimize ETL configuration and baseline\nTroubleshoot issues with ETL connections, performance, or other errors\nUpdate, compile, test, and deploy changes in response to problem reports\nDevelop, test, and deploy ETL modifications based on new customer requirements\nExecute and monitor ETL processes to ensure all components function properly\nCommunicate with clients, developers and other team members\nInterface with vendor technical resources to resolve data transfer issues\nReplace existing manual processes with automated and more reliable versions\nMentor and provide technical guidance to junior members of the team\n\nBasic Qualifications\n\nBachelor's degree in Engineering, Computer Science, Information Systems, Applied Mathematics or other scientific/technical discipline and a minimum of 14 years of industry experience\n2 years of relevant technology architecture consulting or industry experience\nExperience with ETL concepts and tools\nExperience with data dictionaries, data analysis, data warehousing, and relational databases\nUnderstand the benefits of data warehousing, data architecture, data quality processes, data warehousing design and implementation, table structure, fact and dimension tables, logical and physical database design, data modeling, reporting process metadata, and ETL processes\nExperience defining a data warehouse solution, multidimensional model, logical and physical models design, data types, staging process and its benefits, and different data warehouse design approaches and schemas\nFamiliarity with Oracle 11g/12c/18c\n2 years of experience designing and executing complex data queries utilizing diverse data sources as well as both structured and unstructured data\n2 years of strong programming/development skill using PL/SQL (package, procedures, functions, triggers) and batch coding skills such as Bulk collections, dynamic SQL, and parallel processing\nAbility to hold a DoD Secret Clearance (US Citizenship is required)\n\nPreferred Qualifications\n\nDetail driven and possesses an intellectual curiosity to go deeper into data\nAbility to work on several complex projects with general direction and minimal guidance\nAbility to develop professional relationships\nStrong oral and written communication skills, including presentation skills\nKnowledge of Microsoft Visio, Team Foundation Server, Project and Office\nStrong expertise in an object oriented language (e.g. Python or Java)\nExperience with big data tools such as Hadoop, Hive, Spark, etc.\nExperience delivering data pipelines and managing resulting data stores using managed cloud services\nKnowledge of machine learning tools and concepts\nExperience supporting and/or migrating data from other sources\n2 years of experience with software development methodologies including Agile delivery\n1 years of hands on experience with Informatica PowerCenter and/or other tools such as Amazon Redshift, SQL Server Integration Services (SSIS), SAP Data Services, SAP BW/HANA, SAS Data Management, Oracle Warehouse Builder and Oracle Data Integrator (ODI) SAP Data Services\nExperience in developing logical and physical data models using data modeling tools such as Rational Data Architect, Erwin, Oracle Developer, other tools\n\nNorthrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions."},{"jobtitle":"Data Scientist/analyst","companyname":"Honda Trading Europe Ltd.","companyid":"1594782","address":"","geo":"Raymond, OH, US","postDate":"Oct 22 2018","views":"70","applicants":"22","employees":"51-200","jobDetails":[{"level":"Entry level","industry":["Information Technology & Services","Automotive","Financial Services"],"jobtype":"Full-time","function":["Engineering","Information Technology"]}],"description":"Job description\nHonda R&D Americas, Inc. is an innovative and dynamic companyresponsible for the complete product creation of Honda & Acura products,including automobiles, power sports and power equipment. As a member of the EnterpriseApplications team in the Information Systems Division, you will be at theforefront of implementing systems, services and software/data products thatwill focus on ensuring the efficient operations of the R&D business.\n\n We are seeking a data analyst engineer whowill use insights gained from analyzing company data to support ourdevelopment, administrative, and leadership teams. The candidate must be proficient at usinglarge data sets to find opportunities for process optimization across multiplebusiness divisions. They must becomfortable working and communicating with a diverse group of stakeholders andfunctional teams. The ideal candidate isexpected to have a high level of knowledge and experience in data mining andanalytic methods, and creating/running simulations. We are looking for someone to bring passionfor solving complex problems with data sets and working with stakeholders topositively influence our business outcomes.\n\n Each day will bring new andexciting challenges on the job while you:\n\nLearnand use groundbreaking technologies\nInteractwith leading Engineers & Management from across the organization globally\nExperience world classproducts & services built in front of you and by you\n\nEssential Job Requirements\n\nBusiness Analysis - Capture and interpret the businessneeds/requirements through appropriate means (interviews, document analysis,workshops, etc) and identify opportunities to leverage data to drive thebusiness solution.\nProcess Improvement - Actively participateand assist in the projects, mine and analyze data from company databases todrive optimization and improvement of product development and businessstrategies. Ability to assessproductivity and accuracy of new data sets, develop data models and algorithmsto apply to the data sets.\nAdvanced Thinking - Use predictive modeling and what-ifanalysis to increase and optimize stakeholder/customer experiences and influencebusiness outcomes. Develop processes andtools to monitor and analyze model performance and data accuracy.\nCritical Thinking &Problem Solving - Recognizes problems and/oropportunities that are new or without clear precedent. Evaluates alternativesand finds solutions using a systematic, multi-step approach with the goal ofproviding improvements or innovations to enhance the business.\nData Visualization - Organize and develop easy to use and interpret reports/dashboardsfor use by all levels of the organization. Employing basic user experience methodsand delivery techniques to enable quick understanding, what-if analysis and decision-making.\nBA or BS or equivalent experience in Statistics, Mathematics, Computer Science or another quantitative field is required.\nMinimum 5 years of experience manipulating data sets and building statistical models desired\nAbility to interpret data and trends, and present recommendations\nExperience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.\nFamiliar with relational databases / Hadoop-based data mining frameworks, SQL, Java and C/C\nKnowledge of different data mining techniques and advance machine learning algorithms such as regression, simulation, scenario analysis, modeling, clustering, decision trees, text mining, etc.\nExperience visualizing/presenting data for stakeholders\nStrong analytical, planning, and organizational skills with an ability to manage competing demands\nUnderstanding of data analytic concepts and best practices, with a drive to learn and master new technologies and techniques.\nExcellent oral and written communications skills and experience interacting with both business and IT individuals at all levels including the executive level\nCreative approach to problem-solving with the ability to focus on details while maintaining the \"big picture\" view.\n"},{"jobtitle":"Business Data Analyst","companyname":"Coffee And Bagel Brands","companyid":"","address":"","geo":"Aurora, CO, US","postDate":"Oct 22 2018","views":"6","applicants":"1","employees":"","jobDetails":[{"level":"Associate","industry":["Food & Beverages","Retail","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nAddress: | 555 Zang St. Suite #300 , Lakewood, Colorado 80228 |\n\n At Coffee & Bagel Brands, our team has a common set of values that we call our Purpose & Heart. These are the behaviors that guide how we work, how we treat each other and how we treat our guests. Our goal is to create Bright Spots for each other and our guests every day. A Bright Spot is all about making someone's day and putting a smile on their face!\n\n Coffee & Bagels Brands is Caribou Coffee, Einstein Bros. Bagels, Noah's New York Bagels, Bruegger's Bagels and Manhattan Bagel. We are your friendly neighborhood gathering place for good conversation and great food.\n\n Position Mission: Partnering with various members of Coffee and Bagel Brands Organization under guidance of Finance leadership this role will:\n\nWork cross-functionally with Support Center and Field partners to deliver new analytics insights that drive the organization forward\nBridge the gap between data and process to provide enterprise-wide operational and reporting capabilities\nLead meetings with functional leaders to understand current challenges, key business drivers, and deliver data-driven solutions\nHumanize data analysis using narratives and visualizations that effectively convey to the business \"why\" data insights are important, inspiring stakeholders to action\nAssist in the integration of enhanced reporting, advanced analytics, and data systems to streamline business processes\nBe a trusted partner for the Support Center teams and Field management teams\n\nResponsibilities Include, But Are Not Limited To\n\nPartner with team members to deliver accurate, timely reporting and analysis of KPIs\nDevelop new data automation processes to enable greater trust and accuracy in reported data\nEffectively manage information flows from multiple systems\nConduct data quality assessments, data profiling, and support data mining/advanced analytic initiatives\nLeverage big datasets and self-service analytic tools to enable enterprise dashboards\nPartner with team members to evangelize the power of data and train them to be successful using reporting tools/systems\nResearch analytics best practices and provide recommendations for improving current business operations\nSpecial project work and ad hoc analysis as assigned\n\nRequired Knowledge, Skills & Abilities\n\nIntellectually curious\nStrong background in operationalizing analytics, with data mining experience\nExperience automating data transformations on large datasets\nFamiliar with database design principles and highly proficient using SQL to wrangle data\nAbility to document processes and procedures\nBrings an innovator mindset to solving complex problems and ability to deliver with an end-user in mind\nComfortable presenting and providing recommendations to leadership\nExcellent organizational and project management skills\nAttention to detail with high emphasis on data/reporting accuracy\nExpert with Excel (VBA, pivot tables, advanced functions, statistics)\nExperience using business intelligence and big data tools (Tableau, MicroStrategy, PowerBI, Alteryx)\n\nRequired\n\nEducation/Training/Experience:\n\nBachelor's in Business, Systems, Finance, Analytics, or other related field of study\n2 - 3 years of applicable, progressive work experience\n\nHighly Preferred\n\nExperience using data mining tools (R, Python, or similar) and performing advanced analytics with business data (machine learning, statistical analysis, classification)\nStrong technical knowledge of object-oriented programming and/or web programming\nUnderstanding of Agile methodologies\nAdvanced degree or data bootcamp program completion a plus.\n\nBrand\n\nCoffee & Bagel Brands\n\n The physical demands for this position are sits, stands, bends, lifts, and moves intermittently during working hours. These physical requirements may be accomplished with or without reasonable accommodations.\n\n The duties of this position may change from time to time. Coffee & Bagel Brands reserve the right to add or delete duties and responsibilities at the discretion of the company or its managers. This job description is intended to describe the general level of work being performed. It is not intended to be all-inclusive.\n\n Coffee & Bagel Brands are committed to providing equal employment opportunity and equal treatment in employment without regard to race, ethnicity, color, religion, gender/gender identity or expression, sexual orientation, age, national origin or ancestry, physical or mental disability, military status or any other basis in protected by applicable federal, state and local law. Coffee & Bagel Brands makes employment decisions based solely on the basis of qualifications for the job."},{"jobtitle":"Senior Technical/Data Analyst","companyname":"Enterra Solutions, LLC","companyid":"42280","address":"","geo":"17 Blacksmith Road Suite 200, Newtown, PA 18940, US","postDate":"Oct 22 2018","views":"410","applicants":"204","employees":"11-50","jobDetails":[{"level":"Mid-Senior level","industry":["Computer Software","Information Technology & Services"],"jobtype":"Full-time","function":["Analyst","Information Technology"]}],"description":"Job description\n\n \n\nPOSITION: Senior Technical/Data Analyst-Category Management\n\n \n\nAbout Enterra Solutions®\n\nEnterra Solutions has combined artificial intelligence and advanced mathematics to pioneer the Enterra Enterprise Cognitive System™. By reasoning the way humans do and performing sophisticated mathematical analysis, Enterra automates a new way of problem-solving and decision-making; thus, going beyond advanced analytics to answer queries and generate insights instantly. Enterra helps transform market-leading companies into true digital enterprises.\n\n \n\nLOCATION:\n\nEnterra is located in Newtown, PA (Bucks County) --Approximately 30 miles north of Philadelphia/ 20 miles south of Princeton NJ.  Local candidates in a reasonable commutable distance to Newtown, PA are generally preferred; however, this is a client-facing position and requires up to 50% travel to client sites. Travel demands will vary depending on location of candidate in relation to client sites. Enterra will consider candidates willing/able to work from their home residing in the Northeast and Mid-Atlantic regions (preferably Pennsylvania, New Jersey or Northern Virginia/Washington, DC area).\n\n \n\nPOSITION DESCRIPTION:\n\nEnterra has distinguished itself as an early thought leader within the Cognitive Computing space and has built an impressive client list of top companies implementing innovative solutions. Our environment is both exciting and challenging as we continue to build our core platform, further productize our offerings and deliver quality solutions to our rapidly growing client base.\n\n\n\n\nWork with Enterra Business Analysts and client personnel to:\n\n-Understand and document the technical and data infrastructure that supports business functions and processes to be impacted by the engagement. \n\n \n\nWork with client personnel to:\n\n-Derive, specify and document the data requirements for the engagement from the process knowledge. In some cases, this involves identifying and understanding data that is not currently available to client users but could be used to improve the business functions and processes.\n\n-Establish the data acquisition/transfer/integration process for the engagement from primary and/or secondary data sources.\n\n-Understand and document the existing (and planned) system architectures and architecture requirements.  Specific focus is on installation and integration of Enterra offerings within the client architecture. Note that Enterra offerings are generally deployed within the cloud.\n\n\n\n\nObtain a full understanding of the data set(s) to:\n\n-Perform data quality assurance (DQA), validation and verification to ensure accuracy and completeness of data sets against the requirements.\n\n-Perform data munging/wrangling to connect and map data sets such that they can be used by the Enterra engines.\n\n-Resolve data quality problems. Activities include: Identify, assess, fix, document, and communicate potential quality issues. This may involve interacting with business users to resolve data quality problems using techniques such as root cause analysis. It may also include data cleansing and operations like removing duplicate records or determining appropriate proxies for any missing data.\n\n-Note: Candidate should be able to perform the above on sample/initial data submissions from the client in an offline environment AND specify the requirements for Engineering personnel to develop the appropriate production code for use within the systems.\n\n\n\n\nWork with Enterra Business Analysts and the Data Science team to:\n\n-Specify the key insights and recommendations to be generated as output from the system.\n\n-Review the analytics approach.\n\n-Perform initial statistical analysis, as needed.\n\n-Perform initial feature engineering to enrich the data, as needed. Detail the requirements for Engineering to develop the appropriate production code.\n\n-Create technical and business level presentations of analytical results/insights for review with clients.\n\n\n\n\nWork with Enterra Engineering team to:\n\n-Describe the client business operational processes and system requirements.\n\n-Detail the data management requirements to implement the on-going validation, verification, cleansing, harmonization and feature engineering.\n\n-Answer questions from the team – this may require obtaining more information from the client.\n\n-Provide quality assurance oversight of data flows and stores. Review quality of data, loads, transformations, extractions, merges, or other production jobs. This may also include the establishment and monitoring of service level agreements, communication protocols with data suppliers, and data quality assurance policies.\n\n-Debug SQL, stored procedures, NoSQL, Python, and related data issues.\n\n-Manage data quality documentation. Define and maintain data standards, definitions, and models (e.g. data dictionary, organizational data model. This may also include any DQA documents such as checklists, guidelines, manuals, templates, forms, etc.).\n\n-Identify, analyze, and interpret trends or patterns in complex data sets\n\n\n\n\nWork with all project participants to:\n\n-Test the solution and assist in debugging issues.\n\n \n\n \n\nREQUIREMENTS: Must have the following:\n\n-Hands on work experience as a technical/data analyst (5 years minimum).\n\n-Hands on work experience in an external client-facing role (3 years minimum).\n\n-Strong documentation skills especially in documenting requirements using different approaches such as use cases, activity diagrams, sequence diagrams and state charts, data dictionaries, class or entity relationship diagrams.\n\n-Strong communication skills. Ability to clearly articulate and communicate with business and technical personnel. This includes documentation, presentations and individual analysis sessions.\n\n-Experience with databases including SQL skills, stored procedure programming and Python for data manipulation.\n\n-High comfort level with relational databases, data mining and data warehousing.\n\n-Able to make (and defend) informed decisions on a wide range of complex technical issues.\n\n-Distinctive problem-solving and analytical skills, combined with strong business sense.\n\n-Minimum of BS Degree in Computer Science or related field.\n\n\n\n\nHIGHLY DESIRED SKILLS:\n\nExperience in Category Management functions such as Trade Promotion, Assortment and Pricing – along with related data sets and technologies (e.g., Nielsen, IRI, JDA etc.)     \n\n-Experience with automated data profiling tools.\n\n-Experience with BI, Data Mining, and Data Visualization tools.\n\n-Knowledge of statistics and experience using statistical packages for analyzing large datasets (Excel, R, Python, etc.).\n\n-Knowledge of data encryption techniques and algorithms such as PGP, Triple DES, RSA.\n\n-Working knowledge of the cloud environments (Azure, Google, AWS).\n\n\n\n\nBefore applying, please read below:\n\nCandidates must be willing to travel as required.\n\nCandidates must currently reside in the northeast or mid-atlantic region\n\nEnterra does NOT sponsor - Candidates must be eligible to work in the US without sponsorship\n\nNo Corp to Corp --this is a full time position\n\nIf interested, please submit your resume with your full name and contact info, including phone number and location (city/state is acceptable)."},{"jobtitle":"Manager, Data Analysis","companyname":"Micron Technology","companyid":"3690","address":"","geo":"Boise, ID, US","postDate":"Oct 15 2018","views":"175","applicants":"14","employees":"10001","jobDetails":[{"level":"Mid-Senior level","industry":["Computer Hardware","Electrical & Electronic Manufacturing","Semiconductors"],"jobtype":"Full-time","function":["Engineering"]}],"description":"Job description\nReq. ID: 124279\n\n Micron Technology’s vision is to transform how the world uses information to enrich life and our commitment to people, innovation, tenacity, collaboration, and customer focus allows us to fulfill our mission to be a global leader in memory and storage solutions. This means conducting business with integrity, accountability, and professionalism while supporting our global community.\n\nHave you led a Data Analytics team in a fast-moving environment and are you comfortable driving goals while providing and receiving feedback? The Technology Development at Micron has an opportunity for a data driven leader who strives to promote leading edge capability in data analysis and visualization across a large-scale development manufacturing environment. We are looking for a dynamic leader with the ability to strategize and guide teams through goal challenges and decisions regarding technology development capabilities with focus on partner relationships and customer experience. You will manage a team of data analysts and interact with Leadership, Data Science, and Engineering teams to identify questions and issues for data analysis projects, developing new and leveraging innovation from Big Data solutions to present data stories supporting yield, quality, variation, anomaly’s, capability, correlations, SPC, and operations challenges. This position will drive operational and strategic changes in how Technology Development, Manufacturing, and Yield engineering teams do data analysis by automating basic data analysis and leveraging/promoting the implementation of advanced automated solutions. We're passionate about Data Analytics to drive innovation in our business. The foundation for our progress is our ability to work with data, to measure impact and accuracy, to respond quickly while keeping the long-term vision in mind, and to continuously develop the talent on our teams.\n\nResponsibilities Include, But Are Not Limited To\n\nOur Data Analyst Manager is responsible for mentoring and a leading diverse and talented team as we deliver on our technology development roadmap. To thrive in this role, you execute well in a fast paced and agile environment with ability to make pragmatic decisions, establish and use tight feedback loops, and take calculated risks based on your knowledge and collaborating with your peers.\n\nDrive existing and new analytics, reporting, and automation capabilities including the use of advanced data science base solutions\nProvide management updates on correlation breakthroughs, project roadmaps, wins and challenges\nEngage and mentor multi-functional team members in projects, critical metrics to increase efficiencies and consistency\nCommitment to mentor, coach, and serve a team of experienced team members\nCollaborate with partners across Technology Development to develop best-in-class interactive experiences that meet the business objectives of the organization and advance our data visualization positioning and information-based decision-making\nPartner with global peer network to identify and leverage best-known methods where appropriate\nCarry a sense of urgency in problem solving, demonstrates effective time management and organization\nMaintain a high-level strategy to drive innovation and leadership in team's solutions and contributions\nDrive team members to grow through regular review of expectations, performance, and path to progress on career goals\nPromote a safety culture in our working environment\n\n\nMinimum Qualifications\n\nBS in an engineering related field\n3 yrs Supervisory or Management experience\nYou carry a passion for leadership of a team and team member success while devoted to the work they do\nYour primary tools are mentoring, collaboration, communication, goal setting, and a positive growth mindset\nProject management across organizational boundaries and ability to execute to aggressive timelines\nSubject matter expertise in data collection/analysis, and SPC\nExperience in scripting and programming languages (i.e. Python/R)\nExperience in mining data, warehousing systems and also ETL, SQL\nExcellent verbal and written communication; deep interest and aptitude in telling stories with data\nDemonstrate problem solving, analytical skills and report results\nProven ability to drive multiple complex projects to completion\nUnderstanding of semiconductor processing\nAbility to work through ambiguous situations to drive work product delivery\n\n\nWe recruit, hire, train, promote, discipline and provide other conditions of employment without regard to a person's race, color, religion, sex, age, national origin, disability, sexual orientation, gender identity and expression, pregnancy, veteran’s status, or other classifications protected under law. This includes providing reasonable accommodation for team members' disabilities or religious beliefs and practices.\n\n Each manager, supervisor and team member is responsible for carrying out this policy. The EEO Administrator in Human Resources is responsible for administration of this policy. The administrator will monitor compliance and is available to answer any questions on EEO matters.\n\n To request assistance with the application process, please contact Micron’s Human Resources Department at 1-800-336-8918 (or 208-368-4748).\n\n Keywords: Boise || Idaho (US-ID) || United States (US) || Technology Development || Experienced || Regular || Engineering || ||\n\n"},{"jobtitle":"Senior Data Engineer","companyname":"Northrop Grumman","companyid":"1412","address":"","geo":"Monterey, CA, US","postDate":"Oct 15 2018","views":"19","applicants":"5","employees":"10001","jobDetails":[{"level":"Mid-Senior level","industry":["Defense & Space","Aviation & Aerospace","Military"],"jobtype":"Full-time","function":["Quality Assurance","Manufacturing","Engineering"]}],"description":"Job description\nAt Northrop Grumman, innovation isn’t just an idea----its a way of life. Our employees have incredible opportunities to work on revolutionary systems in air and space that impact peoples lives around the world today, and for generations to come. Our work preserves freedom and democracy, and advances human discovery and our understanding of the universe.\n\n We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future. Northrop Grumman is seeking a Senior Data Engineer to become part of Northrop Grumman’s organization supporting the Army Analytics Group’s Research Facilitation Laboratory located in Monterey, California.\n\nRoles And Responsibilities\n\nGather and document data, user, and system business requirements\nProduce comprehensive and usable technical and business database specifications\nLead the data analysis and development efforts for new client implementations and system enhancements\nMaintain and optimize ETL configuration and baseline\nTroubleshoot issues with ETL connections, performance, or other errors\nUpdate, compile, test, and deploy changes in response to problem reports\nDevelop, test, and deploy ETL modifications based on new customer requirements\nExecute and monitor ETL processes to ensure all components function properly\nCommunicate with clients, developers and other team members\nInterface with vendor technical resources to resolve data transfer issues\nReplace existing manual processes with automated and more reliable versions\nMentor and provide technical guidance to junior members of the team\n\nBasic Qualifications\n\nBachelor’s degree in Engineering, Computer Science, Information Systems, Applied Mathematics or other scientific/technical discipline and a minimum of 14 years of industry experience\n2+ years of relevant technology architecture consulting or industry experience\nExperience with ETL concepts and tools\nExperience with data dictionaries, data analysis, data warehousing, and relational databases\nUnderstand the benefits of data warehousing, data architecture, data quality processes, data warehousing design and implementation, table structure, fact and dimension tables, logical and physical database design, data modeling, reporting process metadata, and ETL processes\nExperience defining a data warehouse solution, multidimensional model, logical and physical models design, data types, staging process and its benefits, and different data warehouse design approaches and schemas\nFamiliarity with Oracle 11g/12c/18c\n2 years of experience designing and executing complex data queries utilizing diverse data sources as well as both structured and unstructured data\n2+ years of strong programming/development skill using PL/SQL (package, procedures, functions, triggers) and batch coding skills such as Bulk collections, dynamic SQL, and parallel processing\nAbility to hold a DoD Secret Clearance (US Citizenship is required)\n\nPreferred Qualifications\n\nDetail driven and possesses an intellectual curiosity to go deeper into data\nAbility to work on several complex projects with general direction and minimal guidance\nAbility to develop professional relationships\nStrong oral and written communication skills, including presentation skills\nKnowledge of Microsoft Visio, Team Foundation Server, Project and Office\nStrong expertise in an object oriented language (e.g. Python or Java)\nExperience with big data tools such as Hadoop, Hive, Spark, etc.\nExperience delivering data pipelines and managing resulting data stores using managed cloud services\nKnowledge of machine learning tools and concepts\nExperience supporting and/or migrating data from other sources\n2+ years of experience with software development methodologies including Agile delivery\n1+ years of hands on experience with Informatica PowerCenter and/or other tools such as Amazon Redshift, SQL Server Integration Services (SSIS), SAP Data Services, SAP BW/HANA, SAS Data Management, Oracle Warehouse Builder and Oracle Data Integrator (ODI) SAP Data Services\nExperience in developing logical and physical data models using data modeling tools such as Rational Data Architect, Erwin, Oracle Developer, other tools\n\nNorthrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.\n\nLocation\n\nUnited States-California-Monterey\n\nUS Citizenship Required For This Position\n\nYes\n\nRelocation Assistance\n\nNo relocation assistance available\n\nClearance Type\n\nSecret\n\nShift\n\n1st Shift\n\nTravel\n\nYes, 10 % of the Time"},{"jobtitle":"Data Analyst (Entry Level)","companyname":"Vertafore","companyid":"7892","address":"","geo":"Greenwich, CT, US","postDate":"Oct 15 2018","views":"","applicants":"0","employees":"1001-5000","jobDetails":[{"level":"","industry":["Computer Software"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nWork with internal client facing teams on broker/carrier analytics and reporting\nPerform data analysis by means of data interpretation, and execution of advanced database queries using Tableau, MySQL, Amazon Redshift, Excel, R, Python and other database technologies or programming languages as appropriate. Identify, analyze, and interpret trends, patterns or insights in result sets\nWork independently, or in teams on complex level data gathering, checking, manipulation, analysis, reporting and data quality assurance tasks with minimal supervision\nDevelop analytical model for reporting and mining insights for business development activities using conventional or visualization tools\nDefine and develop platform data quality checks or assessment for purposes of enhancing the RiskMatch service in support new prospects or existing clients.\nDevelop and document rules, integrity and consistency checks\nTroubleshoot and recommend solution to technical problems\nPerform other duties as the company evolves\nProfessional/Hands-on experience with SQL, EXCEL, and interactive data visualization tool like Tableau. If you have not written and executed complex SQL queries, please do not apply\nDeep understanding and working knowledge of relational structures, and reporting techniques and practices\nStrong communication and problem solving skills, a positive attitude and the ability to work with external clients as required\nNice to have: knowledge of statistical concepts and, ideally, supervised learning machine-learning algorithms\nNice to have: Property & Casualty Insurance experience"},{"jobtitle":"Data Analyst","companyname":"Women's World Banking","companyid":"28467","address":"","geo":"New York, New York","postDate":"Oct 15 2018","views":"637","applicants":"126","employees":"11-50","jobDetails":[{"level":"Associate","industry":["Non-profit Organization Management","Banking","Management Consulting"],"jobtype":"Full-time","function":["Analyst","Research","Project Management"]}],"description":"Job description\n\nSummary:\n\nReporting to the Research Director, the Data Analyst will work directly with internal and external stakeholders as well as data providers, leveraging advanced statistical techniques to drive strategic thought and effective decision making in addition to collect and analyzing data an information about customers, markets and the business environment in countries in Africa, Asia, and Latin America. The Analyst also supports all aspects of analytic initiatives from conception to completion, through the development of clear and well-structured analytical plans, and ability to analyze large and complex data-sets. This role will serve in shaping Women’s World Banking business’s data infrastructure, inclusive of data-warehousing, reporting, modeling, and analytics platforms, as well as supporting a variety of data insights and data reporting needs, including, but not limited to, customer segmentation analysis and look-alike modeling, use case development and validation, cross-country trend analysis, and data visualization.  \n\n \n\nResponsibilities:\n\nServe as primary resource for supporting measurement and data analysis needs including: integration of multiple large datasets for ongoing data analysis and mining; data cleaning and variable development; quality control; data segmentation design; programming and analysis. Build and manage large and complex (multi-source and multi-stream) datasets with internal platforms and resources;\n\nWork with research team to support Women’s World Banking project objectives and develop datasets and analysis that provide the most accurate and comprehensive picture;\n\nServe as key team member in development of predictive analytics methodologies and models for use in ongoing applied research projects;\n\nDevelop and implement analytical strategies through a range of quantitative research methods to provide data driven insights that support iterative development of the research project;\n\nWork as a member of the research team to recommend the best analytic approaches and set the standard of excellence for conducting, packaging, and reporting on frequently used analyses and datasets;\n\nConduct a range of statistical tests on datasets to understand aspects of client and organization patterns and relationships including descriptive statistics, segmentation analysis of patterns and trends, inferential statistics and experimental and quasi-experimental tests of difference and relationships;\n\nAssess the methodologies, data quality and synergies across various third-party data sets and develop strategic recommendations on behalf of the research team;\n\nDemonstrated ability to “tell the story” with data at the executive, manager, and team levels using charts and other data visualizations that are clear and easy to understand for any interested layperson.\n\n\n \n\nWithin the first 75 days:\n\nAssume full responsibility of the position;\nEmbrace Women’s World Banking’s core values and desired behaviors;\nForge positive working relationships with cross-functional staff;\nEmbrace Women’s World Banking’s unique characteristics and offerings;\nLearn and comprehend the Women’s World Banking business model;\nBecome trained in and fully integrate the use of Women’s World Banking systems and policies into your day-to-day activities;\nDevelop a road map to achieve targets and deliverables for the year.\n\n \n\nRequired Qualifications:\n\nBachelor’s degree in Statistics, Applied Statistics, Mathematics, or a quantitative field with concentration in mathematics, economics, or social science required; Excellent understanding of both the business and non-profit worlds and the research required in each of them;\n\nThis hands-on applied role will require between three to five years of professional experience with an aptitude for collaboration, as well as a detail-oriented mind-set coupled with the ability to define and shape research agendas;\n\nStrong analytical skills including reporting, building dashboards, segmentation, trends analysis, predictive modeling, inferential and regression analysis;\n\nStrong experience with data manipulation and visualization tools including: SAS, SQL, Tableau, SPSS, STATA;\n\nData cleaning (including missing values and analyzing patterns to detect incomplete data), integration and merging, variable construction and database management with one-time and continuous building of datasets;\n\nExperience with different types of data sets including, but not limited to, surveys (both small and large including publicly available datasets), public administrative data and proprietary administrative data spanning multiple time frames;\n\nWorking with algorithms (including R, python) and applying new and innovative ways of solving data problems with innovative solutions. Querying experience in large datasets;\n\nTraining and applied experience in infographic design and integration into data analysis and interpretation;\n\nWillingness to travel to emerging markets.\n\nFamiliarity with experimental design methodologies\n\nStrong segmentation skills (demographic, behavioral and LCA)\n\n\n\n\n\nPreferred:\n\nMaster’s degree;\nIRB CITI certification and experience with IRB protocols and applications;\nExperience requesting and translating needs of research questions to various types of IT systems and reporting functions (some experience with SQL, Java or other reporting systems a plus);\nInterest in the field of financial inclusion, including gender; and\nFluency in Spanish, Arabic, and/or French."},{"jobtitle":"Data Engineer","companyname":"Great American Insurance Group","companyid":"164044","address":"","geo":"Cincinnati, OH, US","postDate":"Oct 15 2018","views":"3","applicants":"0","employees":"1001-5000","jobDetails":[{"level":"Entry level","industry":["Computer Software","Insurance","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nBe Here. Be Great. Working for a leader in the insurance industry means opportunity for you. Great American Insurance Group, a member of American Financial Group, is a Fortune 500 company consistently recognized as a top place to work. We combine a \"small company\" culture where your ideas will be heard with \"big company\" expertise to help you succeed. With over 30 specialty property and casualty operations and a variety of financial services, there are always opportunities here to learn and grow.\n\n Great American's Predictive Analytics division is looking for a Data Engineer to join their growing and dynamic team.\n\nWork with project team and business stakeholders to determine data requirements for analysis\nAcquire and manipulate internal and external data to create clean reproducible data sets to facilitate predictive modeling\nBuild comprehensive data sets from various source systems including Hadoop, Oracle warehouses/marts, SQL Server, API’s, XLS, etc.\nWork with Information Technology to develop production solutions to bring predictive analytics to the enterprise\nResearch and evaluate new methods and tools to improve data gathering processes\nDesign and implement database structures for modeling solutions\nComplete descriptive analyses on various data sets\nResearch business unit queries regarding model outputs; this includes score shifts, missing items, reason messages, etc.\nSuperior organizational leadership skills.\nIntegrates multiple concepts across job functions with a goal of overall benefit to the organization.\nAbility to communicate, develop and leverage strategic business relationships across the organization and externally.\nRequires advanced technical and business knowledge.\nSelf-motivated team player who excels in a collaborative environment.\nContributes beyond job role and responsibilities.\nExcellent problem solving skills.\n\n\nRequired\n\nStrong SQL and database knowledge (Oracle preferred)\nUnderstanding of ETL techniques and processes\nStrong Excel knowledge/experience including Macros and VB development\nSOAP and REST web service experience testing and development\n\n\nPreferred\n\nPrevious experience in the P&C insurance industry\nReport development/design experience (Tableau / Cognos preferred)\nStrong Software Engineering practices developing enterprise applications - Java, Spring, XML, JDBC/JPA/Hibernate\nFamiliar with approximate string matching techniques (fuzzy matching)\nHadoop Development- interfacing with data stored in Hadoop environment (Familiar with technologies including: Hive, Pig, Spark, HDFS, Sqoop, Flume, HAWQ, Zeppelin)\nExperience with Informatica Data Quality Suite & Infomatica Data Integration Suite (PowerCenter)\nExperience in Linux\nExperience with R/R-Studio\nText Mining experience utilizing Python or R a plus\n\nEducation: Bachelor’s degree or higher in Information Technology, Informatics, Computer Science, Information Systems, or equivalent experience\n\n Experience: 0-6 years of relevant experience"},{"jobtitle":"Financial Data Analyst","companyname":"Inovalon","companyid":"60101","address":"","geo":"Bowie, MD, US","postDate":"Oct 15 2018","views":"1","applicants":"0","employees":"1001-5000","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Computer Software","Hospital & Health Care"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nOverview\n\nInovalon Inc., sees Financial Data Analyst for multiple openings.\n\nResponsibilities\n\nResearch, model and develop solutions to improve financial processes (including invoicing and forecasting) at the front-end of the data analytic process by performing qualitative reviews of complex billable and non-billable membership, reporting/analytic, and intervention event data, that is received by or on behalf of customers and entered into relevant databases.\nApply statistical approaches to data sources to evaluate data quality and troubleshoot data quality issues, confirming that data complies with integration specifications and conducting root cause analysis when it does not, and create reports that evaluate data integrity problems.\nDesign and recommend solutions to correct issues with data integrity and integration to improve billing, invoicing, and forecasting processes that utilize this data.\nParticipate in revenue forecasting processes for relevant products, using MS SQL Server, advanced Excel Spreadsheets, and other technical tools to perform complex data analysis on forecasted and actual data related to billable events by building predictive volume models and comparing forecasting to actual performance.\nDevelop and create dashboards using MS SQL Server and Tableau to compare actual target volume with forecasting and to present volume across multiple clients, using quantitative and metric data to create data visualizations that provide insight into product performance.\nCreate mathematical models and graphs to calculate and propose cost-saving measures and potential revenue opportunities.\nPresent the results of financial modeling and data analysis that leadership can use to gain insight and take action to improve problem areas.\nImprove approve processes related to monthly invoicing from the data side by reviewing and validating financial data and utilize technical tools to trace back and conduct root cause analysis of the data contained in the relevant databases to discover the source of data discrepancies.\nDevelop and model solutions designed to improve invoicing capability and present findings and proposed solutions to senior leadership to assist in critical decision making.\nDevelop and implement billing procedures and streamline existing billing processes, with a focus on automation, billing accuracy, transparency, and efficiency.\n\n\nQualifications\n\nMaster’s degree plus at least two years of related professional experience with quantitative statistical data analysis and modeling (particularly as it relates to finance-based data and reporting) and interactive reporting, or five years of related professional experience if in possession of a relevant bachelor’s degree.\nExperience with data science models typically used in business scenarios and data management processes (including financial data) required.\nExperience with cloud computing and online business models, algorithm development experience including knowledge of statistical and matrix processing techniques, financial data modeling, database systems, computer networks, data structures, and Portfolio Burndown also required.\nMust be able to apply operations research methodology, decision and logic design, root cause analysis, programming languages, data mining techniques, information theory methodology, graphical models, immersed visualization, distributed computing, object-oriented programming, and scalable parallel computing.\nDemonstrated experience with Microsoft technologies (including Excel, PowerPoint, Word, and Visio), data visualization and modeling technologies (including JavaScript, Tableau, SAS Enterprise, and R and related packages, SQL, SQL Server, SSRS, VSTS, Hyperion, Oracle ERP, and Agile development methodology required.\n\nInovalon provides equal employment opportunities (EEO) to all employees and applicants for employment. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, or protected veteran status and will not be discriminated against on the basis of disability.\n\nOptions\n\nApply for this job online Apply\n\n Share\n\n Refer this job to a friend Refer\n\n Sorry the Share function is not working properly at this moment. Please refresh the page and try again later.\n\n Share on your newsfeed\n\n Interested in this opportunity?\n Socialize this job opportunity to a friend, colleague, or family member:"},{"jobtitle":"PRINCIPAL DATA SCIENTIST","companyname":"Footlocker, Inc","companyid":"","address":"","geo":"Bradenton, FL, US","postDate":"Oct 15 2018","views":"","applicants":"0","employees":"","jobDetails":[{"level":"Entry level","industry":["Information Technology & Services","Computer Software","Financial Services"],"jobtype":"Full-time","function":["Engineering","Information Technology"]}],"description":"Job description\nOverview\n\nThe Principal Data Scientist leads the team in developing complete analytical solutions, mining extensive data sets for insights, building scalable data products, and enabling the overall Data Science capability at Foot Locker. This role may come from a highly specialized background such as natural language processing, machine learning, deep learning, or operations research. This individual serves as a senior team member, developing bespoke analytical applications, and applying highly specialized techniques. This role is highly versed in a broad range of analytical strategies, and can seamlessly transition between projects, data types, and problems. This role combines the above mentioned analytical skills with a proven track record of leading projects and delivering viable solutions with measurable returns. Lastly, the Principal Data Scientist is comfortable operating in an ambiguous environment where the outcome may be unclear and the future must be created.\n\nResponsibilities\n\nLeads initiatives to understand, contextualize, and solve the most challenging problems in Foot Locker’s analytical portfolio.\nAs the subject matter expert in Data Science, represents the Data team in strategic projects and executive decisions of high significance.\nDerives new data sets and values from existing and/or potential data sources.\nAccesses data from a variety of sources, including RDMS, NoSQL, or API.\nPerforms data aggregations, manipulations, and cleaning to ensure data integrity throughout the entire analytical process.\nApplies supervised and unsupervised modeling techniques to data to generate predictions and uncover patterns.\nResearches, designs, and implements Deep Learning algorithms for complex business problems.\nCreates measurement systems to continuously evaluate the performance of data products.\nDevelops hypothesis statements and applies statistical testing to determine causality and generalize observations.\nResearch, design, and implement algorithms for complex business problems.\nWorks closely with the Data Engineering teams to align core capabilities around outcomes.\nDecomposes complex problem statements into specific deliverables and requirements.\nBuilds advanced prototypes and proof-of-concepts to test emergent tools against our current processes and prospective business scenarios.\nSupports the leadership team in developing long-term goals and roadmaps.\nContinuously scans the Data Science landscape for recent developments and opportunities to ingrate new methodologies into the existing project portfolio.\nCreates presentations and delivers results to colleagues, stakeholders, external organizations, and executive leadership.\nLeads program review sessions and collaborative exercises to build the team's overall analytical capability.\nThoroughly understands Foot Locker’s retail business model and can seamlessly connect data, context, and analytical solutions.\nMentors junior team members and provides constructive critique on specific projects.\nQUALIFICATIONS\n\nAdvanced SQL skills and is comfortable operating with relational data models and structure.\nAdvanced/expert level skills with NoSQL databases and can interact with large amounts of data stored in a Hadoop environment.\nAdvance skills with accessing data via a variety of API/RESTful services.\nAdvanced/expert level programming skills in either R, Python, or similar analytical language.\nStrong knowledge of Linux and Bash. Can interact with the OS at the command line and create shell scripts to automate workflows.\nAdvanced knowledge of Apache Spark.\nStrong knowledge of cloud environments such as AWS and Azure.\nExperience with popular Deep Learning frameworks such as Tensorflow, Keras, or Caffe.\nAdvanced understanding of software development and collaboration, including experience with tools such as Git.\nExcellent written and verbal communication skills, comfortable presenting in front of large audiences.\nCan effectively and succulently decompose highly complex findings to non-technical audiences.\nExcellent data visualization skills, is able to determine the appropriate visualization for a variety of data types and create compelling stories with data.\nAn advanced understanding of supervised and unsupervised learning techniques including; variable selection, feature engineering, model generation, model diagnostics, and deployment.\nExcellent statistical skills that are grounded in a thorough understanding of testing and frequentist/Bayesian methodologies.\nA proven track record of leading successful projects and driving measurable, viable results using Data Science techniques.\n\n\nEDUCATION And/or EXPERIENCE\n\nMasters Degree or PhD. in a Data Science, Applied Mathematics, Computer Science or otherwise research-based field; 5-7 years of related experience and/or training; or equivalent combination of education and experience.\n- provided by Dice SQL, RDMS, SoSQL, API, R, Python, Linux, Bash, Apache Spark, AWS, Azure, Tensorflow, Keras, Caffe, GIT, Data Scientist, Data Engineer, Agile"},{"jobtitle":"Sr. Business Intelligence Engineer: Internationalization Metrics Platform","companyname":"Amazoncom Services Inc","companyid":"","address":"","geo":"Seattle, WA, US","postDate":"Oct 15 2018","views":"","applicants":"0","employees":"","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Computer Software","Financial Services"],"jobtype":"Internship","function":["Business Development","Sales"]}],"description":"Job description\nJob Description\n\nSr. Business Intelligence Engineer: Internationalization Metrics Platform\n\n Location: US-WA-Seattle\n\n Job ID: ******\n\n Company: : ********** Services, Inc.\n\n Position Category: Business Intelligence\n\n Company/Location (search) : Country (Full Name): : United States\n\nJob Description\n\n's long-term vision is to enable a seamless experience for all Amazon customers worldwide on any Amazon website and device, in any language and for any culture. This extends the personalization of the shopping experience by allowing our customers to define their preferred language and currency and ensure that we provide an equivalent experience for our customers in their language of preference as we do customers in the default marketplace language. Our organization's goal is to provide a framework allowing us to define and measure the quality of these experiences and accelerate language adoption across marketplaces. We believe that, by establishing a platform team and providing tools and mechanisms, we can broadly influence change across Amazon while auditing the quality of our customer experiences.\n\nWe are looking for a Business Intelligence Engineer (BIE) with strong analytical, communication and project management skills to join our team. Working closely with business stakeholders and senior leadership, you will help identify and solve complex language and currency problems, and develop metrics and reports to measure our impact on Amazon's business. In a typical day, you will work closely with the product management team, retail teams, machine-learning scientists, statisticians, software engineers, and various business groups.\n\nAbout You\n\nYou're looking for a career where you'll be able to build, to deliver, and to impress. You look at problems holistically, and thrive on the intricate complexity of designing feedback loops and ecosystems. You want to work on projects where you are implementing solutions to real problems that require creative solutions and deep understanding of the problem space.\n\n You challenge yourself and others to constantly come up with better solutions. This highly visible role requires frequent communication with senior leadership in order to help shape and deliver on the product roadmap, and requires you to nimbly switch between strategic and tactical initiatives to achieve technical, business, and customer experience goals. You'll be given the unique opportunity to own and drive initiatives across the Amazon Retail as a whole -- from algorithmic innovation, all the way down to the datasets that the back-end services consume.\n\nAbout Us Together\n\nWe're going to change the way that Amazon thinks about supporting our global customer. Along the way, we're going to face seemingly impossible problems. We're going to argue about how to solve them, and we'll work together to find a solution that is superior to each of the proposals we came in with. We'll make tough decisions, but we'll all understand why. We'll be the dream team.\n\n The ideal candidate for this space will be highly quantitative, have great judgment, strong data mining and modeling skills and is comfortable facilitating ideation and working from concept through to execution. You will have demonstrated an ability to manage and develop medium to large-scale data tables, identify requirements and build financial reporting and planning models and tools that are statistically grounded but also explainable operationally, apply technical skills allowing the models to adapt to changing attributes, optimize forecast accuracy and to better understand and mitigate model variance drivers. In addition to building data tables, modeling and technical skills, you will possess strong written and verbal communication skills, strong focus on internal customers and professional demeanor and high intellectual curiosity with ability to learn new concepts and frameworks, algorithms and technology rapidly as changes arise.\n\nSome Problem Spaces We'll Be Working On\n\nDATAMART - as we release new languages across marketplaces, our business teams will want to understand customer trends and interactions with these new marketplaces. Ideally, we want to enable our business teams to report on the various languages within a marketplace as if those languages were individual businesses. As such, we need to create a DataMart that enables all business metrics to be split by language and also enables business users to execute ad hoc queries to answer questions that we have not currently considered. As we create the DataMart, we will have to consider the scale of data that we will be handling (at the scale of Amazon's global retail business) and employ BigData techniques to aggregate and manipulate this data. We will need to design the platform to be robust and to seamlessly recover from disaster, should the need arise. Consistency and validation will be primary concerns as we understand that systems fail, specifically systems upon which we rely for signal and we need to protect our business teams from making decisions based upon incomplete information.\n\n CUSTOMER EXPERIENCE - as arbiters of the customer experience, we need to understand our customers' experience in their languages of preference. Similarly, given the scope of this initiative, it is clear that we will not be able to translate all content in a single release. As a result, it is critical that we can truly measure the customer experience as a function of our translations (both coverage and quality) throughout their journey within the Amazon marketplace. This is further complicated by the fact that our customers receive a unique experience based upon their browse history, so our method of measurement must be considerate of and support such a dynamic experience. Furthermore, in real time and with zero latency, we want to understand when the experience is broken so that we can take appropriate actions. This is going to be a challenge that may make use of the latest BigData streaming technologies to provide a real-time data and measurement pipeline.\n\n Questions?:\n\n You may already know if you're a fit, but perhaps you're worried about technology and experience requirements? Don't be - we're looking for smart, proven, engineers; if you're the right candidate, we're flexible.\n\n Amazon is an Equal Opportunity-Affirmative Action Employer - Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation\n\nBasic Qualifications\n\nBS or MS in a quantitative field such as Mathematics, Statistics, Physics, Engineering, Computer Science or Economics\nIndustry experience as a Business Intelligence Engineer or related specialty (e.g. Software Engineer, Data Engineer, and Data Scientist) with extensive professional experience and a proven track record in a role focused on understanding, manipulating, processing and extracting value from large datasets.\nExperience with statistical analysis, regression modeling and forecasting, time series analysis, data mining, financial analysis, and demand modeling\nStrong analytical skills with passions on working with structural data sets\nProficiency with TABLEAU, Microsoft Excel to include making charts, data manipulation, pivot tables, creating macros, and visual basic knowledge\nExperience processing, filtering, and presenting large quantities (100K to Millions of rows) of data\nAble to write SQL scripts for analysis and reporting (Redshift, SQL, MySQL)\nExcellent communication skills and the ability to work well in a team.\nEffective analytical, troubleshooting and problem-solving skills.\n\nAmazon is an Equal Opportunity-Affirmative Action Employer - Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation\n\nPreferred Qualifications\n\nExperience in Statistical Software such as R, SAS, SPSS, MINITAB\nAble to write SQL scripts for analysis and reporting (Redshift, SQL, MySQL)\nExperience using one or more Python, VBA, MATLAB, Java, C++ programming languages\n"},{"jobtitle":"Sr. Associate, Data Engineer, Healthcare","companyname":"KPMG US","companyid":"1079","address":"","geo":"Atlanta, GA, US","postDate":"Oct 15 2018","views":"120","applicants":"5","employees":"10001","jobDetails":[{"level":"Mid-Senior level","industry":["Management Consulting"],"jobtype":"Full-time","function":["General Business"]}],"description":"Job description\nRequisition Number: 36611 - 26\n\nDescription\n\nInnovate. Collaborate. Shine. Lighthouse – KPMG's Center of Excellence for Advanced Analytics – has both applied data science, AI, and big data architecture capabilities. Here, you'll work with a diverse team of sophisticated data and analytics professionals to explore the solutions for clients in a platform-diverse environment. This means your ability to find answers is limited only by your creativity in leveraging a vast array of techniques and tools. Be a part of a high-energy, diverse, fast-paced, and innovative culture that delivers with the agility of a tech startup and the backing of a leading global consulting firm. For you, that translates into the chance to work on a wide range of projects – covering technologies and solutions from AI to optimization – and the power to have a real impact in the business world. So, bring your creativity and pioneering spirit to KPMG Lighthouse.\n\n KPMG is currently seeking a Sr. Associate to join our KPMG Lighthouse - Center of Excellence for Advanced Analytics to work with our Healthcare team.\n\nResponsibilities\n\nRapidly prototype, develop, and optimize D&A implementations to tackle the BI/EDW/Big Data and Data Science needs for a variety of Fortune 1000 corporations and other major organizations\nDesign, develop and maintain D&A solutions on premise/cloud/KPMG-hosted/hybrid infrastructure; Be the team champion of some mainstream BI/EDW/Big Data toolsets like Tableau, Alteryx, Informatica, Pentaho, Er-Win, and Power Designer\nPlay the role of data owner in cross-disciplinary teams; Build logical/physical data models; Discover, profile, acquire, process, model and own data for the solutions\nImplement data processing pipelines, data mining/science algorithms, and visualization engineering to help clients distill insights from rich data sources, including social media, news, internal/external documents, emails, financial data, client data and operational data\nActively be involved in research and experiment of leading/emerging BI/EDW/Big Data methodologies such as serverless data lake, AWS Redshift, Athena, Glue, GCP BigQuery, and MS PowerBI and apply them to real client solutions\nBe the data engineering SME in the process for pursuing innovations, target solutions, and extendable platforms for Lighthouse, KPMG and client\n\n\nQualifications\n\nMinimum of three years of relevant data engineering experience in related industries, preferably professional services; Experience and knowledge of RDBMS design, data modeling, MPP EDW system implementation; Have completed two plus production BI/EDW/Big data projects with the ability to communicate complex technical concepts to non-technical personals at all levels; Proficiency with healthcare analytics and data structures\nBachelor's Degree, Master's Degree or PhD from an accredited college/ university in Computer Science, Computer Engineering or related field\nHands-on experience and knowledge in: BI/EDW/Big Data toolsets (Tableau, Alteryx, Informatica, Pentaho, Er-Win, Power Designer); Mainstream cloud infrastructures (AWS, MS Azure and GCP; their D&A-related Microservices); Implementing data lake and serverless data lake; Proficient-level fluency of SQL\nHands-on experience of Linux/Unix/Windows/.NET; Market-leading fluency in several programming languages: Bash/ksh/PowerShell; Python/Perl/R; Ability to pick up and learn new technologies quickly\nHands-on experience and knowledge in distributed computing architecture, massive-parallel processing big data platforms like Hadoop, MapReduce, HDFS, Spark, Hive/Impala, H-Base/MongoDB/Casandra and Teradata/Netezza/Redshift\nAbility to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future\n\nKPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package. KPMG is an affirmative action-equal opportunity employer. KPMG complies with all applicable federal, state and local laws regarding recruitment and hiring. All qualified applicants are considered for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other category protected by applicable federal, state or local laws. The attached link contains further information regarding the firm's compliance with federal, state and local recruitment and hiring laws. No phone calls or agencies please."},{"jobtitle":"Manager Modeling & Data Analysis (Marketing Analytics) - Omaha, NE","companyname":"Mutual of Omaha","companyid":"","address":"","geo":"Blair, NE, US","postDate":"Oct 13 2018","views":"7","applicants":"0","employees":"","jobDetails":[{"level":"Entry level","industry":["Banking","Insurance","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nThe Manager Modeling and Data Analysis is responsible for driving top line growth by leading development of targeting and segmentation solutions to improve effectiveness of acquisition and early months on book marketing campaigns while interacting with business stakeholders across the organization to promote usage of advanced analytical solutions.\n\nEssential Job Functions\n\nDrive top line growth by leading development of targeting and segmentation solutions to improve effectiveness of acquisition and early months on book marketing campaigns\nInteract with business stakeholders across the organization to promote usage of advanced analytical solutions\nExplore new modeling tools and techniques and develop new solutions to add value to Mutual of Omaha\nManage all aspects of model development process, including model initiation, model design, model documentation and ongoing performance monitoring\nPerform ad hoc analysis to support internal audit requests\nDevelop strong partnership with multiple internal stakeholders, including targeting, model governance teams and Legal and Compliance\nPerform other duties and/or special projects as assigned\nBe a thought leader in driving rigor in all analytical efforts in support of Direct to Consumer campaigns including targeting, segmentation and testing\nPartner with peers to optimize the performance of the Direct to Consumer channel by testing and synthesizing key learnings around prospecting, mail frequency, cadence etc\nLead a team of Analysts to accomplish team goals\n\nMinimum Qualifications\n\n5\nyears of experience as a data analyst of which 2\nyears of experience in predictive model development, preferably in marketing or risk\n3\nyear proven data mining and/or applicable programming skills with SAS, SQL, R, Python or other comparable languages\nBachelor's degree in Statistics\nExperienced in operationalizing targeting models\nRobust understanding of statistical techniques and their application in business\nComfortable with data extraction, data manipulation, synthesis and creating presentations\nPrior experience with analytical initiatives with demonstrated ability to problem solve and think critically\nability to recognize key leverage points in an analysis\nAbility to lead and motivate a team, strive for excellence and hold a high bar\nSelf-motivated and driven with an acute sense of ownership * Be a team player\n\nPreferred Qualifications\n\nHands on modeling experience\nExperience with Big Data tools (Hadoop, Spark etc.)\nPrior experience managing a team\n\nIf you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at 1-800-780-0304. We are available Monday through Friday 7 am to 4:30 pm CST.\n For all other inquiries, contact our HR Helpline at 1-800-365-1405, option 4.\n Mutual of Omaha and its affiliates are an Equal Opportunity /Affirmative Action Employer, Minorities/Female/Disabled/Veteran\n To All Recruitment Agencies: We do not accept unsolicited agency resumes and we are not responsible for any fees related to unsolicited resumes."},{"jobtitle":"Data Analyst","companyname":"Women's World Banking","companyid":"","address":"","geo":"New York City, NY, US","postDate":"Oct 13 2018","views":"11","applicants":"6","employees":"","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Business Supplies & Equipment","Consumer Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nTitle**:Data Analyst\nReports to**:Research Director\nClassification**: Exempt\nLocation**: New York\nStart Date**: Immediately\nSummary**:\n\nThe Data Analyst will work directly with internal and external stakeholders as well as data providers, leveraging advanced statistical techniques to drive strategic thought and effective decision making in addition to collect and analyzing data an information about customers, markets and the business environment in countries in Africa, Asia, and Latin America.\n The Analyst also supports all aspects of analytic initiatives from conception to completion, through the development of clear and well-structured analytical plans, and ability to analyze large and complex data-sets. This role will serve in shaping Women’s World Banking business’s data infrastructure, inclusive of data-warehousing, reporting, modeling, and analytics platforms, as well as supporting a variety of data insights and data reporting needs, including, but not limited to, customer segmentation analysis and look-alike modeling, use case development and validation, cross-country trend analysis, and data visualization.\n\nResponsibilities**:\nServe as primary resource for supporting measurement and data analysis needs including: integration of multiple large datasets for ongoing data analysis and mining; data cleaning and variable development; quality control; data segmentation design; programming and analysis. Build and manage large and complex (multi-source and multi-stream) datasets with internal platforms and resources;\nWork with research team to support Women’s World Banking project objectives and develop datasets and analysis that provide the most accurate and comprehensive picture;\nServe as key team member in development of predictive analytics methodologies and models for use in ongoing applied research projects;\nDevelop and implement analytical strategies through a range of quantitative research methods to provide data driven insights that support iterative development of the research project;\n‪Work as a member of the research team to recommend the best analytic approaches and set the standard of excellence for conducting, packaging, and reporting on frequently used analyses and datasets;\nConduct a range of statistical tests on datasets to understand aspects of client and organization patterns and relationships including descriptive statistics, segmentation analysis of patterns and trends, inferential statistics and experimental and quasi-experimental tests of difference and relationships;\n‪Assess the methodologies, data quality and synergies across various third-party data sets and develop strategic recommendations on behalf of the research team;\nDemonstrated ability to “tell the story” with data at the executive, manager, and team levels using charts and other data visualizations that are clear and easy to understand for any interested layperson.\n\n\nWithin The First 75 Days\n\n\nAssume full responsibility of the position;\nEmbrace Women’s World Banking’s core values and desired behaviors;\nForge positive working relationships with cross-functional staff;\nEmbrace Women’s World Banking’s unique characteristics and offerings;\nLearn and comprehend the Women’s World Banking business model;\nBecome trained in and fully integrate the use of Women’s World Banking systems and policies into your day-to-day activities;\nDevelop a road map to achieve targets and deliverables for the year.\nRequired Qualifications**:\nBachelor’s degree in Statistics, Applied Statistics, Mathematics, or a quantitative field with concentration in mathematics, economics, or social science required; Excellent understanding of both the business and non-profit worlds and the research required in each of them;\nThis hands-on applied role will require between three to five years of professional experience with an aptitude for collaboration, as well as a detail-oriented mind-set coupled with the ability to define and shape research agendas;\nStrong analytical skills including reporting, building dashboards, segmentation, trends analysis, predictive modeling, inferential and regression analysis;\nStrong experience with data manipulation and visualization tools including: SAS, SQL, Tableau, SPSS, STATA;\nData cleaning (including missing values and analyzing patterns to detect incomplete data), integration and merging, variable construction and database management with one-time and continuous building of datasets;\nExperience with different types of data sets including, but not limited to, surveys (both small and large including publicly available datasets), public administrative data and proprietary administrative data spanning multiple time frames;\nWorking with algorithms (including R, python) and applying new and innovative ways of solving data problems with innovative solutions. Querying experience in large datasets;\nTraining and applied experience in infographic de"},{"jobtitle":"Credit Data Engineer","companyname":"Barclays","companyid":"1426","address":"","geo":"New York City, NY, US","postDate":"Oct 13 2018","views":"4","applicants":"1","employees":"10001","jobDetails":[{"level":"","industry":["Banking","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nBarclays Overview\n\nBarclays is an international financial services provider engaged in personal banking, credit cards, corporate and investment banking and wealth management with an extensive presence in Europe, the Americas, Africa and Asia. Barclays’ purpose is to help people achieve their ambitions – in the right way. With over 300 years of history and expertise in banking, Barclays operates in over 50 countries and employs approximately 135,000 people. Barclays moves, lends, invests and protects money for customers and clients worldwide.\n\n For further information about Barclays, please visit our website www.barclays.com.\n\n Barclays offers investment banking products and services in the US through Barclays Capital Inc.\n\nBarclays Values and Diversity\n\nOur common purpose is to help people achieve their ambitions – in the right way. We’ll measure and reward our people, not just on commercial results, but on how they live our Values of Respect, Integrity, Service, Excellence and Stewardship and bring them to life every day. To find out more about working at Barclays and the development opportunities we offer please visit our website www.barclays.com\n\n We are an equal opportunity employer and we are opposed to discrimination on any grounds.\n\nEEO Statement\n\nIt is the policy of Barclays to ensure equal employment opportunity without discrimination or harassment on the basis of race, color, creed, religion, national origin, alienage or citizenship status, age, sex, sexual orientation, gender identity or expression, marital or domestic/civil partnership status, disability, veteran status, genetic information, or any other basis protected by law.\n\nRisk and Control Objective\n\nAll Barclays colleagues have to ensure that all activities and duties are carried out in full compliance with regulatory requirements, Enterprise Wide Risk Management Framework and internal Barclays Policies and Policy Standards\n\nMain Duties And Responsibilities\n\nThe position will be utilized to create data science capability for AI / Machine Learning / Data Mining projects for the markets business for the Credit asset class. Successful candidate will be in charge for the creation and maintenance of a centralized modelling layer to facilitate machine learning studies. The candidate will also work closely with team of IT developers to create and maintain the underlying storage, exploration and visualization layer in the data science platform.\n\n Successful candidate will be involved with creation of the following components of data science platform:\n\nMarket Making Activity: Assist in creation of pricing and hedging algorithms as part of Barclays market making activity.\nModelling layer: including feature engineering interface, feature engineering library, model scoring engine, model training library and the model storage layer\nData exploration API : build tools to allow efficient data summary statistics and graphs\nVisualization layer: build a relevant visualization layer that can allow the sharing of modelling output to other front office personnel.\n\nBasic Qualifications\n\nPhD, Master’s or Bachelors degree in Computer Science, software engineering, machine learning, data mining or big data analytics\n2 to 3 years of relevant work experience in building environments for big data analytics\nExperience in working with Linux, SQL, Python, Scala and JAVA\nExperience with Apache Spark, Hadoop, Impala, Jupyter notebooks\nExperience with big data analysis & visualization\nSuperior verbal and written communication skills\n\nPreferred Qualifications\n\nFollow & promote best practices for engineering & data science\nPOC and/or benchmark Technologies/Tools to choose the most appropriate one\nStay in front of current technical tools available in big data analytics\n\nPrimary Location\n\nUS-New York-745 Seventh Avenue, New York, NY\n\nJob Type\n\nPermanent/Regular\n\nPosting Range\n\n30 Aug 2018"},{"jobtitle":"Senior Data Analyst","companyname":"Stanford University","companyid":"","address":"","geo":"Stanford, CA, US","postDate":"Oct 13 2018","views":"20","applicants":"0","employees":"","jobDetails":[{"level":"Associate","industry":["Non-profit Organization Management","Financial Services","Hospital & Health Care"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nSenior Data Analyst\n School of Humanities and Sciences, California, United States\n Information Analytics\n Jun 14, 2018Post Date\n 79398Requisition #\n Apply for Job\n Share this Job\n Sign Up for Job Alerts\n The College Transition Collaborative (CTC), based out of the Department of Psychology at Stanford University, aims to create higher education learning environments that foster equitable student outcomes by bridging research and practice. CTC partners with colleges and universities to develop scientifically proven approaches that place the student experience at the center of institutional programs and practices. Our work helps institutions better understand how their students experience moments of transition or difficulty, and how psychologically-informed practices can convey to all students they are valued, respected, and can excel. CTC’s work has helped support greater engagement, retention, and completion for students at diverse colleges and universities across the United States, particularly for traditionally marginalized groups such as students of color, first-generation students, and low-income students. To learn more, please visit our website at rg.\n We are seeking a Senior Data Analyst to lead data processing and analysis for multiple ongoing large-scale randomized controlled experiments. The Analyst will oversee all stages of the data pipeline, from standardizing disparate raw data sources (e.g., survey data, institution provided data, etc.) containing millions of records to conducting complex analyses for both scientific and practitioner audiences. This individual will be an essential project member who will be expected to learn and work independently, yet collaborate effectively with team members and project partners. Previous experience processing data and conducting analyses for empirical research projects, particularly projects with a focus on social psychology or education, in an academic environment is a plus. The work will take place in a dynamic environment where specifications often change rapidly in response to demands from both researchers and practitioners, so the analyst must be able to be flexible in their approach and implementations.\n\nAdditional Details About The Responsibilities\n\nProcessing and managing data\nImplement processes to collect, process, and manage raw data from diverse sources (e.g., complex surveys, institutional records from multiple sources and timepoints), producing clean and user-friendly datasets for both internal analysis needs and sharing with affiliates and collaborators.\nCreate clear, standard data requests in collaboration with researchers and fellow CTC staff to share with school partners based on project research questions\nwork closely with fellow CTC staff and data teams at partner institutions to validate accuracy and usability of data shared, including training CTC staff to understand data request specifications and to perform relevant checks.\nAdvise on and implement data storage and security practices.\nAnalyzing data\nCollaborate with researchers and fellow CTC staff to determine analytic approach for projects in light of key research questions, modifying approach as necessary given nuances of data that are available (e.g., limitations in institution-provided data, etc.), and to pre-register analysis plans when appropriate.\nUse both qualitative and quantitative techniques to lead data analysis for all stages of CTC’s research projects, including both earlier stage research and development such as surveys, focus groups, and smaller scale experiments, and later stage large-scale field tests such as randomized controlled trials. Analytic techniques may include but are not limited to: multilevel models, OLS models, structural equation models, clustering techniques, and specification curves/permutation tests.\nServe as a resource for non-routine analysis inquiries.\nReporting results\nWork under consultative or self-initiated direction to report analysis findings for researchers, school partners, and external audiences.\nDevelop processes and write/modify reproducible scripts to automate custom report generation.\nWrite concise, focused prose interpretation of analysis findings for diverse internal and external audiences, varying the language used and level of detail depending on audience background and interests.\nDistribute and disseminate reports to applicable agencies, researchers, management and other internal end-users.\n\nCTC is an early-stage organization, and we are excited to build out our data processes and team over the coming years. This role includes the opportunity to drive decision-making around our data policies and infrastructure in addition to conducting data processing and analyses for discrete large-scale projects.\n To be considered for this position, you must fill out this form: l/forms/qiowL5fh1G6CJUsG3\n\nCore Duties\n\nWork under consultative or self-initiated direction to assess and produce relevant, standard, or custom information (reports, charts, graphs and tables) from structured data sources by querying data repositories and generating the associated information. Distribute and disseminate reports to applicable agencies, researchers, management and other internal end-users.\nDevise methods for identifying data patterns, trends in available information sources using a variety of qualitative and quantitative techniques. Determine and recommend additional data collection and reporting requirements.\nCreate non-routine databases and their related information summary\ndevelop algorithms and statistical model\nand perform statistical analyses appropriate to complex data and reporting requirements.\n- Other duties may also be assigned\n\nMinimum Requirements\n\nEducation & Experience:\n\n Bachelor's degree and three years of relevant experience or combination of education and relevant experience. Experience in a quantitative discipline such as economics, finance, statistics or engineering.\n\nKnowledge, Skills And Abilities\n\nIn-depth knowledge and experience using and applying analytical software, database management system software, database reporting software, database user interface and query software, and data mining software.\nExpert ability to collect data using a variety of methods, such as data mining and hardcopy or electronic documentation study, to improve or expand databases.\nBasic statistical ability.\nStrong listening, verbal and written communication skills.\nAbility to manage multiple activities in a deadline-oriented environment\nhighly organized, flexible and rigorous attention to detail.\nAbility to use logic to calculate data\nefficiently construct a database or scrutinize the form of a question.\nAbility to work with data of varying levels of quality and validity.\nDemonstrated ability to produce data in a clear and understandable manner meeting user requirements.\nAbility to work effectively with multiple internal and external customers.\nAbility to take a leadership role on projects and with users/clients.\n\nPreferred Knowledge, Skills, And Abilities\n\nSubstantial experience in at least one statistical programming language allowing for reproducible, automated analysis and reporting\ne.g., R, Stata, Python.\nSubstantial experience with advanced statistical methods used in social science research to assess the impact of multi-site experiments controlling for relevant covariates, including conducting exploratory analyses to determine optimal modeling approaches\nconducting complex analyses such as multilevel modeling\nunderstanding and addressing problems such as model fit issues and/or problematic statistics that may indicate errors in the underlying data\nand advising team members on best practices around data collection, management, analysis, and reporting.\nExperience and comfort managing complex raw data from disparate sources.\nComfort with early-stage and academic work environments.\nStrong analytical skills.\nAbility to prioritize workload across multiple projects, create realistic timelines for analytic workstreams, and communicate regular updates to team.\n\nCertificates And Licenses Required\n\nNone\n\nPhysical Requirements\n\nConstantly perform desk-based computer tasks.\nFrequently sit, sort, file paperwork or parts, grasp lightly, and use fine manipulation, lift, carry, push and pull objects that weigh 10 pounds or less.\nOccasionally write by hand, twist, bend, stoop and squat.\nRarely stand, walk, reach or work above shoulders and use a telephone.\n- Consistent with its obligations under the law, the University will provide reasonable accommodation to any employee with a disability who requires accommodation to perform the essential functions of the job.\n\nWorking Conditions\n\nMay work extended hours during peak business cycles.\n\nWork Standards\n\nInterpersonal Skills: Demonstrates the ability to work well with Stanford colleagues and clients and with external organizations.\nPromote Culture of Safety: Demonstrates commitment to personal responsibility and value for safety\ncommunicates safety concerns\nuses and promotes safe behaviors based on training and lessons learned.\nSubject to and expected to comply with all applicable University policies and procedures, including but not limited to the personnel policies and other policies found in the University’s Administrative Guide, tanford.edu.\n"},{"jobtitle":"Data Analyst - Retail Operations","companyname":"Carters/OshKosh","companyid":"","address":"","geo":"Atlanta, GA, US","postDate":"Oct 13 2018","views":"9","applicants":"1","employees":"","jobDetails":[{"level":"Associate","industry":["Accounting"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\n# Data Analyst \\- Retail Operations\n\n\nAtlanta,\n\n\nGA**\n\n\nDate Updated:** November 01, 2018\nJob Level:** Mid Career \\(2\\+ years\\)\nJob Type:** Full\\-Time/Regular\nYears of Experience:** 2 \\- 5 Years\nTravel:** Not Specified\nLevel of Education:** BA/BS\nPosition ID:** 85329\\-274869\n\n\n## Job Description\n\n Carter's, Inc\\. is the largest branded marketer in North America of apparel exclusively for babies and young children\\. The Company owns the _Carter's_ and _OshKosh B'gosh_ brands, two of the most recognized brands in the marketplace\\. These brands are sold in leading department stores, national chains, and specialty retailers domestically and internationally\\. They are also sold through more than 1,000 Company\\-operated stores in the United States, Canada, and Mexico and online at www\\.carters\\.com , www\\.oshkoshbgosh\\.com , and www\\.cartersoshkosh\\.ca \\. The Company's _Just One You_ and _Genuine Kids_ brands are available at Target, its _Child of Mine_ brand is available at Walmart, and its _Simple Joys_ brand is available on Amazon\\. The Company also owns _Skip Hop_ , a global lifestyle brand for families with young children\\. Carter's is headquartered in Atlanta, Georgia\\. Additional information may be found at www\\.carters\\.com \\.\n\n Responsible for strategic and analytical support of Workforce Management and cross\\-functional initiatives, including labor deployment, forecasting, payroll distribution, and in\\-store technology\\.\n\n\nDevelop advanced analytics and visualization tools to optimize the WFM application for increased sales, potential costs savings while providing a best\\-in\\-class customer experience\\.\n\n\nExample analyses include Dynamic Field performance, Cost / Benefit, Store Payroll impact, Forecasting sales, Revenue $, Gross Margin $ and % Impact, etc + Utilize data for developing standardized reporting to provide comprehensive analytics into field performance from our current labor model\\.\n\n Provide insight and direction into changes needed to drive increased customer satisfaction + Partner with various departments that drive workload within the store to collect data inputs to our labor model\\.\n\n Develop standardized reporting to provide comprehensive visibility into performance to our current labor model\\. + Drive growth and customer satisfaction\\.\n\n Evaluate and contribute to store training for building business acumen and analyzing in\\-store KPIs \\(e\\.g\\. CTS, Conversion, AT\\), as well as initiatives to incentivize store teams + Analyze data surrounding new technologies to provide insight and store\\-level perspective to business leaders + Be a champion for change management\\.\n\n Communication of past, current, and future expectations for the field is critical within the projects and initiatives of the organization + Drive growth and customer satisfaction\\.\n\n Evaluate and contribute to store training for building business acumen and analyzing in\\-store KPIs \\(e\\.g\\. CTS, Conversion, AT\\), as well as initiatives to incentivize store teams + Provide ongoing and ad hoc analytical support to the Retail Senior Leadership Team + Support Store Operations needs to the business accordingly with current processes and procedures\\. + Communication with external clients regarding store systems, including defect identification and issue resolution + Communicate with store and field leadership as needed to gather data to meet project research goals + Presentation skills needed to review analytics with various business partners\n\n ## Experience and Skills\n\n\nBachelors degree in Business, Finance, Economics or a related field\n3\\\nyears combined experience with Proficiency in advanced analytics and visualization tools preferred \\(SQL, Python, R\\)\nExcellent verbal and written communication skills\\.\n\n\nPossess a collaborative approach to problem\\-solving + Excellent organizational and leadership skills, as well as strong customer focus and with strong ability to deal with ambiguity + Detail\\-oriented, flexible, and able to work well under pressure in a fast paced environment + Ability to be accurate with details, facts and supporting data\\. Ability to review data analysis, quantify results and recommend appropriate action based upon conclusions\\. + Computer proficiency: Microsoft Office with a very strong skillset with Excel\n\n Carters is committed to creating a diverse environment and is proud to be an equal opportunity employer\\. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity, sexual orientation, national origin, genetics, disability, age, veteran status, or any other status protected by federal, state, or local law\\.\n\n Visit http://carters\\.submit4jobs\\.com/ today"},{"jobtitle":"Sr. Healthcare Data Analyst, Payformance Solutions","companyname":"Altarum","companyid":"19146","address":"","geo":"Chicago, IL, US","postDate":"Oct 13 2018","views":"13","applicants":"4","employees":"201-500","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Computer Software","Hospital & Health Care"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nPosition: Sr. Healthcare Data Analyst, Payformance Solutions\n\n Office: Chicago, IL\n\nWhy We’re Excited To Get To Work\n\nThe mission for Payformance Solutions is simple. We aim to be a catalyst for payment transformation in the healthcare industry. Our proprietary software solutions allow payers and providers to focus on what really matters: providing patients with access to care that yields the best health outcomes, at the lowest costs.\n\n The healthcare industry is complex and fragmented. Payers and providers are faced with a lack of transparency and conflicting financial goals that fail to consider the health outcomes of patients. Payformance Solutions offers data-driven, turnkey software solutions that provide payers and providers with the technical tools and resources needed to design, evaluate, build, measure, and negotiate value-based reimbursement contracts — as a neutral third party. Our holistic solutions allow payers and providers to collaborate in an ecosystem that aligns financial goals with patient outcomes.\n\nWhat We Are Looking For\n\nOur team needs hands-on analysts who can work with healthcare claims data to generate insights to help solve complex healthcare transformations facing payers and providers. If you have a background in healthcare, specifically payer/provider contracting, a desire to work on some of the most significant and challenging initiatives facing the industry, and love to push the boundaries to solve complex business problems innovatively, then we want to talk with you. As an Analyst at Payformance Solutions, you will have the opportunity to make mission critical contributions. You’ll have a voice in driving the direction and strategy of the company, and work in an agile environment alongside a rapidly growing team of Engineers, Data Architects, Analysts, and Health Policy Experts in our Chicago, IL office.\nPosition is based in Chicago\n\n\n\nWhat You’ll Do\n\nAnalyze and model structured data, implementing algorithms to support data analysis using advanced mathematical methods from statistics, data mining, econometrics, and operations research\nPerform exploratory data analysis, generate and test working hypotheses, and uncover interesting trends and relationships\nSupporting senior staff and project teams to analyze healthcare claims data, develop comparative rate and reimbursement analysis, cost analysis and financial impact calculations, and national or regional market studies dusing statistical software.\nPresenting insights and findings to senior leadership, external clients, and industry experts as required, through the use of graphs, tables, and other strategic information to summarize analyses and results.\nAnalyze and document business processes, workflows and use cases for alternative payment models (e.g., value-based)\nWork with technical staff to translate business requirements into functional requirements and specifications\nPlan and facilitate functional design sessions\nDevelop testing, validation and implementation plans and processes\nCreate and maintain system design and operational procedure documentation\nProvide guidance and feedback to more junior team members\nContributing to an innovative and team-oriented work environment with individual accountability and ownership to the success of the company\n\n\n\nWhat You’ll Bring To The Table\n\nMasters or PhD degree in relevant disciplines: Bioinformatics, Medical Informatics, Healthcare Administration, Statistics, Applied Mathematics, Operations Research/ Optimization, Computer Science, Computational/ Theoretical Physics, Data Science, or Electrical/ Computer Engineering.\nAbility to recognize payment trends and methodologies, in addition to identifying the big picture perspective within payer and provider environments.\nExperience working with healthcare claim codes (e.g., ICD9, ICD10, HCPCS, CPT)\nDeep experience in extracting, cleaning, preparing and modeling data\nProficient in the big data ecosystem such Hadoop, Spark, and Storm and programming languages (e.g. Python, Ruby, Java, Scala)\nExperience supporting big data analytics projects, developing and documenting methodologies, validating results, coordinating efforts to meet deadlines for deliverables, and completing quality assurance checks.\nCapability to succeed in a dynamic environment and produce multiple deliverables within tight timeframes.\nWillingness to effectively build relationships throughout the organization and communicate with team members virtually and in-person.\nProven ability to interact directly with clients and effectively understand needs while managing expectations\nProven ability to effectively communicate with both technical and non-technical team members\nProven ability to effectively work both independently and within a team\n\n\n\nHow We’ll Support You\n\nIn addition to the meaningful and challenging work, Payformance’s dynamic work environment emphasizes integrity, personal commitment, and teamwork. We offer an outstanding benefits program that includes:\n\nA competitive annual salary\n100% employer-paid medical option (employee, spouse, family)\n100% employer-paid life insurance policy\n100% employer-paid short-term and long-term disability insurance\n401k Retirement Plan (5% employer contribution)\nHealthy work/life balance… Our flexible office hours and time-off allows you to make the most of your time in and out of the office to fit your needs. Plus, an optional work-from-home day once a week (after 3 months)\nPaid maternity leave\nTuition reimbursement\nAnnual personal learning budget (books, conferences, etc.)\nThirsty Thursday team building events\nFree gym Access\nAwesome coworkers\nWork with a highly collaborative and values-driven team\n\n\n\nNot To Boast, But a Little Bit About Us\n\nPayformance Solutions is a health-tech company dedicated to advancing payment transformation in the healthcare industry. We are a wholly owned subsidiary of Altarum Institute, a nonprofit systems research and consulting organization that has been servicing government and private sector clients since 1946.\n\n Altarum Institute combines the analytical rigor of a research institution with the business agility of a consulting firm, the Institute is uniquely positioned to deliver practical, systems-based health and healthcare solutions to its clients. Altarum’s nonprofit status ensures that the public interest is always preeminent in our work. Our dedication to social responsibility is evident in all that we do, serving the public good with integrity and enabling others to do the same. Altarum develops and promote best practices in the application of information technology to health and health care. Applying systems research principles and analytic objectivity, we work to increase access to health information; improve the organization and usability of health information; and develop new knowledge from health information. We work to achieve these goals by addressing all aspects of information technology —policy and planning efforts, system design and development, information exchange, and the management and evaluation of specific information technology and strategies.\n\n At Payformance, we don’t just accept difference - we celebrate, support, and thrive on it for the benefit of our employees, our clients, and our community. Payformance Solutions is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to, among other things, race, color, religion, sex, sexual orientation, gender identity, national origin, age, marital status, status as a protected veteran, or disability.\n\n To all recruitment agencies: Payformance does not accept agency resumes, we are not responsible for any fees related to unsolicited resumes.\n\n External Company URL: http://www.altarum.org"},{"jobtitle":"Data Analyst 3","companyname":"Mitchell International","companyid":"165006","address":"","geo":"Salt Lake City, UT, US","postDate":"Oct 13 2018","views":"10","applicants":"2","employees":"1001-5000","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Computer Software","Hospital & Health Care"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nMitchell International, Inc. is a leading provider of information and workflow solutions to the Property & Casualty Claims Industry and their supply chain partners. We solve interesting and complex problems that directly affect the customers our clients serve. We are constantly adapting to stay on the forefront of emerging technologies and we work diligently to maintain our position as a thought leader within our industry.\n\n Mitchell’s Pharmacy Solutions division provides critical Pharmacy Benefit Management solutions to hundreds of workers’ compensation and auto insurance carriers, administrators and employers in the United States, as well as connects with over 65,000 pharmacies to provide injured patients with access to prescription medicines. Our mission is to provide our customers with better claim outcomes and help patients restore their lives after a workplace or automobile accident. Mitchell’s Salt Lake City office includes over 200 associates who work directly with pharmacies and payers to process over 1 million pharmacy transactions each year. Mitchell is the fastest growing pharmacy solutions provider to the U.S. property and casualty industry and is rapidly growing its Salt Lake City office location. The company offers a competitive compensation and benefits package including health insurance, 401(k), disability protection and tuition reimbursement. Our associates enjoy excellent career growth opportunities in a collaborative and engaging professional office environment that includes an onsite gym, full cafeteria and available on-site day care for children.\n\n\nThis position is not eligible for immigration sponsorship now or in the future*\n\n We are looking for a Data Analyst who can jump in and make an impact quickly in our Pharmacy Solutions Group. Data Analysts can be expected to use statistics, trend analysis and predictive modeling to identify key trends and forecast outcomes in our business and communicate those across cross-functional audiences for improved decision making. You will play an integral role in helping guide the best course of strategic action through a focus on data-driven decisions. This position interacts with the highest levels of management within our organization.\n\nDuties And Skills\n\nWork with the operations team members to further develop metrics, KPIs, and reports that drive enhanced operational rigor and performance improvement\nData-savvy with analytical mind and talent for attention to detail\nExcellent problem solving skills\nStrong work ethic, hard worker, good team player and highly motivated\nQuickly and accurately complete projects that require data mining, analysis, and presentation\nConvert data requests from non-technical stakeholders into actionable data set queries\nCreate and maintain templates for recurring reporting\nEffectively communicate and interact with individuals at all levels of the organization\n\n\nQualifications\n\nMinimum of five (5) years of data analytics experience\nBachelor’s Degree in Computer Science, Information Systems or equivalent technical certifications\nProficient grammar, sentence structure and written communication skills\nExpert knowledge of SQL, Excel and the ability to model and draw inferences from data\nExperience with common types of data analysis tools (ex. R, SAS, SPSS, Python, STATA.etc)\nWorking knowledge of Tableau is a plus\nAbility to multi-task and work on multiple projects\nSelf-starter: Must be productive with minimal direction\nAbility to work in a fast-paced, technical, cross-functional environment\nExcellent visual design sense regarding clear and accurate presentation of data"},{"jobtitle":"Senior Data Engineer (Azure Cloud)","companyname":"East West Bank","companyid":"","address":"","geo":"Palo Alto, CA, US","postDate":"Oct 13 2018","views":"","applicants":"0","employees":"","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Banking","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nCompany Overview\n\nFor more than 40 years, East West Bank has served as a pathway to success. With over 130 locations across the U.S. and Greater China, we are the premier financial bridge between the East and West. Our teams of experienced, multi-cultural professionals help guide businesses and community members on both sides of the Pacific looking to explore new markets and create new opportunities. And our sustained growth and expertise in industries like real estate, entertainment and media, private equity and venture capital, high-tech and aviation help build sustainable businesses and expand our employees’ potential for career advancement.\n\n Headquartered in California, East West Bank (NASDAQ: EWBC) is a top performing commercial bank with an exclusive focus on the U.S. and Greater China markets. With assets of $37.7 billion, we’re ranked among the 30 largest banks in the United States and currently top 5 in “America’s 100 Best Banks” by Forbes, a list where we've consistently been in the top 15 since 2010. With a strong foundation, an enterprising spirit and a commitment to absolute integrity, East West Bank gives people the confidence to reach further.\n\nJob Summary\n\nEast West Bank is looking for a motivated Data Scientists to contribute towards the success of our Data and Analytics Technology initiatives. This person will be experienced in different machine learning, deep learning and AI algorithms and work on data mining and statistical modelling for predictive and prescriptive analytics and generating actionable insights. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire diverse set of data, design, develop, deploy and interpret models and outcomes.\n\nResponsibilities\n\nImplement techniques to acquire, discover and explore data for analytics\nIdentify use cases and implement statistical modelling, machine learning, deep learning and AI capabilities to create data-driven user experiences\nPOC / POV and prototyping data and analytics solutions and derive viability\nEnsure data quality, integrity, security and completeness throughout the data lifecycle\nDefine data validation strategies, pre-processing and feature engineering strategies\nTest/train and fine tune models and deployment of models in production\nWork with business stakeholders to understand requirements and business use cases and translating data into metrics, KPI, and solutions\nDevelop deep understanding of the data sources, implement data standards, maintain data quality and master data management\nDesign and develop data services and API\nMentor, coach, train data engineers and analysts\n\n\nRequirements\n\nStrong Machine learning, deep learning experience especially in banking and financial sector with hands-on development using technology stack including Python, R, Spark and Hadoop\nExperienced in analyzing large quantities of data in cloud platform like AWS or Azure eco-system. (Azure preferred)\nExposure and deep understanding of supervised and unsupervised machine learning algorithms, logistic regression, random forest, SVM, KNN and other analysis.\nSolid understanding of python libraries for machine learning such as scikit-learn, pandas, numpy and deep learning frameworks such as tenserflow, keras etc…\nStrong experience and exposure in classification, clustering, segmentation, targeted recommendations and managing customer behavior data\nHandling large internal and external data including social media and other 3rd party datasets to derive valuable insights\nNoSQL Databases and Big data technologies including Hadoop, MongoDB, and Azure CosmosDB\nExperience with API / RESTful data services\nWorked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Streaming Analytics\nExperience working with different data storage options including AWS S3, Azure BLOB storage etc.\nUnderstanding of different data formats including Parquet, Avro, CSV, ORC etc.\nPrior experience with MPP databases and maintain large amount of data processing\nExperience with Azure Data Factory and Azure Data Catalog is a big plus but not mandatory\nExperience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big plus but not mandatory\nPast working experience on a fast paced and agile environment\nAbility to review architecture design and provide direction on system capabilities\nPerform ongoing monitoring, automation and refinement of data engineering solutions\nExperience in leading high visibility projects that interacts with multiple business lines\nExperience working with an on-shore / off-shore model\nBuild and meet project timelines and manage delivery commitments with proper communication to management\nCollaborate and communicate with key business lines, technology partners, vendors and architects\n\n\nQualifications\n\nMS degree with 8+ years of relevant experience in Computer Science/ Statistical Modelling & Analysis/Operations Research\nWillingness to learn new technologies and thrive in an extremely fast paced environment\nTeam player and easy to work with.\n\n\nApplicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify East West Bank ethical principles of uncompromising integrity, respect for others, and accountability for decisions."},{"jobtitle":"Scientific Data Analyst","companyname":"Stanford University School of Medicine","companyid":"1790","address":"","geo":"Stanford, CA, US","postDate":"Oct 13 2018","views":"125","applicants":"11","employees":"5001-10000","jobDetails":[{"level":"Associate","industry":["Research","Biotechnology","Hospital & Health Care"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nThe Stanford Cognitive and Systems Neuroscience Laboratory in the Department of Psychiatry and Behavioral Sciences is seeking a Scientific Data Analyst. This is an exciting opportunity to work with a multidisciplinary research team (http//scsnl.stanford.edu) on a wide range of studies of human brain function and dysfunction. The successful candidate will assist lab members with neuroimaging and behavioral data analysis, data organization, and management. The Scientific Data Analyst would be responsible for programming and optimizing pipelines for data quality control, imaging data preprocessing and statistical and computational analyses pipelines for large scale multimodal brain imaging data, including but not limited to resting – state and task – based fMRI, diffusion MRI, and volumetric data, behavior data and biological (e.g. hormonal, genetic) data.\n\n Interested candidates are encouraged to submit their CV, a statement of research interests and career goals, and contact information for three references.\n\nDuties include\n\nWork under consultative or self-initiated direction to assess and produce relevant, standard, or custom information (reports, charts, graphs and tables) from structured data sources by querying data repositories and generating the associated information. Distribute and disseminate reports to applicable agencies, researchers, management and other internal end-users.\nDevise methods for identifying data patterns, trends in available information sources using a variety of qualitative and quantitative techniques. Determine and recommend additional data collection and reporting requirements.\nDesign and customize reports based upon data in the database.\nCreate non-routine databases and their related information summary; develop algorithms and statistical model; and perform statistical analyses appropriate to complex data and reporting requirements.\nServe as a resource for non-routine inquiries such as requests for statistics or surveys.\nLead the implementation of data standards and common data elements for data collection.\nCollaborate with technical staff to standardize and systemize routine reports, dashboards, and metrics.\nMay test prototype software and participate in approval and release process for new software.\n- Other duties may also be assigned\n\nDesired Qualifications\n\nMaster’s or Ph.D. degree in biomedical engineering, computer science, psychics, computational neuroscience, quantitative psychology or related field preferred.\nProficient with multiple neuroimaging analysis platforms (e.g. HCP Pipeline, FreeSurfer, SPM, FSL AFNI, GIFT)\nStrong programing skills and comfort with diverse computing environments (e.g. MatLab, Python, UNIX/BASH languages)\nStrong background in statistics and statistical software scripting (e.g. R, Python)\nExperience with data visualization\n\nEducation & Experience (required)\n\nBachelor\\'s degree and three years of relevant experience or combination of education and relevant experience. Experience in a quantitative discipline such as economics, finance, statistics or engineering.\n\nKnowledge, Skills And Abilities (required)\n\nIn-depth knowledge and experience using and applying analytical software, database management system software, database reporting software, database user interface and query software, and data mining software.\nExpert ability to collect data using a variety of methods, such as data mining and hardcopy or electronic documentation study, to improve or expand databases.\nBasic statistical ability.\nStrong listening, verbal and written communication skills.\nAbility to manage multiple activities in a deadline-oriented environment; highly organized, flexible and rigorous attention to detail.\nAbility to use logic to calculate data; efficiently construct a database or scrutinize the form of a question.\nAbility to work with data of varying levels of quality and validity.\nDemonstrated ability to produce data in a clear and understandable manner meeting user requirements.\nAbility to work effectively with multiple internal and external customers.\nAbility to take a leadership role on projects and with users/clients.\n\nCERTIFICATIONS & LICENSES\n\nNone\n\nPHYSICAL REQUIREMENTS*\n\nConstantly perform desk-based computer tasks.\nFrequently sit, sort, file paperwork or parts, grasp lightly, and use fine manipulation, lift, carry, push and pull objects that weigh 10 pounds or less.\nOccasionally write by hand, twist, bend, stoop and squat.\nRarely stand, walk, reach or work above shoulders and use a telephone.\n- Consistent with its obligations under the law, the University will provide reasonable accommodation to any employee with a disability who requires accommodation to perform the essential functions of his or her job.\n\nWORKING CONDITIONS\n\nMay work extended hours during peak business cycles."},{"jobtitle":"Data Analyst - USA","companyname":"Ingram Micro","companyid":"2576","address":"","geo":"Williamsville, NY, US","postDate":"Sep 12 2018","views":"157","applicants":"32","employees":"10001","jobDetails":[{"level":"Associate","industry":["Marketing & Advertising","Information Technology & Services","Human Resources"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nDescription\n\nPosition at Ingram Micro\n\nMarketing Data Analyst and Customer Insights Role\n\n Ingram Micro helps businesses fully realize the promise of technology.TM No other company delivers the full spectrum of global technology and supply chain services to businesses around the world. Ingram Micro’s global infrastructure and deep expertise in technology solutions, supply chain, cloud and mobility enable its business partners to operate efficiently and successfully in the markets they serve. Combined with distinct market insights and the trust and dependability generated from decades of strong partner relationships, Ingram Micro stands apart as the global technology services provider for the future.\n\nAs a Marketing Data Analyst, you will analyze and synthesize partner, market and competitive data to translate findings into business insights and action plans to support improved performance.\nYou will provide financial and business information, analysis, and insight to the company’s leadership team around Marketing initiatives. You will be a member of a high-impact, fast paced, Account team driven to show marketing results.\nDevelop and present insightful presentations across departments that outline significant changes in customer behavior and the marketplace with recommendations for actions. You will Communicate insights across relevant forums in order to broadly inform key decision makers.\nThe Marketing Analyst is responsible for developing and analyzing data models that generate knowledge into the project owner’s business objectives and show how marketing activities tie to revenue growth.\nHe or she will utilize reports of findings and create appropriate materials to communicate the findings across multiple departments.\nThey will maintain a broad understanding of Ingram Micro’s business model along with becoming educated on vendors, partners, end users and internal division’s business models and needs.\nThey must understand client’s objectives and translate business needs into the appropriate technical data models.\nExpertise to prepare data models and review output to ensure model accuracy, along with translating the trends and applying to business demands.\nThey must have the ability to data-mine and aggregate data from multiple sources and provide a cohesive report back to associates and people managers.\nHe or she must have strong business acumen and be able to work on most projects independently and lead projects with guidance from management.\nEffectively listen, communicate, recommend, and present data analytic solutions to internal and external clients, including over the phone meetings, in person presentations with PowerPoint, and other media sources.\nWe’re looking for an ambitious, focused professional who is comfortable with change and can provide great story-telling through data.\n\n\nRequirements\n\nMaster’s degree in quantitative discipline (Statistics, Applied Mathematics, Operations Research, Computer Science, or Econometrics) and 2 years of experience OR Bachelor’s degree in quantitative field with 5-10 years relevant experience.\nExperience working on research and analytics initiatives in the areas of digital marketing, customer experience, branding, advertising, marketing communications and customer segmentation.\nExperience in analysis of large data sets, identifying trends and patterns.\nExperience with Modeling Techniques (linear regression, logistic regression, decision tree), Query Languages (SQL, Python), Automation (SQL Stored Procedures, SSIS, APIs), Reporting (Excel, .Net, MicroStrategy), prior management of a project in which a relational database was built and utilized for analysis, Google Analytics, and Data Mining experience\n\n\nIngram Micro Inc. is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, veteran status, or any other protected category under applicable law."},{"jobtitle":"Data Analyst - USA","companyname":"Ingram Micro","companyid":"","address":"","geo":"Irvine, CA, US","postDate":"Sep 12 2018","views":"50","applicants":"9","employees":"","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Computer Software","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nMarketing Data Analyst and Customer Insights Role\n\n Ingram Micro helps businesses fully realize the promise of technology.TM No other company delivers the full spectrum of global technology and supply chain services to businesses around the world. Ingram Micro’s global infrastructure and deep expertise in technology solutions, supply chain, cloud and mobility enable its business partners to operate efficiently and successfully in the markets they serve. Combined with distinct market insights and the trust and dependability generated from decades of strong partner relationships, Ingram Micro stands apart as the global technology services provider for the future.\n\nAs a Marketing Data Analyst, you will analyze and synthesize partner, market and competitive data to translate findings into business insights and action plans to support improved performance.\nYou will provide financial and business information, analysis, and insight to the company’s leadership team around Marketing initiatives. You will be a member of a high-impact, fast paced, Account team driven to show marketing results.\nDevelop and present insightful presentations across departments that outline significant changes in customer behavior and the marketplace with recommendations for actions. You will Communicate insights across relevant forums in order to broadly inform key decision makers.\nThe Marketing Analyst is responsible for developing and analyzing data models that generate knowledge into the project owner’s business objectives and show how marketing activities tie to revenue growth.\nHe or she will utilize reports of findings and create appropriate materials to communicate the findings across multiple departments.\nThey will maintain a broad understanding of Ingram Micro’s business model along with becoming educated on vendors, partners, end users and internal division’s business models and needs.\nThey must understand client’s objectives and translate business needs into the appropriate technical data models.\nExpertise to prepare data models and review output to ensure model accuracy, along with translating the trends and applying to business demands.\nThey must have the ability to data-mine and aggregate data from multiple sources and provide a cohesive report back to associates and people managers.\nHe or she must have strong business acumen and be able to work on most projects independently and lead projects with guidance from management.\nEffectively listen, communicate, recommend, and present data analytic solutions to internal and external clients, including over the phone meetings, in person presentations with PowerPoint, and other media sources.\nWe’re looking for an ambitious, focused professional who is comfortable with change and can provide great story-telling through data.\n\n\nRequirements\n\nMaster’s degree in quantitative discipline (Statistics, Applied Mathematics, Operations Research, Computer Science, or Econometrics) and 2 years of experience OR Bachelor’s degree in quantitative field with 5-10 years relevant experience.\nExperience working on research and analytics initiatives in the areas of digital marketing, customer experience, branding, advertising, marketing communications and customer segmentation.\nExperience in analysis of large data sets, identifying trends and patterns.\nExperience with Modeling Techniques (linear regression, logistic regression, decision tree), Query Languages (SQL, Python), Automation (SQL Stored Procedures, SSIS, APIs), Reporting (Excel, .Net, MicroStrategy), prior management of a project in which a relational database was built and utilized for analysis, Google Analytics, and Data Mining experience\n\n\nIngram Micro Inc. is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, veteran status, or any other protected category under applicable law."},{"jobtitle":"Data Analyst - USA","companyname":"Ingram Micro","companyid":"","address":"","geo":"Williamsville, NY, US","postDate":"Sep 12 2018","views":"15","applicants":"2","employees":"","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Computer Software","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nMarketing Data Analyst and Customer Insights Role\n\n Ingram Micro helps businesses fully realize the promise of technology.TM No other company delivers the full spectrum of global technology and supply chain services to businesses around the world. Ingram Micro’s global infrastructure and deep expertise in technology solutions, supply chain, cloud and mobility enable its business partners to operate efficiently and successfully in the markets they serve. Combined with distinct market insights and the trust and dependability generated from decades of strong partner relationships, Ingram Micro stands apart as the global technology services provider for the future.\n\nAs a Marketing Data Analyst, you will analyze and synthesize partner, market and competitive data to translate findings into business insights and action plans to support improved performance.\nYou will provide financial and business information, analysis, and insight to the company’s leadership team around Marketing initiatives. You will be a member of a high-impact, fast paced, Account team driven to show marketing results.\nDevelop and present insightful presentations across departments that outline significant changes in customer behavior and the marketplace with recommendations for actions. You will Communicate insights across relevant forums in order to broadly inform key decision makers.\nThe Marketing Analyst is responsible for developing and analyzing data models that generate knowledge into the project owner’s business objectives and show how marketing activities tie to revenue growth.\nHe or she will utilize reports of findings and create appropriate materials to communicate the findings across multiple departments.\nThey will maintain a broad understanding of Ingram Micro’s business model along with becoming educated on vendors, partners, end users and internal division’s business models and needs.\nThey must understand client’s objectives and translate business needs into the appropriate technical data models.\nExpertise to prepare data models and review output to ensure model accuracy, along with translating the trends and applying to business demands.\nThey must have the ability to data-mine and aggregate data from multiple sources and provide a cohesive report back to associates and people managers.\nHe or she must have strong business acumen and be able to work on most projects independently and lead projects with guidance from management.\nEffectively listen, communicate, recommend, and present data analytic solutions to internal and external clients, including over the phone meetings, in person presentations with PowerPoint, and other media sources.\nWe’re looking for an ambitious, focused professional who is comfortable with change and can provide great story-telling through data.\n\n\nRequirements\n\nMaster’s degree in quantitative discipline (Statistics, Applied Mathematics, Operations Research, Computer Science, or Econometrics) and 2 years of experience OR Bachelor’s degree in quantitative field with 5-10 years relevant experience.\nExperience working on research and analytics initiatives in the areas of digital marketing, customer experience, branding, advertising, marketing communications and customer segmentation.\nExperience in analysis of large data sets, identifying trends and patterns.\nExperience with Modeling Techniques (linear regression, logistic regression, decision tree), Query Languages (SQL, Python), Automation (SQL Stored Procedures, SSIS, APIs), Reporting (Excel, .Net, MicroStrategy), prior management of a project in which a relational database was built and utilized for analysis, Google Analytics, and Data Mining experience\n\n\nIngram Micro Inc. is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, veteran status, or any other protected category under applicable law."},{"jobtitle":"Data Analyst","companyname":"ManTech","companyid":"5461","address":"","geo":"Sterling, VA, US","postDate":"Sep 12 2018","views":"36","applicants":"12","employees":"5001-10000","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Defense & Space","Computer Software"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nManTech is seeking Top Talent as a Data Analyst . The analyst will join our Entity Resolution project as a collaborative team member in support of on-going law enforcement enterprise search applications. The analyst will aid in the ongoing assessment of our entity resolution systems. The results of the analyses will drive further developments and capabilities our name identity matching software.\n\nThe Data Analyst Will\n\nObtain, join, scrub, explore, model, and interpret large datasets\nTransform and manipulate large dataset to suit the desired analysis\nCreate and present clear oral and written reports on the findings\nBecome an expert on name identity matching.\n\nRequired Qualifications\n\nBS Degree in a related technical fields (Computer Science, Math, Statistics, etc.)\nAt least two years of experience performing data analyses and interpreting results\nAt least two years of experience using Java, R, Python, MatLab, and SQL for data analysis\nConceptual understanding of – and/or prior experiences related to – data profiling, fuzzy matching, entity resolution, and signal detection theory (specifically with respect to SD theory: designing and improving upon systems that monitor, minimize, and balance false positive and false negative outcomes).\n\nMUST BE A US CITIZEN AND ABLE TO OBTAIN AND MAINTAIN A CBP BI. MAY ALSO BE SPONSORED FOR A TOP SECRET LEVEL CLEARANCE.\n\nPreferred Experience\n\nExperience working with SQL, data-mining or statistical software.\nJava programming experience is a plus\nExperience with SAS Enterprise Minder, SPSS Modeler, or equivalent\nExperience working in field of entity resolution, analytics, data mining or name matching.\nExperience working with Customs or ICE travel-related data.\nUnix / Linux experience.\n\nMUST BE A US CITIZEN AND ABLE TO OBTAIN AND MAINTAIN A CBP/BI CLEARANCE. POTENTIAL TO BE SPONSORED FOR A TOP SECRET CLEARANCE.\n Qualifications Qualifications Requires Bachelor’s degree or equivalent experience and two to four years of experience in intelligence and analysis for a Customs and Border Protection including comprehensive knowledge of intelligence and or counterintelligence. Ability to obtain security clearance. Requires Bachelor’s degree or equivalent experience and two to four years of experience in intelligence and analysis for a Customs and Border Protection including comprehensive knowledge of intelligence and or counterintelligence. Ability to obtain security clearance. Requires Bachelor’s degree or equivalent experience and two to four years of experience in intelligence and analysis for a Customs and Border Protection including comprehensive knowledge of intelligence and or counterintelligence. Ability to obtain security clearance."},{"jobtitle":"Financial Data Analyst","companyname":"Inovalon","companyid":"","address":"","geo":"Bowie, MD, US","postDate":"Sep 12 2018","views":"5","applicants":"0","employees":"","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Computer Software","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nFinancial Data Analyst\n\n\nJob Locations US-MD-Bowie\n\n Requisition ID 2018-8782\n\nOverview\n\nInovalon Inc., sees Financial Data Analyst for multiple openings.\n\nResponsibilities\n\nResearch, model and develop solutions to improve financial processes (including invoicing and forecasting) at the front-end of the data analytic process by performing qualitative reviews of complex billable and non-billable membership, reporting/analytic, and intervention event data, that is received by or on behalf of customers and entered into relevant databases.\nApply statistical approaches to data sources to evaluate data quality and troubleshoot data quality issues, confirming that data complies with integration specifications and conducting root cause analysis when it does not, and create reports that evaluate data integrity problems.\nDesign and recommend solutions to correct issues with data integrity and integration to improve billing, invoicing, and forecasting processes that utilize this data.\nParticipate in revenue forecasting processes for relevant products, using MS SQL Server, advanced Excel Spreadsheets, and other technical tools to perform complex data analysis on forecasted and actual data related to billable events by building predictive volume models and comparing forecasting to actual performance.\nDevelop and create dashboards using MS SQL Server and Tableau to compare actual target volume with forecasting and to present volume across multiple clients, using quantitative and metric data to create data visualizations that provide insight into product performance.\nCreate mathematical models and graphs to calculate and propose cost-saving measures and potential revenue opportunities.\nPresent the results of financial modeling and data analysis that leadership can use to gain insight and take action to improve problem areas.\nImprove approve processes related to monthly invoicing from the data side by reviewing and validating financial data and utilize technical tools to trace back and conduct root cause analysis of the data contained in the relevant databases to discover the source of data discrepancies.\nDevelop and model solutions designed to improve invoicing capability and present findings and proposed solutions to senior leadership to assist in critical decision making.\nDevelop and implement billing procedures and streamline existing billing processes, with a focus on automation, billing accuracy, transparency, and efficiency.\n\n\nQualifications\n\nMaster’s degree plus at least two years of related professional experience with quantitative statistical data analysis and modeling (particularly as it relates to finance-based data and reporting) and interactive reporting, or five years of related professional experience if in possession of a relevant bachelor’s degree.\nExperience with data science models typically used in business scenarios and data management processes (including financial data) required.\nExperience with cloud computing and online business models, algorithm development experience including knowledge of statistical and matrix processing techniques, financial data modeling, database systems, computer networks, data structures, and Portfolio Burndown also required.\nMust be able to apply operations research methodology, decision and logic design, root cause analysis, programming languages, data mining techniques, information theory methodology, graphical models, immersed visualization, distributed computing, object-oriented programming, and scalable parallel computing.\nDemonstrated experience with Microsoft technologies (including Excel, PowerPoint, Word, and Visio), data visualization and modeling technologies (including JavaScript, Tableau, SAS Enterprise, and R and related packages, SQL, SQL Server, SSRS, VSTS, Hyperion, Oracle ERP, and Agile development methodology required.\n\nInovalon provides equal employment opportunities (EEO) to all employees and applicants for employment. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, or protected veteran status and will not be discriminated against on the basis of disability.\n\nInterested in this opportunity?\n Socialize this job opportunity to a friend, colleague, or family member:\n\n Software Powered by iCIMS"},{"jobtitle":"Senior Data Analyst","companyname":"Credit Sesame","companyid":"1098518","address":"","geo":"San Francisco, CA, US","postDate":"Sep 12 2018","views":"56","applicants":"11","employees":"51-200","jobDetails":[{"level":"Associate","industry":["Computer Software","Internet","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nCredit Sesame is the nation’s only full-lifecycle credit management service that helps consumers achieve financial wellness. Since 2010, we’ve helped millions improve their financial health, at no cost to them, by offering the best tools possible to access, understand, use, and protect their credit so they can lead better lives.\n\n We are a fast-growing, nimble startup, and we succeed only because of our amazing teammates and our strong, positive culture.\n\n We’re looking for Senior Data Analyst who can help drive business intelligence efforts and support the growth of our Analytics team. You’ll be generating data-driven insights that will inform our core business strategies. If you’re curious, have the grit to tackle tough analytical problems, and want to be part of a team that helps create innovative products so millions can improve their credit wellness, then this opportunity is for you!\n\n What you’ll be doing…\n\nmining data from large SQL databases;\nbuilding models that lead to better insights and business understanding;\ndesigning and maintaining reports and dashboards to track Credit Sesame’s KPIs;\nassuring data quality and data integrity for revenue and business development;\nworking with data source owners and developing project plans;\ngenerating creative insights beyond the scope of supporting reactive requests;\nacting as an evangelist for the power of data to drive decisions and generate insights;\nmentoring junior team members.\nWhat you’ll bring to the table…\n\nyou have over 2 years of experience in data analytics;\nyou’re a expert in statistics, econometrics, and data science, and have the experience and education to back it up;\nyou have a command of machine learning techniques and tools (K-means, Naïve Bayes, SVM, etc.), and are familiar with lifting model performance to get world-class results;\nyou’re comfortable analyzing large data sets and creating data flow diagrams;\nyou can use Python and R to analyze and solve complex business problems;\nyou can produce correct and efficient SQL queries, and have sufficient mastery to design useful databases;\nyou have the adaptability and agility needed to succeed in a high-growth startup environment;\nyou’re excited about the potential of FinTech to disrupt the traditional delivery of finance services, and have past experience in financial services or technology;\nyou have an e-commerce background, preferably;\nyou have a Master’s degree in a quantitative field of study, preferably.\nYou’ll love working with us because...\n\nwe pioneered the Personal Credit Management space;\nyou will have huge potential to grow with a dynamic startup that’s a category leader;\nwe have an amazing company culture with the best coworkers in the Bay Area;\nyou will get equity in a leading startup that is backed by top VCs, along with comprehensive medical, dental, vision insurance;\nwe have meals catered twice a week;\nwe offer both free on-site fitness centers and a monthly fitness reimbursement;\nwe have fully-stocked kitchens with tasty snacks and drinks;\nwe have open paid time off—take the time off you need so you’re happy and healthy;\nwe are only a block from the Montgomery Street BART;\nyou can work in either our San Francisco or our Mountain View office;\nwe are an equal opportunity employer."},{"jobtitle":"BI Data/Reporting Analyst","companyname":"Astreya","companyid":"54325","address":"","geo":"Mountain View, CA, US","postDate":"Aug 13 2018","views":"75","applicants":"29","employees":"1001-5000","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Computer Software","Telecommunications"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nCompany\n\nAstreya Partners are at the cusp of the new way of working. We provide IT services and Managed Performance to some of the most exciting companies on the planet. Our delivery model helps our clients be Positively productive by matching exceptional people to on-site teams delivering world class IT service. With engineers in over 30 countries and 70 cities around the world we are a truly global company working with truly global clients.\n\n If you are an ambitious and driven individual with a passion for data, tools and problem solving of vexing operational challenges, then this BI Data Analyst is for you! You will be working within a very dynamic and evolving Insights team as part of our largest global support program.\n\n You will be traversing a vast landscape of evolving tools and technologies to harness large sets of data to produce enhance reporting, live dashboard and analysis results for Managers across the globe. You will work collaboratively alongside peer analysts to produce and maintain insight deliverables. You will work directly with operational managers, client program managers and cross functional stakeholders to gather requirements and produce data in consumable formats and end-point.\n\n This role will also partake in BI initiatives to continually improve the process of data management, transformation and visualization of raw data into meaningful information and insights.\n\nYou Will Have The Opportunity To\n\nWrite, review, optimize SQL queries, views, and set stored/scheduled procedures to extract data\nDesign, develop, publish and maintain dashboards in Tableau or similar\nBe an MS Office Excel Ninja (Pivot tables, Power Pivot, formulas, VBA /Macros)\nTest, validate and enhance report output\nWork simultaneously across multiple data sources and reporting tools\nCreate scripts for importing, exporting, cleansing, analyzing, mapping and converting data\nAnalyze performance data and provide intelligent synthesis, interpretation and provide recommendations where appropriate\nBuild visualization data in charts, graphs and tables\n\n\n\nRequirements\n\n3 years+ of strong analytical skills with the ability to collect, organise, analyse, and disseminate significant amounts of information with attention to detail and accuracy\nAbility to learn new software and tools in an efficient manner\nCritical-thinking skills and the ability to identify trends in the data and come up with key takeaways and recommendations\nStrong interpersonal skills, oral communication skills, and problem solving abilities\nBA/BS/MS degree with strong academic record\n\n\n\nAdditional Experience In (but Not Required)\n\nR and/or Python scripting language\nUnderstanding or prior use of Cloud SQL and Cloud storage technology\n\n\nWhat can Astreya offer you?\n\nWorking with some of the biggest firms in the world as part of the Astreya delivery network\nEmployment in the fast growing IT space providing you with brilliant career options for years to come\nIntroduction to the new ways of working and awesome technologies\nCareer paths to help you establish where you want to go\nA company-wide mentoring program to advise you along the way\nOnline training courses through CBT-nuggets to upskill you\nPerformance management system to provide you with meaningful, actionable feedback\nDedicated management to provide you with a point of leadership and care\nInternal promotion focus. We love to build people from within.\nNumerous on-the-job perks\nPeer Recognition\nMarket competitive rates and benefits\n\n\nDesired Skills and Experience\nAbility to Adapt and Quickly Adjust to Change"},{"jobtitle":"Manager Modeling & Data Analysis (Marketing Analytics) - Omaha, NE","companyname":"Mutual of Omaha","companyid":"","address":"","geo":"Omaha, NE, US","postDate":"Aug 13 2018","views":"9","applicants":"0","employees":"","jobDetails":[{"level":"Entry level","industry":["Banking","Insurance","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nThe Manager Modeling and Data Analysis is responsible for driving top line growth by leading development of targeting and segmentation solutions to improve effectiveness of acquisition and early months on book marketing campaigns while interacting with business stakeholders across the organization to promote usage of advanced analytical solutions.\n\nEssential Job Functions\n\nDrive top line growth by leading development of targeting and segmentation solutions to improve effectiveness of acquisition and early months on book marketing campaigns\nInteract with business stakeholders across the organization to promote usage of advanced analytical solutions\nExplore new modeling tools and techniques and develop new solutions to add value to Mutual of Omaha\nManage all aspects of model development process, including model initiation, model design, model documentation and ongoing performance monitoring\nPerform ad hoc analysis to support internal audit requests\nDevelop strong partnership with multiple internal stakeholders, including targeting, model governance teams and Legal and Compliance\nPerform other duties and/or special projects as assigned\nBe a thought leader in driving rigor in all analytical efforts in support of Direct to Consumer campaigns including targeting, segmentation and testing\nPartner with peers to optimize the performance of the Direct to Consumer channel by testing and synthesizing key learnings around prospecting, mail frequency, cadence etc\nLead a team of Analysts to accomplish team goals\n\nMinimum Qualifications\n\n5\nyears of experience as a data analyst of which 2\nyears of experience in predictive model development, preferably in marketing or risk\n3\nyear proven data mining and/or applicable programming skills with SAS, SQL, R, Python or other comparable languages\nBachelor's degree in Statistics\nExperienced in operationalizing targeting models\nRobust understanding of statistical techniques and their application in business\nComfortable with data extraction, data manipulation, synthesis and creating presentations\nPrior experience with analytical initiatives with demonstrated ability to problem solve and think critically\nability to recognize key leverage points in an analysis\nAbility to lead and motivate a team, strive for excellence and hold a high bar\nSelf-motivated and driven with an acute sense of ownership * Be a team player\n\nPreferred Qualifications\n\nHands on modeling experience\nExperience with Big Data tools (Hadoop, Spark etc.)\nPrior experience managing a team\n\nIf you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at 1-800-780-0304. We are available Monday through Friday 7 am to 4:30 pm CST.\n For all other inquiries, contact our HR Helpline at 1-800-365-1405, option 4.\n Mutual of Omaha and its affiliates are an Equal Opportunity /Affirmative Action Employer, Minorities/Female/Disabled/Veteran\n To All Recruitment Agencies: We do not accept unsolicited agency resumes and we are not responsible for any fees related to unsolicited resumes."},{"jobtitle":"Manager Modeling & Data Analysis (Marketing Analytics) - Omaha, NE","companyname":"Mutual of Omaha","companyid":"","address":"","geo":"Lincoln, NE, US","postDate":"Aug 13 2018","views":"6","applicants":"2","employees":"","jobDetails":[{"level":"Entry level","industry":["Banking","Insurance","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nThe Manager Modeling and Data Analysis is responsible for driving top line growth by leading development of targeting and segmentation solutions to improve effectiveness of acquisition and early months on book marketing campaigns while interacting with business stakeholders across the organization to promote usage of advanced analytical solutions.\n\nEssential Job Functions\n\nDrive top line growth by leading development of targeting and segmentation solutions to improve effectiveness of acquisition and early months on book marketing campaigns\nInteract with business stakeholders across the organization to promote usage of advanced analytical solutions\nExplore new modeling tools and techniques and develop new solutions to add value to Mutual of Omaha\nManage all aspects of model development process, including model initiation, model design, model documentation and ongoing performance monitoring\nPerform ad hoc analysis to support internal audit requests\nDevelop strong partnership with multiple internal stakeholders, including targeting, model governance teams and Legal and Compliance\nPerform other duties and/or special projects as assigned\nBe a thought leader in driving rigor in all analytical efforts in support of Direct to Consumer campaigns including targeting, segmentation and testing\nPartner with peers to optimize the performance of the Direct to Consumer channel by testing and synthesizing key learnings around prospecting, mail frequency, cadence etc\nLead a team of Analysts to accomplish team goals\n\nMinimum Qualifications\n\n5\nyears of experience as a data analyst of which 2\nyears of experience in predictive model development, preferably in marketing or risk\n3\nyear proven data mining and/or applicable programming skills with SAS, SQL, R, Python or other comparable languages\nBachelor's degree in Statistics\nExperienced in operationalizing targeting models\nRobust understanding of statistical techniques and their application in business\nComfortable with data extraction, data manipulation, synthesis and creating presentations\nPrior experience with analytical initiatives with demonstrated ability to problem solve and think critically\nability to recognize key leverage points in an analysis\nAbility to lead and motivate a team, strive for excellence and hold a high bar\nSelf-motivated and driven with an acute sense of ownership * Be a team player\n\nPreferred Qualifications\n\nHands on modeling experience\nExperience with Big Data tools (Hadoop, Spark etc.)\nPrior experience managing a team\n\nIf you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at 1-800-780-0304. We are available Monday through Friday 7 am to 4:30 pm CST.\n For all other inquiries, contact our HR Helpline at 1-800-365-1405, option 4.\n Mutual of Omaha and its affiliates are an Equal Opportunity /Affirmative Action Employer, Minorities/Female/Disabled/Veteran\n To All Recruitment Agencies: We do not accept unsolicited agency resumes and we are not responsible for any fees related to unsolicited resumes."},{"jobtitle":"Data Analyst","companyname":"Astreya","companyid":"54325","address":"","geo":"Sunnyvale, CA, US","postDate":"Aug 13 2018","views":"637","applicants":"215","employees":"1001-5000","jobDetails":[{"level":"Entry level","industry":["Information Technology & Services","Computer Software","Telecommunications"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nCompany\n\nAstreya Partners are at the cusp of the new way of working. We provide IT Services and Managed Performance to some of the most exciting companies on the planet. Our delivery model helps our clients be Positively Productive by matching exceptional people to on-site teams delivering world class IT service. With professionals in over 35 countries and 70 cities around the world, we are a truly global company working with global clients.\n\nClient Overview\n\nThe Global Infrastructure Group (GIG) is responsible for end-to-end planning & delivery of the client's production compute infrastructure. This position will support the Data Center Capacity Allocation and Planning team (GIG-CAP), which is responsible for long range datacenter capacity planning and the allocation of new capacity to product areas through quarterly capacity sales.\n\nPosition Overview\n\nWe are searching for a Data Analyst to join our Data Center Global team in Sunnyvale, CA. This is a full-time Mon-Fri, long-term need for our team. You would be working closely with Technical Program Managers and other Data Analysts to build on business reporting needs. This is a great fit for someone who has the ability and passion to lead data reporting projects utilizing project management and business operations skills. We need sound data analysis skills and someone who is passionate about data in an engineering space.\n\nResponsibilities\n\nQuerying and analyzing data center delivery performance data using tools and functions such as SQL, Dashboards, and Google spreadsheets.\nUse statistical methods to analyze data and generate useful business reports\nAuditing and maintaining capacity delivery performance reports\nResolving issues involving capacity delivery metrics derived for data center project delivery\nFollow-up with internal teams to solve internal data problems\nResolving minor issues regarding risk identification and management in relation to delivery of data center capacity with guidance from other team members\nManage multiple projects and effectively communicate status updates with Project Managers\nDetail and explain methodology used in analyses as requested by Project Managers\nGenerate various visual charts and reports pertaining to data center capacity\nDaily, weekly, and quarterly reports to support the data center operations needs\nCreation and maintenance of proprietary dashboards reports, utilizing internal tools such as PLX reports, SQL Scripting, and Google spreadsheets related to data center projects.\n\n\n\nQualifications\n\nBachelor’s Degree in Mathematics or Computer Engineering\n2-3yrs experience as a data analyst\n2-3yrs experience with Data Mining or Big Data Query\n1-2yrs experience in dashboard creation/maintenance\nExperience with: SQL, R, Tableau, Excel, (Python is a plus)\nAbility to create strategies that optimize statistical efficiency and quality\nAbility to thrive in a faced paced and ever changing environment\nAttention to detail, organization, versatility is a must\n\n\n\nWhat can Astreya offer you?\n\nWorking with some of the biggest firms in the world as part of the Astreya delivery network\nEmployment in the fast growing IT space providing you with brilliant career options for years to come\nIntroduction to the new ways of working and awesome technologies\nCareer paths to help you establish where you want to go\nA company-wide mentoring program to advise you along the way\nOnline training courses through CBT-nuggets to upskill you\nPerformance management system to provide you with meaningful, actionable feedback\nDedicated management to provide you with a point of leadership and care\nInternal promotion focus. We love to build people from within.\nNumerous on-the-job perks\nPeer Recognition\nMarket competitive rates and benefits\n\n\nDesired Skills and Experience\nData Analytics, Big Data Query, DATA VISUALIZATION, SQL, SCRIPTING"},{"jobtitle":"Lead Analytic Scientist/Lead Data Engineer","companyname":"NPAworldwide","companyid":"281315","address":"","geo":"San Diego, CA, US","postDate":"Aug 13 2018","views":"23","applicants":"2","employees":"1001-5000","jobDetails":[{"level":"Associate","industry":["Staffing & Recruiting","Financial Services","Hospital & Health Care"],"jobtype":"Full-time","function":["Research","Analyst","Information Technology"]}],"description":"Job description\nWhy a Great Opportunity\n\n We are seeking an experienced Lead Analytic Scientist for our client in San Diego, Calif. This is a direct hire opportunity. They are seeking a highly motivated individual eager to learn and apply cutting edge computing technologies for advanced applications possessing strong communication skills and the ability to work efficiently in a team environment.\n\n Our client is a global leader in financial analytics software whose groundbreaking work is actively shaping the industry. In addition to a competitive salary, incentive plan, and comprehensive benefits package, employees are offered opportunities for personal recognition, professional development, and a flexible work/life balance. The San Diego office is in a centralized location near the beach that also makes it a great place to live: new restaurant and retail centers, top school district and biking/hiking trails.\n\n Our client is creating the science and technology behind Fraud Detection. Be a part of a team who helps to wipe out financial fraud activities by staying at the forefront of Artificial Intelligence (AI) and Machine Learning (ML). Want to build something meaningful and have fun while doing it? They do too. Use cutting-edge technology to help build that next best solution. If you are a problem solver and like the idea of solving tough problems with data and analytics in real-world situations, you will thrive in this role! You will have the opportunity to work side by side with some of the brightest analytical and engineering minds in the industry who share a passion for innovation.\n\nIncentives\n\nHigh performance culture promoting recognition, rewards and professional development\nCompetitive base salary coupled with attractive role-specific incentive plan\nComprehensive benefits program\n\n\nJob Description\n\nDuties:\n\nWork with large amounts of real-world data\nEnsure data quality throughout all stages of acquisition and processing, including data collection, normalization and transformation\nResearch and select appropriate statistical methods and computational algorithms.\nBuild and/or oversee teams building high-end analytic models for relevant problems using statistical modeling techniques. Manage these projects under time constraints, working with other teams to provide high quality support to enable integration and deployment of analytics software and solutions.\nAssist with model go-lives by performing production data validations and analysis of models in production.\nAssist with client meetings to investigate and resolve problems. Apply data mining methodology in thorough analyses of model behavior and provide support for customer meetings, model construction and pre-sales. May also participate in post-implementation support.\nWhen opportunity presents itself, advance position in the market for analytical and statistical software by helping to understand and anticipate market needs.\n\n\nQualifications\n\nQualifications:\n\nMS or PhD degree in computer science, engineering, physics, statistics, mathematics, operations research or natural science fields with significant years of hands-on related experience in predictive modeling and data mining is required.\nExperience analyzing large data sets and applying data-cleaning techniques along with performing statistical analyses leading to the understanding of the structure of data sets.\nProven ability to lead cross functional teams on medium to large scale projects and handling client interactions requiring strong communication skills.\nStrong scripting experience using Perl, Bash, or similar.\nExperience working with two of the following: Java, Python, C++ or C.\nProven and demonstrable experience with at least three of the following: neural networks, logistic regression, non-linear regression, random forests, decision trees, support vector machines, linear/non-linear optimization.\nFamiliarity with cloud computing technologies such as AWS or OpenStack a plus.\n\nApplicants must be authorized to work for any U.S. employer. Relocation assistance available within the United States.\n\n Staff Smart, Inc. is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status."},{"jobtitle":"Data Engineer","companyname":"Perfect Price","companyid":"6590563","address":"","geo":"San Francisco, CA, US","postDate":"Aug 13 2018","views":"34","applicants":"6","employees":"11-50","jobDetails":[{"level":"Entry level","industry":["Information Technology & Services","Computer Software","Internet"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nPerfect Price is changing how companies sell, by bringing artificial intelligence to pricing. Our software suite solves pricing challenges faced by companies in many industries, and we are solving the challenges of the use of AI to manage everyday aspects of business. For example we enable dynamic pricing like Uber or Lyft, but at a fraction of the cost to set up and time to implement. Our rapid growth demands adding another talented professional to our team.\n\n We're looking to train the next generation of data scientists and AI engineers on some of the most challenging data science problems in the world.\n\n Responsibilities\n\nYou'll be in charge of building and maintaining ETL pipeline for scalability and stability.\nBuilding, maintaining and improving the modeling infrastructure using cutting edge tools including: Hadoop, PIG, Kafka, Flume, Ssamza, Zookeeper, PySpark, Elasticsearch, Python, Django\nSupport data analysis, mathematical modeling, machine learning and data mining for price testing and its optimization\nReviewing the code of peer engineers and others team members\nExplore and employ external data sets, finding them, adding them to the system, adjusting and reformatting/cleaning up so that they can be consumed by our infrastructure. Developing models and machine-based understanding of interactions between external datasets and client data.\nThis role reports to the cofounder and CTO, who previously trained engineers at Microsoft, Twitter and Drawbridge.\nRequirements\n\nMasters or PhD in Computer Science/Engineering/Physics or related fields\n2 years relevant experience"},{"jobtitle":"Senior Data Engineer (Azure Cloud)","companyname":"East West Bank","companyid":"14528","address":"","geo":"Palo Alto, CA, US","postDate":"Aug 13 2018","views":"19","applicants":"2","employees":"1001-5000","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Banking","Financial Services"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nCompany Overview\n\n Overview\n\nFor more than 40 years, East West Bank has served as a pathway to success. With over 130 locations across the U.S. and Greater China, we are the premier financial bridge between the East and West. Our teams of experienced, multi-cultural professionals help guide businesses and community members on both sides of the Pacific looking to explore new markets and create new opportunities. And our sustained growth and expertise in industries like real estate, entertainment and media, private equity and venture capital, high-tech and aviation help build sustainable businesses and expand our employees’ potential for career advancement.\n\n Headquartered in California, East West Bank (NASDAQ: EWBC) is a top performing commercial bank with an exclusive focus on the U.S. and Greater China markets. With assets of $37.7 billion, we’re ranked among the 30 largest banks in the United States and currently top 5 in “America’s 100 Best Banks” by Forbes, a list where we've consistently been in the top 15 since 2010. With a strong foundation, an enterprising spirit and a commitment to absolute integrity, East West Bank gives people the confidence to reach further.\n\nJob Summary\n\nEast West Bank is looking for a motivated Data Scientists to contribute towards the success of our Data and Analytics Technology initiatives. This person will be experienced in different machine learning, deep learning and AI algorithms and work on data mining and statistical modelling for predictive and prescriptive analytics and generating actionable insights. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire diverse set of data, design, develop, deploy and interpret models and outcomes.\n\nResponsibilities\n\nImplement techniques to acquire, discover and explore data for analytics\nIdentify use cases and implement statistical modelling, machine learning, deep learning and AI capabilities to create data-driven user experiences\nPOC / POV and prototyping data and analytics solutions and derive viability\nEnsure data quality, integrity, security and completeness throughout the data lifecycle\nDefine data validation strategies, pre-processing and feature engineering strategies\nTest/train and fine tune models and deployment of models in production\nWork with business stakeholders to understand requirements and business use cases and translating data into metrics, KPI, and solutions\nDevelop deep understanding of the data sources, implement data standards, maintain data quality and master data management\nDesign and develop data services and API\nMentor, coach, train data engineers and analysts\n\n\nRequirements\n\nStrong Machine learning, deep learning experience especially in banking and financial sector with hands-on development using technology stack including Python, R, Spark and Hadoop\nExperienced in analyzing large quantities of data in cloud platform like AWS or Azure eco-system. (Azure preferred)\nExposure and deep understanding of supervised and unsupervised machine learning algorithms, logistic regression, random forest, SVM, KNN and other analysis.\nSolid understanding of python libraries for machine learning such as scikit-learn, pandas, numpy and deep learning frameworks such as tenserflow, keras etc…\nStrong experience and exposure in classification, clustering, segmentation, targeted recommendations and managing customer behavior data\nHandling large internal and external data including social media and other 3 rd party datasets to derive valuable insights\nNoSQL Databases and Big data technologies including Hadoop, MongoDB, and Azure CosmosDB\nExperience with API / RESTful data services\nWorked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Streaming Analytics\nExperience working with different data storage options including AWS S3, Azure BLOB storage etc.\nUnderstanding of different data formats including Parquet, Avro, CSV, ORC etc.\nPrior experience with MPP databases and maintain large amount of data processing\nExperience with Azure Data Factory and Azure Data Catalog is a big plus but not mandatory\nExperience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big plus but not mandatory\nPast working experience on a fast paced and agile environment\nAbility to review architecture design and provide direction on system capabilities\nPerform ongoing monitoring, automation and refinement of data engineering solutions\nExperience in leading high visibility projects that interacts with multiple business lines\nExperience working with an on-shore / off-shore model\nBuild and meet project timelines and manage delivery commitments with proper communication to management\nCollaborate and communicate with key business lines, technology partners, vendors and architects\n\n\nQualifications\n\nMS degree with 8+ years of relevant experience in Computer Science/ Statistical Modelling & Analysis/Operations Research\nWillingness to learn new technologies and thrive in an extremely fast paced environment\nTeam player and easy to work with.\n\nApplicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify East West Bank ethical principles of uncompromising integrity, respect for others, and accountability for decisions.\n\nOptions\n\nApply for this job online Apply\n\n Share\n\n Email this job to a friend Refer\n\n Sorry the Share function is not working properly at this moment. Please refresh the page and try again later.\n\n Share on your newsfeed\n\n Connect With Us!\n\nNot ready to apply? Connect with us for general consideration.\n\n East West Bank is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, or any other legally protected status. Reasonable accommodations for disability are provided to applicants and employees in accordance with applicable law."},{"jobtitle":"Data Scientist/Data Analyst","companyname":"ConsultNet","companyid":"19626","address":"","geo":"Columbus, OH, US","postDate":"Aug 13 2018","views":"236","applicants":"34","employees":"201-500","jobDetails":[{"level":"Entry level","industry":["Information Technology & Services","Computer Software","Financial Services"],"jobtype":"Full-time","function":["Engineering","Information Technology"]}],"description":"Job description\nTitle: Data Scientist/Data Analyst\nLocation: Columbus, OH\nDuration: 6 Months + with a probable conversion to an FTE w/client\nRate: DOE (Depends on Experience)\n\nJob Description\n\nThis position is responsible for identifying, acquiring, qualifying, analyzing, and distributing data in support of evolving physical and digital product Supply Chain Strategy as well as Forecasting, Supply Planning, and Sourcing operations. The Data Analyst works closely with multiple business and technical teams.\n\nSuccessful Candidates Will Have The Following Experience\n\nCreate and maintain queries, data sets, and analysis to monitor supply chain performance, evaluate trends, and support demand and supply planning activities\nPerform ad-hoc / non-repetitive data analysis to support fact-based decision\nDevelop, implement, and maintain a variety of reports related to supply chain management.\nConduct statistical analysis, develop machine learning methodologies, and model estimation including variance estimation for complex business metrics as well as handling issues with heavy tailed distributions and extreme values\n\n\n\nWhat You'll Need To Be Successful\n\n2+ years of experience in a role with heavy emphasis on quantitative analysis and data analytics (Supply Chain and/or Finance experience preferred)\nBachelor's Degree required preferably in or with a concentration in Statistics, Mathematics, Information Science, or Engineering.\nDemonstrated experience defining statistical experiments and using analytical tools (SAS, SPSS, R, etc.).\nDemonstrated experience using business intelligence, data warehousing, data mining, modeling, data analysis, and data visualization tools (Tableau, Alteryx, SQL, Python, etc.)\nExperience with distributed computing (Hadoop, Hive, Spark, MapReduce etc.)\nAdvanced skills and experience using Excel (complex modeling, importing/linking datasets, using macros, VBA scripting, pivot tables, etc.) and Access (database design, data modeling, complex query building, reporting, etc.).\nExperience working with Salesforce.com data for reporting and analysis preferred.\nExperience with Oracle databases and/or Oracle EBS preferred.\nSolution-driven, customer service mindset with the ability to multi-task and work agilely within tight deadlines.\nDemonstrated problem-solving skills to analyze, interpret and synthesize large data sets with limited direction.\n\n\nBe a part of the ConsultNet difference. As a leading national provider of IT staffing and solutions, ConsultNet delivers exceptional services to startup, midmarket and Fortune 1000 companies across North America. Since 1996, we've partnered with clients to create rewarding opportunities for our consultants, successfully building teams that have surefire results.\n In the past two years alone, we have placed more than 1,500 consultants in contract, contract-to-hire, or direct placement opportunities. We understand communication is key to finding the right job that matches your skills and career goals. For us, it's not just the work that we do; it's how we do the work. Our breadth of offerings extends to multiple IT positions in major markets throughout the country, see more at www.consultnet.com."},{"jobtitle":"Data Analyst I","companyname":"TrueSense Marketing","companyid":"1049812","address":"","geo":"Warrendale, PA, US","postDate":"Jul 13 2018","views":"149","applicants":"24","employees":"201-500","jobDetails":[{"level":"Associate","industry":["Marketing & Advertising","Online Media","Non-profit Organization Management"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nAs a TrueSense Data Analyst I, the ideal candidate will be challenged with analyzing data and working within relational databases, including various customer meta data and transactional information to support multichannel marketing initiatives across a variety of media (direct mail, site, email, events, search, telemarketing, etc.).\n\n The role will revolve around the application of valid analytic techniques to inform and enhance client marketing performance across their fundraising portfolio.\n\n To succeed in this role, the candidate is expected to demonstrate analytical thinking, logical reasoning, strong technical aptitude with software applications, and an ability to communicate and present, at times complex, data findings in a way that promotes general understanding.\n\nEssential Functions\n\nExecuting a wide variety of analytics projects including donor profiling, lifecycle analysis, segmentation review, campaign analysis, and ad hoc data exploration.\nExtract and process large quantities of data from our data warehouse and other data marts\nAnalyze marketing metrics to identify cause-effect relationships between marketing levers and outcomes – ability to answer the “What happened” and “Why”\nData mining and analysis, including the ability to independently QA database information and help drive database enhancements via communication and requirements documentation for our Data Solutions team\nTurn complex data into practical and actionable marketing insights\nSupport development of efficient and accurate summary reports\nDevelop and tune queries and packages within our SQL Server-based data warehouse environment\nAbility to discover hidden insights or complex patterns through data analysis\n\n\n\nPosition Requirements (Knowledge, Skills And Abilities)\n\nAppreciation - Is transparent and honest with team members, appreciates differences between coworkers in thought as well as style, and shows respect for others and their ideas.\nCommunication - Demonstrates excellent use of the English language (grammar, syntax, vocabulary); possesses the ability to communicate effectively and continuously with internal as well as external customers; composes clear/complete emails. Strong presentation skills preferred.\nComputer Proficiency - Strong computer skills including all Microsoft products (Outlook; Excel; Word; PowerPoint). Excel power-users preferred\nJob Specific Programs/Functions as Applicable: BI or other analytics tools (SAS, Python, R, Tableau, TIBCO Spotfire, Adobe analytics, Google Analytics, Power BI)\nCongeniality - Positive attitude, not easily discouraged, open to alternative views, accepting of coaching/peer input, and copes well even under pressure.\nCustomer Service - Anticipates the needs of others as well as clients, acts upon those needs appropriately, and help remove barriers to excellent customer service.\nIndustry Knowledge - In-depth knowledge and understanding of direct-response best practices, strategy, and tactics.\nInnovation - Pursues better ways of getting things done, models breakthrough thinking, acts as a change agent, and helps others manage through change. Ultimately translates the department vision into actionable plans and creates enthusiasm about the future of TrueSense.\nModeling - Acts as a role model for others and actively participates in the development and mentorship of teammates/direct reports; positively influences others while providing motivational support and direction where needed.\nPersonal Development - Demonstrates personal growth and learning; acknowledges mistakes & learns from them.\nProblem Solving - Digs in to problems, investigates all aspects, gathers facts, and recommends solutions.\nProfessionalism - Is visible with a positive presence, is ethical, and highly professional.\nProject Management - Can be trusted to troubleshoot all job processes, manage timelines and inventory needs, anticipates issues, effectively multitasks, and follow through with all tasks to completion.\nTeam Mentality - Works in a coordinated effort with other members of the team in order to achieve overreaching goals, models collaboration, instills effective team membership in others, and allows for flexibility in how work is accomplished.\n\n\n\nEducation And Experience\n\nBachelor's Degree or equivalent\nMinimum of 3 years of experience in analytics in the direct response marketing arena a must"},{"jobtitle":"Data Analyst","companyname":"ManTech","companyid":"5461","address":"","geo":"Alexandria, VA, US","postDate":"Jul 13 2018","views":"9","applicants":"3","employees":"5001-10000","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Defense & Space","Computer Software"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nManTech is seeking Top Talent as a Data Analyst. The analyst will aid in the ongoing assessment of our customer systems. The results of the analyses will drive further developments and capabilities our name and entity matching software.\n\nThe Data Analyst Will\n\nObtain, join, scrub, explore, model, and interpret large datasets\nTransform and manipulate large dataset to suit the desired analysis\nCreate and present clear oral and written reports on the findings\nBecome an expert on name and entity matching.\n\nRequired Qualifications\n\nBS Degree in a related technical field (Computer Science, Math, Statistics, etc.)\nAt least two years of experience performing data analyses and interpreting results\nAt least two years of experience using Java, R, or python, Matlab, SQL for data analysis\nConceptual understanding of – and/or prior experiences related to – data profiling, fuzzy matching, entity resolution, and signal detection theory (specifically with respect to SD theory: designing and improving upon systems that monitor, minimize, and balance false positive and false negative outcomes).\n\nMUST BE A US CITIZEN AND ABLE TO OBTAIN AND MAINTAIN A CBP BI. MAY BE SPONSORED FOR TOP SECRET LEVEL CLEARANCE.\n\nPreferred Experience And Skills\n\nExperience working with SQL, data-mining or statistical software.\nJava programming experience is a plus\nExperience with SAS Enterprise Minder, SPSS Modeler, or equivalent\nExperience working in the field of entity resolution, analytics, data mining or name matching.\nExperience working with Customs or ICE travel-related data.\nUnix / Linux experience.\n\nMUST BE A US CITIZEN AND ABLE TO OBTAIN AND MAINTAIN A CBP/BI CLEARANCE. POTENTIAL TO BE SPONSORED FOR A TOP SECRET CLEARANCE.\n Qualifications Qualifications Requires Bachelor’s degree or equivalent experience and two to four years of experience in intelligence and analysis for a Customs and Border Protection including comprehensive knowledge of intelligence and or counterintelligence. Ability to obtain security clearance. Requires Bachelor’s degree or equivalent experience and two to four years of experience in intelligence and analysis for a Customs and Border Protection including comprehensive knowledge of intelligence and or counterintelligence. Ability to obtain security clearance. Requires Bachelor’s degree or equivalent experience and two to four years of experience in intelligence and analysis for a Customs and Border Protection including comprehensive knowledge of intelligence and or counterintelligence. Ability to obtain security clearance."},{"jobtitle":"Data Analyst","companyname":"ManTech","companyid":"5461","address":"","geo":"Sterling, VA, US","postDate":"Jul 13 2018","views":"44","applicants":"8","employees":"5001-10000","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Defense & Space","Computer Software"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nManTech is seeking Top Talent as a Data Analyst. The analyst will aid in the ongoing assessment of our customer systems. The results of the analyses will drive further developments and capabilities our name and entity matching software.\n\nThe Data Analyst Will\n\nObtain, join, scrub, explore, model, and interpret large datasets\nTransform and manipulate large dataset to suit the desired analysis\nCreate and present clear oral and written reports on the findings\nBecome an expert on name and entity matching.\n\nRequired Qualifications\n\nBS Degree in a related technical field (Computer Science, Math, Statistics, etc.)\nAt least two years of experience performing data analyses and interpreting results\nAt least two years of experience using Java, R, or python, Matlab, SQL for data analysis\nConceptual understanding of – and/or prior experiences related to – data profiling, fuzzy matching, entity resolution, and signal detection theory (specifically with respect to SD theory: designing and improving upon systems that monitor, minimize, and balance false positive and false negative outcomes).\n\nMUST BE A US CITIZEN AND ABLE TO OBTAIN AND MAINTAIN A CBP BI. POTENTIAL TO BE SPONSORED FOR TOP SECRET LEVEL CLEARANCE.\n\nPreferred Experience And Skills\n\nExperience working with SQL, data-mining or statistical software.\nJava programming experience is a plus\nExperience with SAS Enterprise Minder, SPSS Modeler, or equivalent\nExperience working in the field of entity resolution, analytics, data mining or name matching.\nExperience working with Customs or ICE travel-related data.\nUnix / Linux experience.\n\nQualifications Qualifications Requires Bachelor’s degree or equivalent experience and two to four years of experience in intelligence and analysis for a Customs and Border Protection including comprehensive knowledge of intelligence and or counterintelligence. Ability to obtain security clearance. Requires Bachelor’s degree or equivalent experience and two to four years of experience in intelligence and analysis for a Customs and Border Protection including comprehensive knowledge of intelligence and or counterintelligence. Ability to obtain security clearance. Requires Bachelor’s degree or equivalent experience and two to four years of experience in intelligence and analysis for a Customs and Border Protection including comprehensive knowledge of intelligence and or counterintelligence. Ability to obtain security clearance."},{"jobtitle":"Data Analyst","companyname":"ManTech","companyid":"5461","address":"","geo":"Sterling, VA, US","postDate":"Jul 13 2018","views":"9","applicants":"1","employees":"5001-10000","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Defense & Space","Computer Software"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nManTech is seeking Top Talent as a Data Analyst. The analyst will aid in the ongoing assessment of our customer systems. The results of the analyses will drive further developments and capabilities our name and entity matching software.\n\nThe Data Analyst Will\n\nObtain, join, scrub, explore, model, and interpret large datasets\nTransform and manipulate large dataset to suit the desired analysis\nCreate and present clear oral and written reports on the findings\nBecome an expert on name and entity matching.\n\nRequired Qualifications\n\nBS Degree in a related technical field (Computer Science, Math, Statistics, etc.)\nAt least two years of experience performing data analyses and interpreting results\nAt least two years of experience using Java, R, or python, Matlab, SQL for data analysis\nConceptual understanding of – and/or prior experiences related to – data profiling, fuzzy matching, entity resolution, and signal detection theory (specifically with respect to SD theory: designing and improving upon systems that monitor, minimize, and balance false positive and false negative outcomes).\n\nMUST BE A US CITIZEN AND ABLE TO OBTAIN AND MAINTAIN A CBP BI. POTENTIAL TO BE SPONSORED FOR TOP SECRET/SCI LEVEL CLEARANCE.\n\nPreferred Experience And Skills\n\nExperience working with SQL, data-mining or statistical software.\nJava programming experience is a plus\nExperience with SAS Enterprise Minder, SPSS Modeler, or equivalent\nExperience working in the field of entity resolution, analytics, data mining or name matching.\nExperience working with Customs or ICE travel-related data.\nUnix / Linux experience.\n\nQualifications Qualifications Requires Bachelor’s degree or equivalent experience and two to four years of experience in intelligence and analysis for a Customs and Border Protection including comprehensive knowledge of intelligence and or counterintelligence. Ability to obtain security clearance. Requires Bachelor’s degree or equivalent experience and two to four years of experience in intelligence and analysis for a Customs and Border Protection including comprehensive knowledge of intelligence and or counterintelligence. Ability to obtain security clearance. Requires Bachelor’s degree or equivalent experience and two to four years of experience in intelligence and analysis for a Customs and Border Protection including comprehensive knowledge of intelligence and or counterintelligence. Ability to obtain security clearance."},{"jobtitle":"Data Analyst","companyname":"ManTech","companyid":"5461","address":"","geo":"Sterling, VA, US","postDate":"Jul 13 2018","views":"38","applicants":"8","employees":"5001-10000","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Defense & Space","Computer Software"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nManTech is seeking Top Talent as a Data Analyst. The analyst will aid in the ongoing assessment of our customer systems. The results of the analyses will drive further developments and capabilities our name and entity matching software.\n\nThe Data Analyst Will\n\nObtain, join, scrub, explore, model, and interpret large datasets\nTransform and manipulate large dataset to suit the desired analysis\nCreate and present clear oral and written reports on the findings\nBecome an expert on name and entity matching.\n\nRequired Qualifications\n\nBS Degree in a related technical field (Computer Science, Math, Statistics, etc.)\nAt least two years of experience performing data analyses and interpreting results\nAt least two years of experience using Java, R, or python, Matlab, SQL for data analysis\nConceptual understanding of – and/or prior experiences related to – data profiling, fuzzy matching, entity resolution, and signal detection theory (specifically with respect to SD theory: designing and improving upon systems that monitor, minimize, and balance false positive and false negative outcomes).\n\nMUST BE A US CITIZEN AND ABLE TO OBTAIN AND MAINTAIN A CBP BI. MAY BE SPONSORED FOR TOP SECRET LEVEL CLEARANCE.\n\nPreferred Experience And Skills\n\nExperience working with SQL, data-mining or statistical software.\nJava programming experience is a plus\nExperience with SAS Enterprise Minder, SPSS Modeler, or equivalent\nExperience working in the field of entity resolution, analytics, data mining or name matching.\nExperience working with Customs or ICE travel-related data.\nUnix / Linux experience.\n\nMUST BE A US CITIZEN AND ABLE TO OBTAIN AND MAINTAIN A CBP/BI CLEARANCE. POTENTIAL TO BE SPONSORED FOR A TOP SECRET CLEARANCE.\n Qualifications Qualifications Requires Bachelor’s degree or equivalent experience and two to four years of experience in intelligence and analysis for a Customs and Border Protection including comprehensive knowledge of intelligence and or counterintelligence. Ability to obtain security clearance. Requires Bachelor’s degree or equivalent experience and two to four years of experience in intelligence and analysis for a Customs and Border Protection including comprehensive knowledge of intelligence and or counterintelligence. Ability to obtain security clearance. Requires Bachelor’s degree or equivalent experience and two to four years of experience in intelligence and analysis for a Customs and Border Protection including comprehensive knowledge of intelligence and or counterintelligence. Ability to obtain security clearance."},{"jobtitle":"Lead Data Engineer","companyname":"Pluto TV","companyid":"3656219","address":"","geo":"Los Angeles, CA, US","postDate":"Jun 13 2018","views":"16","applicants":"1","employees":"51-200","jobDetails":[{"level":"Associate","industry":["Online Media","Computer Software","Internet"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nWho We Are\n\nPluto TV is the leading free streaming television service in the US. We are defining the future of television, delivering over 100 live, linear channels, in a lean back experience and thousands of hit movies and television on demand. Available on all devices, millions of viewers tune in each month to enjoy premier content spanning all categories including movies, news, entertainment, lifestyle & more. Pluto TV boasts an exclusive and coveted network of world renowned corporate and VC investors, elite industry advisors and an accomplished and proven leadership team.\n\nCitizenship\n\nCitizens of Pluto TV have the privilege of entertaining millions of people. We are entrepreneurs looking to revolutionize the future of TV. While our planet is small, our ambition is boundless. The stakes don't get much higher.\n\n Becoming a Citizen is hard work. We need self-starters that thrive in changing environments, who treat company resources like their own, and who deliver seemingly impossible outcomes at warp speed. It's the only way we stay ahead of the giants looking to take the opportunity we have earned. We are selective but once chosen, you're in.\n\nSummary\n\nAs a Lead Data Engineer, you have a solid understanding of both the business and the technical aspects of BI in relation to digital media business. You will drive the completion of projects within the established scope, while simultaneously planning for and managing unknown future BI requirements in a dynamic environment.\n\nResponsibilities Include\n\nDesign, model and develop data sets to support reporting and analytics in a cloud environment.\nETL development: perform all aspects of programming assignments and assist with systems design.\nDevelop and maintain a technical metadata framework and repository of data events and ETL operations.\nManage and administer Analytics tools and tag management systems.\nHelp plan and maintain the technical infrastructure, its configuration, performance, and storage requirements, with consideration of tiered data and data archiving.\nGenerate ad-hoc queries and reports based on business requirements.\nProvide ongoing evaluations of technology solutions and capabilities to ensure alignment with business objectives, identify areas of risk, while monitoring the current environment and potential improvement areas.\nWork with business stakeholders to gather, analyze, and translate requirements in BI reporting area – either recommending an existing solution, developing a solution, or synthesizing delivery requirements to engineering teams for development.\nActively question and challenge customers to understand their requirements and reach the best solutions, near and long term.\nUnderstand and adhere to development and documentation standards, database design and storage.\nSuccessfully implement process improvements impacting own work and work of others.\nOn-call application support is required.\n\n\n\nQualities / Experience We're Seeking\n\n5+ years of top-tier Data engineering experience; at least 2 years on cloud Infrastructure.\nWorking knowledge of digital media ecosystem, including how digital video streaming, ad servers, DSPs, SSPs work.\nExperience working in a mix of Cloud and Enterprise data environments with real world implementation of data collection and processing on AWS environment.\nKnowledge of web technologies and online advertising systems.\nExperience with real-time Big Data analytics.\nExperience with Hadoop, MapReduce, Spark, Flink and/or other Big Data processing platforms.\nExcellent knowledge of OLAP concepts.\nFamiliarity with columnar databases like Redshift, Vertica etc.\nProgramming language such as Java, and scripting languages like python, ruby and Unix shell scripts.\nExperienced working in a fast-paced, high-tech environment (preferably software development) and comfortable navigating conflicting priorities and ambiguous problems.\nExperience with data visualization tools such as Looker, Tableau.\nGreat communication and collaboration skills across technical and non-technical stakeholders.\nA Bachelor's degree in Computer Science or equivalent preferred.\n\n\nWhy You Should Become a Citizen of Pluto TV\n\nBecoming a Citizen is hard work but the rewards of citizenship are plentiful. Work with the smartest people on some of the most complex projects of your life, while profoundly impacting both Pluto TV and the broader world of entertainment. Share in the epic quest to define the future of television as we know it. Big commitment, big impact, lasting change.\n\n As a Citizen, you will enjoy generously-sponsored medical benefits, an open vacation policy, 401K retirement plan, social and team events, and more!"},{"jobtitle":"Senior Data Engineer","companyname":"Omada Health","companyid":"2227727","address":"","geo":"San Francisco, CA, US","postDate":"Jun 13 2018","views":"85","applicants":"10","employees":"201-500","jobDetails":[{"level":"Associate","industry":["Computer Software","Internet","Hospital & Health Care"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nOmada Health is on a mission to inspire and enable people everywhere to live free of chronic disease.\n\n We are a San Francisco-based healthcare and technology company, and are looking for an experienced data engineer to join our growing team. Our program supports people in making lifestyle changes to improve their health, and ultimately, their lives. As a data engineer at Omada, you will be a key contributor in the collection and conversion of rich behavioral health inputs and their translation into data products that enable evidence-based decisions for cross functional teams.\n\n As a key member of our data team, you will help design, build, and scale our data pipelines, data warehouse, and machine learning infrastructure. You should be motivated to learn new technologies and be ready to drive technical work. We use sustainable engineering practices: we work together using pair programming and test-driven development as much as possible, and value mindful collaboration and shipping.\n\nHow You Can Make An Impact\n\nYou'll evaluate, benchmark, and improve the scalability, robustness, and performance of our data platform and applications, making significant contributions to the architecture and design of our data processing platform\nYou'll implement scalable, fault tolerant, and accurate ETLs\nYou'll gather and process raw data at scale from diverse sources\nYou'll collaborate with product management, data scientists, analysts, and other engineers on technical vision, design, and planning\nYou'll implement and maintain a high level of data quality monitoring in our analytics ecosystem\nYou'll train and collaborate with teammates effectively in data engineering best practices\nYou'll be involved and supportive of agile sprint model of development, helping to implement the practice and the discipline\n\n\n\nWhat You Need For This Role\n\n5+ years of experience as a software engineer and 3+ years of experience as a data engineer\nExcellent communication and collaboration skills\nExperience implementing data pipelines and improving the performance of ETL processes and SQL queries\nEnthusiasm for working in an agile development environment\nStrong database schema design and query optimization skills\nProficiency with relational databases and SQL queries (PostgreSQL preferred)\nStrong scripting skills in Python or Ruby\nExperience in data modeling for OLTP and OLAP applications\nUnderstanding of basic principles of data governance\nFamiliarity with workflow management tools (Airflow preferred)\nFamiliarity with cloud-based data warehouses (Amazon Redshift preferred)\nShown ability to understand automated testing concepts and ability to consistently apply those concepts\n\n\n\nBonus Points\n\nExperience with streaming technologies and concepts used with data warehouses\nExperience in taking machine learning models from development to production\nExperience working with visualization tools like Tableau\nExperience working with sensitive data, i.e. PHI / PII\nApplication development experience\n\n\n\nTechnologies We Use\n\nRedshift, Postgres, Python, Ruby, Airflow, Jenkins, Git, Docker, EC2, S3, SNS, SQS, Linux\n\nBenefits\n\nCompetitive salary\nStock options + extended post termination option exercise window (for Omadans who are with us 3 years or more)\nFlexible vacation\nParental leave\nHealth, dental, and vision\nHealthy snacks and meals\nWellness events (e.g. running club)\nCommunity volunteering\n401k retirement savings plan\n\n\nAbout Omada Health: We've pioneered digital behavioural medicine: an innovative approach to tackling the growing epidemic of type 2 diabetes, heart disease, and obesity. Our online programs combine world-class science, technology, and design to inspire and enable people everywhere to live free of chronic disease. Named one of Fast Company's \"50 Most Innovative Companies in the World,\" our team includes passionate and talented individuals. Our approach has been embraced by major employers across the country, including Costco and Iron Mountain, as well as leading health plans, such as Kaiser Permanente and BlueCross Blue Shield of Louisiana.\n\n We carefully hire the best talent we can find, which means actively seeking diversity of beliefs, backgrounds, education, and ways of thinking. We strive to build an inclusive culture where differences are celebrated and leveraged to inform better design and business decisions. Omada is proud to be an equal opportunity workplace and affirmative action employer. We are committed to equal opportunity regardless of race, color, religion, sex, gender identity, national origin, ancestry, citizenship, age, physical or mental disability, legally protected medical condition, family care status, military or veteran status, marital status, domestic partner status, sexual orientation, or any other basis protected by local, state, or federal laws."},{"jobtitle":"Data Scientist #Marketing Analyst","companyname":"Housecall Pro","companyid":"3491149","address":"","geo":"San Diego, CA, US","postDate":"Jun 13 2018","views":"207","applicants":"37","employees":"51-200","jobDetails":[{"level":"Entry level","industry":["Information Technology & Services","Computer Software","Internet"],"jobtype":"Full-time","function":["Engineering","Information Technology"]}],"description":"Job description\nData Scientist #Marketing Analyst\n\nSan Diego, CA\n\nAre you a seasoned #Marketing Data Scientist or Data Analyst? If so, we want to hear from you!\n\nAt Housecall Pro, we are focused on helping home services professionals elevate their businesses and lives. Community coupled with the use of a modern and mobile software platform that handles the scheduling and management aspects frees our Pros to focus on their craft. Housecall Pros thrive and so do their businesses, which grow by 30% on average year over year.\n\n The home services industry remains vast ($700b+) but largely untouched by technology and unencumbered by a dominant competitor. The 3M+ businesses in home services space are facing dramatic change as the world shifts from offline to online. Along this journey, we are quickly becoming the backbone operating system for service labor across the US and Canada. We have rocketed from MVP to the #1 ranked SaaS software platform very quickly...which has made us the fastest growing startup in San Diego.\n\nThe role\n\nAs a Data Analyst you’ll be working closely with our Marketing team and help stakeholders to make informed, data-driven decisions. You are intellectually curious, a creative problem solver, technically savvy and experienced in marketing analytics, data mining, and data visualization. You have experience with lead generation analytics, web and campaign analytics, marketing attribution, full-funnel analysis and channel ROI optimization. You get excited about learning new technologies and working in a collaborative environment. You want to enjoy work, be part of a growing start up and get the opportunity to grow your career.\n\n Our Analytics team is extraordinary. Empathetic, hard working and focused on easy data and information access. Housecall Pro is a data-driven company and we are the \"insights engine\" of the organization, helping HCP and the HCP service professionals to optimize and to grow their businesses.\n\nResponsibilities\n\nBuild out a best-in-class multi-touch marketing attribution model\nSet up, maintain and optimize performance analysis of online/offline Marketing Channels\nIdentify optimal lead touchpoints and help optimize the customer journey\nAnalyze front end marketing KPIs from Facebook, Google Analytics, AdWords, and other channels to provide recommendations for campaign optimization\nDevelop marketing campaign measurement strategies to determine campaign success\nCapture and analyze quantitative and qualitative customer data to drive campaign development\nUse website heat map data to uncover insights into user behavior\nTake the lead on A/B testing by defining useful hypotheses, designing robust experiments, analyzing results\nDefine, implement and standardize metrics, reports and dashboards leveraging Tableau\n\n\nQualifications\n\nBachelor or Master's degree in a quantitative discipline (statistics, economics, mathematics, marketing analytics)\n2+ years of experience in marketing analytics field, solving problems using quantitative approaches\nStrong background in statistical concepts, modeling, and scenario analysis\nExpertise in manipulating and analyzing large, complex, multi-dimensional data sets using SQL and statistical software tools such as R, Python, etc.\nExpertise in Google Analytics and Tableau\nHigh energy and intellectually curious individual with a desire to work in a result oriented, dynamic, rapid growth environment\nIndependent thinker with ability to move a project forward, draw key insights, and plan next steps\nExcellent verbal and written skills and the ability to interface effectively with all levels of management\n\n\nWhy Housecall Pro?\n\nHousecall Pro is a mission-driven company. Our co-founder/CEO built a software company to help service professionals like his father (a house painter), get to a better life. We save our service professionals time, and help them, in turn, to delight their end-customers.\nWe are tackling the last, large market ($700b+) untouched by technology and unencumbered by a dominant competitor.\nOur goal is to build a $10 billion+ company that is a powerful brand to home service providers and consumers.\nCompetitive compensation and benefits.\nEquity in a growth stage startup backed by top-tier VCs.\nSan Diego is an idyllic place to live; our office is minutes away from hiking/biking trails, and the surf.\nPaid holidays and self-managed paid time off.\n\n\nHousecall Pro is committed to equal treatment and opportunity in all aspects of recruitment, selection, and employment without regard to gender, race, religion, national origin, ethnicity, disability, gender identity/expression, sexual orientation, veteran or military status, or any other category protected under the law. Housecall Pro is an equal opportunity employer; committed to a community of inclusion, and an environment free from discrimination, harassment, and retaliation."},{"jobtitle":"Data Engineer - Center of Data Science Team","companyname":"New York Life Insurance Company","companyid":"3432","address":"","geo":"New York City, NY, US","postDate":"Mar 14 2018","views":"101","applicants":"14","employees":"10001","jobDetails":[{"level":"","industry":["Financial Services","Insurance"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nA career at . It all adds up to a rewarding career at a company where doing right by our customers is part of who we are, as a mutual company without outside shareholders. We invite you to bring your talents to New York Life, so we can continue to help families and businesses “Be Good At Life.” To learn more, please visit\n\nNew York Life, the largest writer of retail life insurance in the U.S. and a top player in annuities, long-term care and mutual funds, is seeking a Data Engineer in its Center for Data Science and Analytics.\n The Center for Data Science and Analytics is the innovative corporate Analytics group within New York Life. We are a rapidly growing entrepreneurial department, which aims to design, create and offer innovative data-driven solutions for many parts of the enterprise. We are aided by New York Life’s existing business with a large market share in individual life insurance. We have the freedom to explore external data sources and new statistical techniques, and are excited about delivering a whole new generation of Analytical solutions.\n In fact, we are designing and will build one of the first multivariate model-based continuous risk differentiations in the industry. This model will incorporate current underwriting best practices (including medical rules) as features and add other data sources, patterns/ideas and variables to essentially create a rating plan to support the next generation underwriting process at New York Life. This is just one of several projects with large business value. Geographic analytics on agents and customers, application fraud detection, agent success prediction and client prospecting analytics (off-line and on-line) are other exciting examples of enormous incremental value from analytics. Our products will be implemented into real-time core business processes and decisions that drive the company (e.g. underwriting, pricing, agent recruiting, prospecting, new product development).\n\nWe work with data ranging from demographics, credit and geo data to detailed medical data (medical test results, diagnosis, prescriptions) and social media information. We have a modern computing environment with a solid suite of data science/modeling tools and packages, and a large (but manageable) group of well-trained professionals at various levels to support you. Life insurance is on the verge of huge change. This is a chance to be part of, actually to drive, the transformation of an industry.\n\nYou will be part of Data & Platform sub-function team under Center for Data Science and Analytics. The Data & Platform team services internally to Data Scientists who focus on Statistical analysis.\n\nYou will be part of a fast paced, high-impact team who will work with an entrepreneurial mindset using some of the best of breed tools as part of our Enterprise Data Hub (Hadoop) using R, Spark and Python.\n\nYou will apply your data engineering skills to build pipelines, workflows to gather, cleanse, test and curate datasets from Oracle, MSSQL Server, 3rd party data and create datasets in Enterprise Data Lake (Hadoop), which will be used by several teams of predictive modelers.\n\nYou will perform Proof of Concepts and test out new software tools under the umbrella of Data Science but geared more towards data engineering.\n\nResponsibilities\n\nIngests, merges, prepares, tests, documents curated datasets from various novel external and internal datasets for a variety of advanced analytics involving multi-variate models\nUtilizes data wrangling/data matching/ETL techniques while to explore a variety of data sources, gain data expertise, perform summary analyses and curate datasets\nFunctions as data expert, contributes to analytics/solutions design and productizing decisions\nCollaborate with Business leaders to understand business challenges and devise solutions by using business acumen and mining vast amounts of data to draw insights\nCan work independently with some supervision and be part of a collaborative team\nWork with Project Managers and Scrum Masters to provide milestones and stories\nProactively and effectively communicates in various verbal and written formats with senior level member of the team and partner\nActively participates in proof of concept tests of new data, software and technologies. Shares knowledge within the team\nFollows industry trends and related data/analytics processes and businesses. Attends conferences, events, and vendor meetings as needed\n\n\nRequired Qualifications\n\nGraduate-level degree in computer science, engineering, or relevant experience in the field of Business Intelligence, Data Mining, Database Engineering, Programming\n3-5 years of overall experience working in the field of data wrangling and programming with a minimum of 1 year experience with ingesting, cleaning, merging and applying necessary data wrangling logic in Hadoop\n1+ years in writing complex SQL queries in any of the following and/or similar databases - Oracle, SQL Server, DB2, MySQL\nProficiency using Python for all data related work such as Numpy, Pandas, PySpark\nExperience working with Linux Operating System\nExperience working with data visualization tools or packages\nExperience building Exploratory Data Analysis reports such as Histograms, Box plots, Pareto, Scatter Plot using R, Python or a Data Visualization tool such as Tableau and Spotfire\n\n\nPreferred\n\nUnderstanding of statistical modeling concepts, designs and analytics-based products\nAny experience in using ETL tools such as Ab Initio, Talend, Informatica, Pentaho\nAny experience working with Data Warehouses and/or Data Marts\nAny experience in Life Insurance business\n\n\nOther Notes\n\nOur technology stack is RStudio Pro, SAS, Enterprise Data Hub (using Hortonworks Hadoop Data Platform), Waterline, Trifacta, R, Python, Spark, PySpark, SparkR, Linux\n\n EOE M/F/D/V\n SF: LI-TK1\n\n EF: EF-TK1\n\n EOE M/F/D/V\n If you have difficulty using or interacting with any portions of this Web site due to incompatibility with an Assistive Technology, if you need the information in an alternative format, or if you have suggestions on how we can make this site more accessible, please contact us at: (212) 576-5811."},{"jobtitle":"Development & Integration Data Analyst","companyname":"Axiologic Solutions LLC","companyid":"2192237","address":"","geo":"Washington, D.C., DC, US","postDate":"Mar 14 2018","views":"2","applicants":"0","employees":"51-200","jobDetails":[{"level":"Associate","industry":["Information Technology & Services","Defense & Space","Computer Software"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nOverview\n\nBased in Northern, VA, Axiologic Solutions LLC has opportunities for you to become part of our high-quality team that delivers innovative solutions to key federal clients. We are currently seeking candidates toprovide data analysis support. This position will be located either in Reston, VA or Washington, DC.\n\nResponsibilities\n\nDeliver data environment that enables the integration of data sources such that advanced analytic algorithms can be applied and yield analytic results supporting visualizations to inform senior level decision makers and line level analyst.\nPerform security integration, auditing and monitoring in accordance with DIA standard and processes to include accurate reporting procedures for internal use software expenditures\nTechnical subject matter expertise in software coding and unit level testing, including but not limited to Java, python, Ruby, R.\nDraw on existing DIA (DoDIIS) and IC ITE Data Service Architecture (DSA) architecture, security and application requirements/processes, take advantage of lessons learned from previous projects, leverage existing, available DIA data repositories and services, the DIA Software Development Environment, DevOps processes, EPS data and platform capabilities, DoDIIS available infrastructure (including but not limited to: C2S AWS,\nGovCloud, VMware, physical systems) and leverage existing DIA and future IC ITE environment, tools and services.\nThe contractor shall perform data analysis against DIA's data holdings implementing industry best-practices such as data mining, predictive analytics, text analytics, or other techniques as appropriate.\nProvide support for the \"data retrograde\" tool that provides a solution to sort out relevant documents from a larger data set and operate, maintain, and update a machine learning data model, rules engine, and workflow within the web application that allows a user to curate documents against a binary decision.\nProvide SMEs experience in Cloud Technologies, AWS/C2S, containers, data layers, micro-services, System Administration, and SQL/NSQL database experience.\n\n\n\nQualifications\n\nMust have an active/current TS/SCI and CI Poly.\nA bachelor's degree or equivalent training.\nSeven years or more years of specialized experience working on complex data/database projects as a data analyst, data architect, data scientist or database engineer.\nProduces and reports timely and accurate analyses at the appropriate level of detail to enable business decisions.\nSupport the client with comprehending the context of its program data by extracting qualitative and quantitative relationships, including patterns and trends from large amounts of data and providing analytic support to help inform policy, rational decision making, and resource allocation.\nProvide support for IT Strategic implementation, coordination of project management and communications support efforts across a matrixed organization.\n\n\nWe are proud of our diverse environment, EOE, M/F/Disability/Vet/Sexual Orientation/Gender Identity.\n\nJob Start/End Date: 17-Apr-2017 to 01-Sep-2017 (EST)\n\nLocation: Washington, DC, USA\n\nEmployment Type: Full Time\n\nPay Type: Salary"},{"jobtitle":"Data Analyst 2","companyname":"Stanford University","companyid":"","address":"","geo":"Stanford, CA, US","postDate":"Dec 12 2017","views":"26","applicants":"6","employees":"","jobDetails":[{"level":"Associate","industry":["Non-profit Organization Management","Financial Services","Hospital & Health Care"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\n## Description\n\nData Analyst 2\n\nJob Family: Information Analytics\n\nJob Series: Data Analyst\n\nJob Code: 4745\n\nGrade: I\nExemption: Exempt\nEffective/Revision Date: 04/01/2015\n\nJob Series Matrix URL: View PDF\n\nNote: Not all unique aspects of the job are covered by this job description\n\nJob Purpose\n\nUnder minimal supervision, perform the most complex technical work associated with a wide variety of analytical data and produce routine, single data sources’ information requests. Sources and acquires data both internally and externally needed to conduct dataanalyticsacross procure to pay such as spend analytics, savings, and business expense analysis\n\nCORE DUTIES*:\n\nWork under consultative or self-initiated direction to assess and produce relevant, standard, or custom information (reports, charts, graphs and tables) from structured data sources by querying data repositories and generating the associated information. Distribute and disseminate reports to applicable agencies, researchers, management and other internal end-users.\nDevise methods for identifying data patterns, trends in available information sources using a variety of qualitative and quantitative techniques. Determine and recommend additional data collection and reporting requirements.\nDesign and customize reports based upon data in the database.\nCreate non-routine databases and their related information summary; develop algorithms and statistical model; and perform statistical analyses appropriate to complex data and reporting requirements.\nServe as a resource for non-routine inquiries such as requests for statistics or surveys.\nLead the implementation of data standards and common data elements for data collection.\nCollaborate with technical staff to standardize and systemize routine reports, dashboards, and metrics.\nMay test prototype software and participate in approval and release process for new software.\n\n\n**\n\n - Other duties may also be assigned\n\nQualifications\n\nMINIMUM REQUIREMENTS:\n\nDesired Qualifications**\n\nAbility to translate unstructured, complex business problems into abstract analytical and mathematical framework and solutions.\nAbility to analyze analytics requirements and recommend solutions, techniques and metrics to minimize false positive.\nAbility to extract, transform, and enrich data from multiple sources, e.g. data warehouse, data mart, OLTP data bases, API, csv.\nExperience with programming languages such as SQL, R, Python, or Java.\nExperience with data visualization such as Tableau.\nExperience working with large data sets and distributed computing framework -- Hadoop, MapReduce, Spark, Pig, Hive, NoSQL, MongoDB,\nSome experience with Data Science, predictive analytics, or NLP.\nExpertise in software engineering and data analysis principles and skills working on Windows/ Unix/Linux operating systems, Version Control and Office software.\nAbility to understand and apply the software development lifecycle.\nAbility to lead, mentor, motivate and supervise technical staff.\nAbility to communicate technical information to all audiences.\n\n\n\nEducation & Experience\n\nBachelor's degree and three years of relevant experience or combination of education and relevant experience. Experience in a quantitative discipline such as economics, finance, statistics or engineering.\n\n Preferred education with Master’s Degree in Computer Science, Data Science, Applied Math, Statistics or related field.\n\nKnowledge, Skills And Abilities\n\nIn-depth knowledge and experience using and applying analytical software, database management system software, database reporting software, database user interface and query software, and data mining software.\nExpert ability to collect data using a variety of methods, such as data mining and hardcopy or electronic documentation study, to improve or expand databases.\nBasic statistical ability.\nStrong listening, verbal and written communication skills.\nAbility to manage multiple activities in a deadline-oriented environment; highly organized, flexible and rigorous attention to detail.\nAbility to use logic to calculate data; efficiently construct a database or scrutinize the form of a question.\nAbility to work with data of varying levels of quality and validity.\nDemonstrated ability to produce data in a clear and understandable manner meeting user requirements.\nAbility to work effectively with multiple internal and external customers.\nAbility to take a leadership role on projects and with users/clients.\n\n\nCertifications and Licenses:**\n\n None\n\nPHYSICAL REQUIREMENTS*:\n\nConstantly perform desk-based computer tasks.\nFrequently sit, sort, file paperwork or parts, grasp lightly, and use fine manipulation, lift, carry, push and pull objects that weigh 10 pounds or less.\nOccasionally write by hand, twist, bend, stoop and squat.\nRarely stand, walk, reach or work above shoulders and use a telephone.\n\n\n**\n\n\n- Consistent with its obligations under the law, the University will provide reasonable accommodation to any employee with a disability who requires accommodation to perform the essential functions of his or her job.\n\nWorking Conditions\n\nMay work extended hours during peak business cycles.\n\n\nWORK STANDARDS:_**\n\nInterpersonal Skills: Demonstrates the ability to work well with Stanford colleagues and clients and with external organizations.\nPromote Culture of Safety: Demonstrates commitment to personal responsibility and value for safety; communicates safety concerns; uses and promotes safe behaviors based on training and lessons learned.\nSubject to and expected to comply with all applicable University policies and procedures, including but not limited to the personnel policies and other policies found in the University’s Administrative Guide, http://adminguide.stanford.edu/.\n\n\nJob: Information Analytics\n\nLocation: Business Affairs\n\nSchedule: Full-time\n\nReq ID: 73800\n\nJob Grade: 4745"},{"jobtitle":"Data Management Consultant","companyname":"Kalypso","companyid":"33920","address":"","geo":"Portland, OR, US","postDate":"Nov 12 2017","views":"137","applicants":"12","employees":"201-500","jobDetails":[{"level":"","industry":["Information Technology & Services","Computer Software","Management Consulting"],"jobtype":"Full-time","function":["Information Technology"]}],"description":"Job description\nKalypso – Enterprise Information Management Practice\n\nData Management Consultant/Specialist\n\nResponsibilities Include\n\nInterpreting data, analyzing results using statistical and data management techniques and providing ongoing reports\nDeveloping and implementing data management solutions, data analytics and other strategies to provide input for information management, integration, and migration functional designs.\nAcquiring data from primary or secondary data sources and maintaining databases/data systems\n\n\n\nJob Brief\n\nWe are looking for a intermediate level consultant to join the Enterprise Information Management practice. The successful candidate will help our clients succeed with their data management programs by providing operational expertise, innovative approaches and close partnership with all data stakeholders.\n\nJob Duties\n\nData Management Consultant/Specialist responsibilities include conducting full lifecycle analysis to include requirements, activities, and design. Consultant will develop analysis and reporting capabilities. They will also monitor performance and quality control plans to identify improvements.\n\nSuccess Measures\n\nTechnical expertise regarding data models, database design development, data mining and segmentation techniques\nWorking knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Javascript, or ETL frameworks)\nKnowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc)\nStrong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy\nAdept at queries, report writing and presenting findings\nAbility to interpret data, analyze results using statistical techniques and provide ongoing reports\nIdentify, analyze, and interpret trends or patterns in complex data sets\nFilter and “clean” data by reviewing reports, outputs, and performance indicators to locate and correct issues\nWork with management to prioritize business and information needs\nLocate and define new process improvement opportunities\n\n\n\nExpectations\n\nTake ownership of and execute against data related Agile (SAFe) stories\nConduct interviews and work sessions with technology and business team members to clarify information requirements (as needed)\nRepresent information requirements in tool configuration\nDocument and/or leverage data documentation of source and target systems\nDevelop a clear understanding of the integration and migration strategy for the project\nAid in the creation of the business object model (analysis model) and associated documents\nCreate and/or aid in the creation of context diagrams and associated system process models to aid in clarity\nPerform data analysis leveraging methods such as SQL\nProvide input into technical integration design as needed\nCreate test cases and participate in testing when required\nContribute and consult to physical data models including Attribute Data Model and Service Design/Contracts\nProvide data analysis and insights in support of Key Design Decisions and Data Definition\nDocument and analyze data scenarios which contribute to design validation and other analysis\n\n\n\nSkills & Experience Requirements\n\nProven working 3+ years experience as a data analyst or business data analyst\nExcellent verbal and written communication skills\nExcellent analysis and problem solving skills\nStrong meeting and work session facilitation skills\nStrong planning and organizational skills\nStrong ability to adapt to changing needs, adjusted process and ambiguity.\n3+ years systems to system integration analysis and design\n2+ years SQL\n2+ years use case development\n2+ years of using Microsoft Office tools (Word, Excel, Access, PowerPoint)\n1+ years using MS Visio\n1+ years (recent) OOAD\nBachelor’s degree in Mathematics, Economics, Computer Science, Information Management or Statistics."}]
